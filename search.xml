<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>JVM</title>
      <link href="/2022/11/16/jvm-bi-ji/"/>
      <url>/2022/11/16/jvm-bi-ji/</url>
      
        <content type="html"><![CDATA[<h3 id="一、类加载机制"><a href="#一、类加载机制" class="headerlink" title="一、类加载机制"></a>一、类加载机制</h3><h4 id="1-类加载过程"><a href="#1-类加载过程" class="headerlink" title="1 类加载过程"></a>1 类加载过程</h4><h5 id="1-1加载"><a href="#1-1加载" class="headerlink" title="1.1加载"></a>1.1加载</h5><p>（1）获取类的全限定类名，把 class 文件转为二进制流 </p><p>（2）将二进制流中类的描述信息存入方法区中。如：创建时间、版本等… </p><p>（3）将 java.lang.Class 对象存入堆</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114110604298-16685935581542.png" alt="image-20221114110604298"></p><h5 id="1-2-链接"><a href="#1-2-链接" class="headerlink" title="1.2 链接"></a>1.2 链接</h5><p>（1）验证：验证被加载类的正确性：如文件的格式，元数据等。 </p><p>（2）准备：在方法区中为静态变量分配空间，并设置初始值</p><p>（3）解析：把类的符号引用转为直接引用。 </p><p>符号引用：class 文件定义的内容 </p><p>直接引用：JAVA 进程中真实的地址</p><h5 id="1-3-初始化"><a href="#1-3-初始化" class="headerlink" title="1.3 初始化"></a>1.3 初始化</h5><p>为类的静态变量设置默认值、执行静态代码块。</p><p>初始化的时候就把这个10给过去</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114114035360.png" alt="image-20221114114035360"></p><h4 id="2-类加载器"><a href="#2-类加载器" class="headerlink" title="2 类加载器"></a>2 类加载器</h4><h5 id="2-1-分类"><a href="#2-1-分类" class="headerlink" title="2.1 分类"></a>2.1 分类</h5><p>不同的类加载器加载不同的类： </p><p><strong>启动类加载器(Bootstrap classLoader)</strong>: 主要负责加载 JAVA 中的 一些核心类库，主 要是位于&#x2F;lib&#x2F;rt.jar 中。 </p><p>**拓展类加载器(Extension classLoader):**主要加载 JAVA 中的一些拓展类，位于 &#x2F;lib&#x2F;ext 中,是启动类加载器的子类。 </p><p><strong>应用类加载器(System classLoader):</strong> 主要用于加载 CLASSPATH 路径下我们自己写 的类，是拓展类加载器的子类</p><h5 id="2-2-双亲委派模型"><a href="#2-2-双亲委派模型" class="headerlink" title="2.2 双亲委派模型"></a>2.2 双亲委派模型</h5><p><img src="/2022/11/16/jvm-bi-ji/image-20221114114754436.png" alt="image-20221114114754436"></p><p>上面这段代码中，我们只能加载系统的String，而不能加载我们自定义的String</p><p>那为什么我们希望加载我们自定义的String，但是却加载出来了系统的String，这就涉及到类加载中的双亲委派模型</p><p>如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给 父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器。如果父类加载器可以完成类加载任务，就成功返回。 倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载。</p><p>所有的类加载器都是这个流程，向上委派，再向下验证</p><p>问起来能不能加载一个同名的自定义，就可以回答由于双亲委派模型，最后一定加载出来的是系统的Object</p><p>然后继续问</p><p>面试题：如何打破双亲委派机制？   ————- tomcat （打破双亲委派的例子）</p><p>自定义类加载器类，继承 ClassLoader 类，重写 loadClass 方法</p><p>其实重写这个方法的代码非常长，就是之前的装载、链接、初始化、都要去写一遍，但是答到上面就可以了</p><h3 id="二、JVM-内存模型"><a href="#二、JVM-内存模型" class="headerlink" title="二、JVM 内存模型"></a>二、JVM 内存模型</h3><h4 id="1-什么是-JVM内存模型"><a href="#1-什么是-JVM内存模型" class="headerlink" title="1 什么是 JVM内存模型"></a>1 什么是 JVM内存模型</h4><p>JVM 需要使用计算机的内存，Java 程序运行中所处理的对象或者算法都会使用 JVM 的内 存空间，JVM 将内存区划分为 5 块，这样的结构称之为 JVM内存模型</p><h4 id="2-JVM-为什么进行内存区域划分"><a href="#2-JVM-为什么进行内存区域划分" class="headerlink" title="2 JVM 为什么进行内存区域划分"></a>2 JVM 为什么进行内存区域划分</h4><p>随着对象数量的增加，JVM 内存使用率也在增加，如果 JVM 内存使用率达到 100%， 则无法继续运行程序。为了让 JVM 内存可以被重复使用，我们需要进行垃圾回收。为了提 高垃圾回收的效率，JVM 将内存区域进行了划分。</p><h4 id="3-JVM-内存划分"><a href="#3-JVM-内存划分" class="headerlink" title="3 JVM 内存划分"></a>3 JVM 内存划分</h4><p> JVM 按照线程是否共享将内存首先分成两大类 </p><h5 id="线程独享区"><a href="#线程独享区" class="headerlink" title="线程独享区"></a>线程独享区</h5><p>只有当前线程能访问数据的区域，线程之间不能共享 </p><p>线程独享区随线程的创建而创建，随线程的销毁而被回收 </p><h5 id="线程共享区"><a href="#线程共享区" class="headerlink" title="线程共享区"></a>线程共享区</h5><p>所有线程都可以访问的区域， 当线程被销毁的时候，共享区的数据不会立即回收，需要等待达到垃圾回收的阈（yu） 值之后才会进行回收。</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114124457085.png" alt="image-20221114124457085"></p><p><strong>栈内存独立，堆内存共享</strong></p><p><strong>基本数据类型的数据，存在栈内存里</strong>—-比如int</p><p><strong>堆内存里：存引用类型数据</strong>—-比如Student</p><p>上面说的可以用代码测试一下</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114124923338.png" alt="image-20221114124923338"></p><p>这就体现线程独享区和线程共享区中栈内存和堆内存的一个例子</p><p>因为CPU是轮询的，所以代码可能执行到某一行就轮到下一个时间片分给别人了，那再轮到自己的时候，我得知道自己执行到哪里了，所以要记录执行到哪，就是程序计数器在记录这个东西</p><h4 id="4-程序计数器"><a href="#4-程序计数器" class="headerlink" title="4 程序计数器"></a>4 程序计数器</h4><p>程序计数器会记录当前线程要执行指令的内存地址，只占用一小部分内存区域，只记录一个 地址，所以我们认为程序计数器是不会出现内存溢出问题的分区。</p><p>所以优化肯定不会去优化程序计数器</p><h4 id="5-本地方法栈"><a href="#5-本地方法栈" class="headerlink" title="5 本地方法栈"></a>5 本地方法栈</h4><p>Java 中有些代码的实现是依赖于其他非 Java 语言的（C++），本地方法栈存储的是维护 非 Java 语句执行过程中产生的数据，一般我们认为本地方法栈不会出现内存的问题。</p><p><strong>问划分的时候就不要说这块了，就说：堆内存，方法区，程序计数器，虚拟机栈就可以</strong></p><p>因为本地方法栈在JVM中并不是一个特别重要的知识点</p><h4 id="6-虚拟机栈"><a href="#6-虚拟机栈" class="headerlink" title="6 虚拟机栈"></a>6 虚拟机栈</h4><h5 id="6-1-虚拟机栈的作用"><a href="#6-1-虚拟机栈的作用" class="headerlink" title="6.1 虚拟机栈的作用"></a>6.1 虚拟机栈的作用</h5><p>存放当前线程中所声明的变量，包括基本数据类型的数据和引用数据类型的引用。 </p><h6 id="基本数据类型和引用数据类型划分的标准："><a href="#基本数据类型和引用数据类型划分的标准：" class="headerlink" title="基本数据类型和引用数据类型划分的标准："></a>基本数据类型和引用数据类型划分的标准：</h6><p> 基本数据类型： </p><p>变量在声明的时候，能够确认占用内存的大小。 </p><p> 引用数据类型： </p><p>变量在声明的时候，不能确认占用内存的大小。 </p><p>引用数据类型将值的引用存放到虚拟机栈中，而对象存放在堆内存中，引用数据类型占用 4 个字节存放地址</p><p>基本数据类型，我们知道占用的字节，但是引用数据类型我们是不知道它占用了多少空间的，所以虚拟机栈存放这俩种数据的时候采用的策略是不一样的</p><p>这就是虚拟机栈存的内容</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114151634447.png" alt="image-20221114151634447"></p><p>同一个线程同一个虚拟机栈，那输出的时候，是输出第一个num还是第二个</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114151754058.png" alt="image-20221114151754058"></p><p>其实虚拟机栈为了解决这样一个问题，就是在方法调用的时候如果出现同名变量的情况，进行这样一个设计，<strong>栈帧</strong></p><h5 id="6-2-栈帧"><a href="#6-2-栈帧" class="headerlink" title="6.2 栈帧"></a>6.2 栈帧</h5><p>每一个线程都会对应一个虚拟机栈，线程中的每个方法都会创建一个栈帧，存放<strong>本次方法执行过程</strong>中所需要的所有数据。 </p><p>如果我们一个线程中有多个方法的嵌套调用，虚拟机栈会对栈帧进行压栈和出栈操作。正在 执行的方法一定在栈顶，我们只能获取栈顶的栈帧，栈帧在虚拟机栈中先进后出</p><p>然后在上面这个线程中就会创建三个栈帧，main、m1栈帧、m2栈帧。</p><p>所以就是m2找m2的栈帧，m1找m1的栈帧</p><p>栈帧工作流程：</p><p>栈：先进后出（栈帧）</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114152437175.png" alt="image-20221114152437175"></p><p>就是这样子</p><p>解释一下，首先这段代码是在一个线程中的，那就用的是同一个虚拟机栈，来，看图</p><p>就是压栈之后，只能执行虚拟机栈帧最上面的内容</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114152827806.png" alt="image-20221114152827806"></p><p>然后输出完之后，栈帧就会进行一个出栈（弹栈）</p><h5 id="6-3-栈帧的数据结构"><a href="#6-3-栈帧的数据结构" class="headerlink" title="6.3 栈帧的数据结构"></a>6.3 栈帧的数据结构</h5><h6 id="局部变量"><a href="#局部变量" class="headerlink" title="局部变量"></a>局部变量</h6><p>存放当前方法的局部变量 ，基本数据类型存值，引用数据类型存堆内存地址。 </p><h6 id="操作数栈"><a href="#操作数栈" class="headerlink" title="操作数栈"></a>操作数栈</h6><p>对方法中的变量提供计算的区域。 </p><h6 id="常量数据的引用"><a href="#常量数据的引用" class="headerlink" title="常量数据的引用"></a>常量数据的引用</h6><p>常量数据会存放到方法区的常量池中，不管是基本数据类型还是引用数据类型都会存放常量池的地址 </p><h6 id="方法返回值的地址"><a href="#方法返回值的地址" class="headerlink" title="方法返回值的地址"></a>方法返回值的地址</h6><p>方法返回数据会存到计算机内存的寄存器中。</p><p>其实局部变量就是栈帧的主要功能</p><p>a&#x3D;a+1，需要放到操作数栈中计算，但是a++就不用，直接就在局部变量里+1</p><p>常量数据的引用都是存的引入</p><p>实际上是存在方法区的常量池</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114155219300.png" alt="image-20221114155219300"></p><h5 id="6-4-虚拟机栈溢出异常"><a href="#6-4-虚拟机栈溢出异常" class="headerlink" title="6.4 虚拟机栈溢出异常"></a>6.4 虚拟机栈溢出异常</h5><p>由于栈帧调用的深度太深，会出现虚拟机栈溢出异常（SOF 异常）。一般手动方法的调用 是不会出现这个异常的，如果出现这个异常 ，99%是由于递归。 可以通过修改虚拟机栈的内存大小设置栈帧的最大深度，指令为    -Xss 虚拟机栈内存大</p><p>一般栈帧深度达到 3000~5000 即可 </p><p>太小：虚拟机栈容易溢出。 </p><p>太大：每个线程占据的内存过大，影响线程数量</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114155751110.png" alt="image-20221114155751110"></p><p>设置为256k之后，两千多栈帧就会报栈移除SOF</p><p>一般情况下我们不用设置，使用默认的就行，默认都用一万多</p><h4 id="7-方法区"><a href="#7-方法区" class="headerlink" title="7 方法区"></a>7 方法区</h4><p>在 java8 之后，我们把方法区称之为元空间（MetaSpace），方法区在逻辑上属于堆的一部分，但一些具体机制和堆有所区别，如：一些 JVM 的方法区是可以不进行垃圾回收 的，关闭 JVM 时才会释放方法区内存。所以方法区还有一个别名叫非堆，目的是和堆分开。 </p><p>方法区会存储<strong>类信息、静态变量、常量（JDK8 之后不存放字符串常量）、本地机器指令。</strong> </p><p>如果加载大量 class 文件，也会造成方法区内存溢出，如一个 tomcat 运行 20~30 个 项目</p><h2 id="三、JVM-执行引擎"><a href="#三、JVM-执行引擎" class="headerlink" title="三、JVM 执行引擎"></a>三、JVM 执行引擎</h2><h4 id="1-什么是-JVM-执行引擎"><a href="#1-什么是-JVM-执行引擎" class="headerlink" title="1 什么是 JVM 执行引擎"></a>1 什么是 JVM 执行引擎</h4><p>执行引擎是 Java 虚拟机核心的组成部分之一。JVM 的将字节码装载到内存，但字节码 并不能够直接运行在操作系统之上。为了执行内存中的字节码文件指令,执行引擎 (Execution Engine)就要将字节码指令解释&#x2F;编译为对应平台上的本地机器指令。 </p><p>执行引擎的翻译过程有两种：1、通过解释器将字节码文件转为机器指令执行；2、使用即时编译器(JIT)将字节码文件的二进制流编译成机器指令执行。 </p><p>目前市面的主流 JVM 采用解释器与即时编译器并存的架构。在 Java 虚拟机运行时，解 释器和即时编译器相互协作，取长补短。在今天，Java 程序的运行性能早已脱胎换骨,已经 达到了可以和 C&#x2F;C++程序一较高下的地步</p><h4 id="2-解释器与即时编译器"><a href="#2-解释器与即时编译器" class="headerlink" title="2 解释器与即时编译器"></a>2 解释器与即时编译器</h4><p>解释器每次解释都会将字节码文件解释为机器指令。整体效率较低，但当程序启动后, 解释器可以马上发挥作用，省去编译的时间，立即执行。 </p><p>即时编译器则会将字节码文件编译为机器指令，存在方法区中，编译完成后直接执行本 地机器指令即可。编译器把代码编译成本地代码需要一定的执行时间，但编译为本地代码后执行效率高。 </p><p>当 Java 虚拟器启动时，解释器首先发挥作用，不必等待即时编译器全部编译完成后再执行。随着时间的推移，编译器把越来越多的代码编译成本地代码，此时运行本地机器指令， 获得更高的执行效率。</p><h2 id="四、堆内存模型💖"><a href="#四、堆内存模型💖" class="headerlink" title="四、堆内存模型💖"></a>四、堆内存模型💖</h2><p> 对JVM的调优主要就是对堆内存的调优</p><h4 id="1-JAVA-对象的内存布局"><a href="#1-JAVA-对象的内存布局" class="headerlink" title="1 JAVA 对象的内存布局"></a>1 JAVA 对象的内存布局</h4><p>看原笔记</p><h4 id="2-JVM-内存溢出和垃圾回收机制"><a href="#2-JVM-内存溢出和垃圾回收机制" class="headerlink" title="2 JVM 内存溢出和垃圾回收机制"></a>2 JVM 内存溢出和垃圾回收机制</h4><h6 id="为什么要进行垃圾回收："><a href="#为什么要进行垃圾回收：" class="headerlink" title="为什么要进行垃圾回收："></a>为什么要进行垃圾回收：</h6><p>如果对象只创建不回收，会造成堆内存溢出(OOM)异常。 </p><h6 id="为什么要进行堆内存分区："><a href="#为什么要进行堆内存分区：" class="headerlink" title="为什么要进行堆内存分区："></a>为什么要进行堆内存分区：</h6><p>1.提高搜索垃圾的效率。 </p><p>2.垃圾回收后可以更好的利用内存空间，存放大对象。 </p><p>3.尽可能减少 GC 次数</p><p>**OOM—内存溢出异常–**堆内存存满对象之后，还要往里面存放对象</p><p>说白了就是堆内存被挤爆了，但其实开发过程中没有遇到过这个异常，因为有垃圾回收机制（GC）</p><p>垃圾回收机制会扫描堆里的垃圾对象，把不需要的对象进行清除</p><p>不分区的缺点：</p><p>1.如果堆内存没有分区，那每次进行垃圾回收的时候，得从第一个对象搜索到最后一个对象，那这样的整个搜索，是非常浪费虚拟机的资源的</p><p>2.垃圾回收后的空间是不连续的，现在要放一个大对象，比如本来剩下的位置本来是够的，但是不连续就放不下去，这个问题叫<strong>内存的碎片化</strong>， <strong>存不进去会怎么办呢，它又会执行一遍垃圾回收</strong>，这时候又搜索一遍，效率又很低，还<strong>频繁垃圾回收</strong></p><h4 id="3-JVM-堆内存的划分"><a href="#3-JVM-堆内存的划分" class="headerlink" title="3 JVM 堆内存的划分"></a>3 JVM 堆内存的划分</h4><h5 id="老年代："><a href="#老年代：" class="headerlink" title="老年代："></a>老年代：</h5><p>对象会<strong>优先分配到新生代内存</strong>中，每次 GC 后没有回收的对象年龄加 1，年龄到 15 还没有被回收，对象会存放到老年代内存中；如果对象较大，超过新生代内存的一 半，对象也会存放到老年代区域。 </p><h5 id="新生代："><a href="#新生代：" class="headerlink" title="新生代："></a>新生代：</h5><p>为了减少young区垃圾回收后的空间碎片，新生代又分为Eden区和<strong>两个Survivor 区，且始终有一个 Suvivor 区保持闲置</strong>。对象会先存放到 Eden 区当中，Eden 区空间 满了之后会进行 young 区的垃圾回收，之后将 young 区所有存活的对象复制到闲置 的 Suvivor 区中，并清空 Eden 区和正在使用的 Survivor 区。</p><p><strong>总的来说就是，垃圾回收完之后，把剩下的都放在一个A篮子里，下次回收的时候，Eden又剩下的，放进B篮子，然后把A篮子的又放过去B篮子，所以一直保持Eden和一个Survivor区是空的，所以Eden空就可以往里面放大对象</strong></p><h4 id="4-YoungGC-和-OldGC"><a href="#4-YoungGC-和-OldGC" class="headerlink" title="4 YoungGC 和 OldGC"></a>4 YoungGC 和 OldGC</h4><h5 id="YoungGC"><a href="#YoungGC" class="headerlink" title="YoungGC"></a>YoungGC</h5><p>新生代区域的垃圾回收称之为 YoungGC，也叫 MinorGC，Eden 区满后会触发 YoungGC </p><h5 id="OldGC"><a href="#OldGC" class="headerlink" title="OldGC"></a>OldGC</h5><p>老年代区域的垃圾回收称之为 OldGC，也叫 MajorGC，OldGC 非常浪费性能， <strong>所以我们的 JVM 调优要尽可能减少 OldGC 的次数，</strong> OldGC 往往伴随着 YoungGC。 YoungGC+OldGC &#x3D; FullG</p><p>老年代可没有像新生代一样的，分区，为了避免产生碎片化的问题，就会进行一次整理和补齐，所以非常浪费性能</p><h4 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h4><h5 id="1-Survivor-区空间并不大，如果满了怎么办？"><a href="#1-Survivor-区空间并不大，如果满了怎么办？" class="headerlink" title="1.Survivor 区空间并不大，如果满了怎么办？"></a>1.Survivor 区空间并不大，如果满了怎么办？</h5><p>（1）一般情况下 GC 会回收 95%的对象，且超过 15 次 GC 的对象会存放到 old 去，所以 Survivor 区不容易满。 </p><p>（2）如果 Survivor 区满了，会触发<strong>担保机制，提前将对象存入 Old 区。</strong></p><h5 id="2-为什么需要-Survivor-区？"><a href="#2-为什么需要-Survivor-区？" class="headerlink" title="2.为什么需要 Survivor 区？"></a>2.为什么需要 Survivor 区？</h5><p>为了减少垃圾回收带来的空间碎片，空间碎片过多会频繁触发 YoungGC。 </p><h5 id="3-为什么需要两块-Survivor-区？"><a href="#3-为什么需要两块-Survivor-区？" class="headerlink" title="3.为什么需要两块 Survivor 区？"></a>3.为什么需要两块 Survivor 区？</h5><p>为了减少 Survivor  区的空间碎片。———-不能转来转去，Survivor  区也会又空间碎片，转来转去就补齐了空间碎片的位置</p><h4 id="5-JVM-运行监控工具-VisualVM"><a href="#5-JVM-运行监控工具-VisualVM" class="headerlink" title="5 JVM 运行监控工具 VisualVM"></a>5 JVM 运行监控工具 VisualVM</h4><p>打开 JAVA 安装目录&#x2F;bin&#x2F;jvisualvm.exe，安装 VisualGC 插件。 </p><p>注：JDK9 之后需自行下载该工具</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114171813411.png" alt="image-20221114171813411"></p><p>芜湖</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114172014762.png" alt="image-20221114172014762"></p><p>然后写了一个测试，死循环不断往堆里添加对象</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114172115754.png" alt="image-20221114172115754"></p><p>默认堆内存占计算机的四分之一，8G就会占2G，为了看到效果，改小堆内存</p><h6 id="修改堆内存大小的指令"><a href="#修改堆内存大小的指令" class="headerlink" title="修改堆内存大小的指令"></a>修改堆内存大小的指令</h6><p>-Xms10M -Xmx10</p><p>第一个是初始内存，第二个是最大内存</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114172334168.png" alt="image-20221114172334168"></p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114172347267.png" alt="image-20221114172347267"></p><p>现在看见Old区就越来越大，等满了之后就会OOM</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114172619572.png" alt="image-20221114172619572"></p><p>这就是老年代回收速度赶不上创建对象的速度了，也是对之前的一个验证</p><h2 id="五、垃圾回收机制"><a href="#五、垃圾回收机制" class="headerlink" title="五、垃圾回收机制"></a>五、垃圾回收机制</h2><p>堆内存模型设计是为了提高垃圾回收的效率，那么如何判断一个对象是垃圾？</p><h4 id="1-如何判断一个对象是垃圾"><a href="#1-如何判断一个对象是垃圾" class="headerlink" title="1 如何判断一个对象是垃圾"></a>1 如何判断一个对象是垃圾</h4><h5 id="引用计数法："><a href="#引用计数法：" class="headerlink" title="引用计数法："></a>引用计数法：</h5><p>如果要操作对象，必须通过引用来进行。如果一个对象没有任何引用与之关联，则说明 该对象基本不太可能在其他地方被使用到。那么这个对象就成为可被回收的对象了。这种方式实现简单，效率较高，但是它无法解决循环引用的问题，因此在 Java 中并没有采用这种 方式（Python 采用的是引用计数法）</p><p>循环引用</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114173302200.png" alt="image-20221114173302200"></p><p>使用引用计数法这两个对象是不能被回收，但其实是应该被回收的</p><h5 id="可达性分析：（用的这个）"><a href="#可达性分析：（用的这个）" class="headerlink" title="可达性分析：（用的这个）"></a>可达性分析：（用的这个）</h5><p> 以一个 GC Root 对象作为起点进行搜索，如果在 GC Roots 和对象之间没有可达路径， 则称该对象是不可达的。</p><h5 id="GC-ROOT-对象：💖"><a href="#GC-ROOT-对象：💖" class="headerlink" title="GC ROOT 对象：💖"></a>GC ROOT 对象：💖</h5><p>其实这里还少了几种，详情可以看深入理解Java虚拟机P70 </p><ul><li>栈帧中的本地变量表中引用的对象。</li><li>方法区中静态属性引用的对象。 </li><li>方法区中常量引用的对象。 </li><li>本地方法栈中引用的对象。</li></ul><p>顶部栈帧中的对象，那一定是正在使用的对象，那肯定就是重要的对象</p><p>只要是可达的，它就不回收，就是有用的对象能到达的对象，也是有用的</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114173617227.png" alt="image-20221114173617227"></p><p>然后刚刚循环依赖的代码执行完出栈之后，两个循环依赖的就是不可达的，就回收</p><p>第二类：静态中的东西，是类的变量，是整个程序都要用的东西，不把它回收</p><p>第三类：常量也是一直要使用的</p><p>最后就是本地方法栈的对象，存放的是非Java语言的，那也是不会回收的</p><p>一句话总结就是，正在使用的对象和正在使用的对象所关联的对象，都是不回收的</p><h4 id="2-垃圾回收算法"><a href="#2-垃圾回收算法" class="headerlink" title="2 垃圾回收算法"></a>2 垃圾回收算法</h4><h5 id="（1）标记——清除算法："><a href="#（1）标记——清除算法：" class="headerlink" title="（1）标记——清除算法："></a>（1）标记——清除算法：</h5><p>效率较低，有空间碎片。Old 区使用</p><p>扫描全部，进行可达性分析，不可达就标记，第二遍扫描再清理</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114174433704.png" alt="image-20221114174433704"></p><h5 id="（2）复制算法："><a href="#（2）复制算法：" class="headerlink" title="（2）复制算法："></a>（2）复制算法：</h5><p>空间碎片少，但会浪费空间。存活对象较少才会使用的算法。young 区使用的算法</p><p>就是垃圾回收后，剩下很少对象，使用这个算法就很好，不然剩下对象多，复制来复制去很浪费</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114174610337.png" alt="image-20221114174610337"></p><h5 id="（3）标记——整理算法："><a href="#（3）标记——整理算法：" class="headerlink" title="（3）标记——整理算法："></a>（3）标记——整理算法：</h5><p>空间碎片少，效率较低。Old 区使用的算法</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114175058222.png" alt="image-20221114175058222"></p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114175105364.png" alt="image-20221114175105364"></p><h4 id="3-垃圾收集器的评判标准"><a href="#3-垃圾收集器的评判标准" class="headerlink" title="3 垃圾收集器的评判标准"></a>3 垃圾收集器的评判标准</h4><p>垃圾收集器是对垃圾回收算法的实现，<strong>JVM 中提供了很多垃圾收集器，</strong>我们如何评判 一个垃圾收集器的好坏呢？</p><p><strong>垃圾收集器的执行效率</strong> &#x3D; 吞吐量 &#x2F; 停顿时间 </p><p><strong>吞吐量</strong> &#x3D; 用户代码执行时间&#x2F;(用户代码执行时间+停顿时间)</p><p>停顿时间，，扫描的时候，垃圾回收是要停顿的</p><p>根据注重点不同，有不同的垃圾收集器的类型</p><p>其实吞吐量和执行效率是相对的，鱼和熊掌不可兼得</p><h4 id="4-垃圾收集器的类型"><a href="#4-垃圾收集器的类型" class="headerlink" title="4 垃圾收集器的类型"></a>4 垃圾收集器的类型</h4><h5 id="串行收集器："><a href="#串行收集器：" class="headerlink" title="串行收集器："></a>串行收集器：</h5><p>只有一个垃圾回收线程，在垃圾回收时暂停用户代码线程，如 Serial 和 Serial Old 收集器</p><p>JDK1.3的时候用，都已经过时20年了</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114184935680.png" alt="image-20221114184935680"></p><h5 id="并行收集器"><a href="#并行收集器" class="headerlink" title="并行收集器"></a>并行收集器</h5><p>吞吐量优先，多个垃圾收集器线程共同工作, 尽快完成垃圾收集。如 ParNew， Parallel Scanvenge, Parallel Old 收集器</p><p>前两个是针对young区的收集器，最后一个Parallel Old是针对old区的</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114185044610.png" alt="image-20221114185044610"></p><h5 id="并发收集器–主流"><a href="#并发收集器–主流" class="headerlink" title="并发收集器–主流"></a>并发收集器–主流</h5><p>停顿时间优先，用户线程和垃圾回收线程一同工作，用户代码线程也会完全停止一 小段时间，如 CMS，G1 收集器。</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114185227309.png" alt="image-20221114185227309"></p><p>清理耗的时间更多，但是清理的时候已经不影响应用的执行了</p><p>但是这个标记不是特别精准</p><h4 id="5-CMS-收集器"><a href="#5-CMS-收集器" class="headerlink" title="5 CMS 收集器"></a>5 CMS 收集器</h4><p>CMS（concurrent mark sweep，并发标记扫描）收集器是并发收集器，是基于<strong>标记 ——清理</strong>的算法进行垃圾回收，用于 OldGC</p><p>优点：并发收集、低停顿 </p><p>缺点：会产生大量空间碎片，停顿时间虽然短但是不可控。</p><h5 id="问：CMS-收集器为什么不进行并发的初始标记？"><a href="#问：CMS-收集器为什么不进行并发的初始标记？" class="headerlink" title="问：CMS 收集器为什么不进行并发的初始标记？"></a>问：CMS 收集器为什么不进行并发的初始标记？</h5><p>因为初始标记速度很快，不值得多开线程，开线程也是需要耗费资源的。</p><h4 id="6-G1-收集器–最主流用的最多"><a href="#6-G1-收集器–最主流用的最多" class="headerlink" title="6 G1 收集器–最主流用的最多"></a>6 G1 收集器–最主流用的最多</h4><p>G1（garbage first，垃圾优先）收集器是并发收集器，从 JDK1.7 开始支持，能进行 OldGC 和 YoungGC。Old 区采用<strong>标记整理</strong>算法，Young 区采用复制算法</p><p>G1 收集器没有固定的 Old、Young、Eden、Survivor 区，而是将内存分为一个个大 小相等的 Region（格子，1Mb~32Mb)。每次垃圾回收后<strong>，Region 的用途可以发生改变</strong>， 提高了内存的灵活性和利用率。</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114185738033.png" alt="image-20221114185738033"></p><p>G1 收集器可以根据开发者设置的参数，停顿时间的期望值，<strong>优先筛选回收存活的对象比较少，垃圾对象比较大的区域</strong> </p><p>用更少的时间去腾出更大的区域</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221114190040784.png" alt="image-20221114190040784"></p><h4 id="7-ZGC-收集器"><a href="#7-ZGC-收集器" class="headerlink" title="7 ZGC 收集器"></a>7 ZGC 收集器</h4><p>ZGC 从 JDK11 开始支持，目前还是一个实验性版本，原理类似 G1。是目前<strong>收集效率最高</strong>的垃圾收集器，平均暂停时间为 0.05 毫秒</p><h4 id="8-如何选择垃圾收集器？"><a href="#8-如何选择垃圾收集器？" class="headerlink" title="8 如何选择垃圾收集器？"></a>8 如何选择垃圾收集器？</h4><ul><li>优先让服务器自己来选择 </li><li>如果内存小于 100M，使用串行收集器 </li><li>如果服务器是单核，并且没有停顿时间要求，使用串行收集器 </li><li>如果允许停顿时间超过 1 秒，选择并行收集器 </li><li>如果停顿时间不能超过 1 秒，使用并发收集器</li></ul><h2 id="六、JVM-参数设置"><a href="#六、JVM-参数设置" class="headerlink" title="六、JVM 参数设置"></a>六、JVM 参数设置</h2><h4 id="1-JVM-参数设置方式"><a href="#1-JVM-参数设置方式" class="headerlink" title="1 JVM 参数设置方式"></a>1 JVM 参数设置方式</h4><p>Intellij idea：在运行设置的 VM Option 中设置。 </p><p>tomcat：进入 Tomcat 的 bin 目录下，打开文件 catalina.bat&#x2F;catalina.sh，修改如下参数。</p><pre><code>set &quot;JAVA_OPTS=参数&quot;</code></pre><h4 id="2-JVM-参数类型"><a href="#2-JVM-参数类型" class="headerlink" title="2 JVM 参数类型"></a>2 JVM 参数类型</h4><p>（1）标准参数：不随 jdk 版本的变化而变化的参数，如：-version </p><p>（2）-X 参数：不能保证所有的 JVM 都支持。</p><p>​             如：-Xcomp：使用即时编译器执行字节码文件 </p><p>​                    -Xint：使用解释器执行字节码文件</p><p>​                    -Xmixed：混合模式，先使用解释器，即时编译器编译好后执行机器指令。 </p><p>（3）-XX 参数：不能保证所有的 JVM 都支持。 </p><p>​            A. Boolean 类型参数： </p><p>​                    -XX:+UseG1GC：使用 G1 收集器 </p><p>​                    -XX:-UseG1GC：不使用 G1 收集器 </p><p>​            B. Key-Value 类型参数：</p><p>​                     -XX:MaxTenuringThreshold&#x3D;15：对象年龄达到 15 就会进入老年代</p><h4 id="3-常用参数"><a href="#3-常用参数" class="headerlink" title="3 常用参数"></a>3 常用参数</h4><p>对着PDF手打吧</p><table><thead><tr><th align="center">参数</th><th align="left">含义</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">-XX:CICompilierCount&#x3D;3</td><td align="left">最大并行编译数</td><td align="center">如果设置大于1，虽然编译速度会提高，但是同样影响系统稳定性，会增加JVM崩溃的可能</td></tr><tr><td align="center">-XX:InitialHeapSize&#x3D;100M</td><td align="left">初始化堆大小</td><td align="center">简写-Xms100M</td></tr><tr><td align="center">-XX:MaxHeapSize</td><td align="left">最大堆大小</td><td align="center">简写-Xmx100M</td></tr><tr><td align="center">-XX:NewSize</td><td align="left">设置年轻代大小</td><td align="center"></td></tr><tr><td align="center">-XX:MaxNewSize</td><td align="left">年轻代最大大小</td><td align="center"></td></tr><tr><td align="center">-XX:OldSize</td><td align="left">设置老年代大小</td><td align="center"></td></tr><tr><td align="center">-XX:MetaspaceSize</td><td align="left">设置方法区大小（元空间）</td><td align="center"></td></tr><tr><td align="center">-XX:MaxMetaspaceSize</td><td align="left">方法区最大大小</td><td align="center"></td></tr><tr><td align="center">-XX:+UseParallelGC</td><td align="left">使用ParallelGC</td><td align="center">新生代，吞吐量优先</td></tr><tr><td align="center">-XX:+UseParallelOldGC</td><td align="left">使用ParallelOldGC</td><td align="center">老年代，吞吐量优先</td></tr><tr><td align="center">-XX:+UseConcMarkSweepGC</td><td align="left">使用CMS</td><td align="center">老年代，停顿时间优先</td></tr><tr><td align="center">-XX:UseG1GC</td><td align="left">使用G1GC</td><td align="center">新生代、老年代，停顿时间优先</td></tr><tr><td align="center">-XX:NewRatio</td><td align="left">新老生代的比值</td><td align="center">比如-XX:NewRatio&#x3D;4，则表示新生代：老年代&#x3D;1：4，也就是新生代占整个堆内存的1&#x2F;5</td></tr><tr><td align="center">-XX:SurvivorRatio</td><td align="left">两个S区和Eden区的比值</td><td align="center">比如-XX:SurvivorRatio&#x3D;8，也就是（S0+S1）：Eden&#x3D;2：8，也就是一个S占新生代的1&#x2F;10</td></tr><tr><td align="center">-XX:+HeapDumpOnOutOfMemoryError</td><td align="left">启动顿内存溢出打印</td><td align="center">当JVM发生堆内存溢出时，也就是OOM，自动生成dump文件</td></tr><tr><td align="center">-XX:HeapDumpPath</td><td align="left">指定堆内存溢出打印目录</td><td align="center">表示在当前目录生成一个heap.hprof文件</td></tr><tr><td align="center">-XX:PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xloggc:g1.log</td><td align="left">打印GC日志</td><td align="center"></td></tr><tr><td align="center">-Xss128k</td><td align="left">设置每个线程的堆栈大小</td><td align="center">经验值是3000-5000最佳</td></tr><tr><td align="center">-XX:MaxTenuringThreshold&#x3D;6</td><td align="left">提升老年代的最大临界值</td><td align="center">默认15</td></tr><tr><td align="center">-XX:InitatingHeapOccupancyPercent</td><td align="left">启动并发GC周期时堆内存使用占比</td><td align="center">G1之类的垃圾收集器用它来触发GC周期，基于整个堆的使用率，而不只是某一代内存的使用比，值为0标识一直执行GC循环，默认45</td></tr><tr><td align="center">-XX:G1HeapWastePercent</td><td align="left">允许浪费堆空间的占比</td><td align="center">默认10% ，如果并发标记可回收的空间小于10%，则不会触发MixedGC</td></tr><tr><td align="center">-XXMaxGCPauseMills&#x3D;200ms</td><td align="left">G1最大停顿时间</td><td align="center">暂停时间不能太小，太小会导致G1跟不上垃圾产生的速度，最终退化为Full GC，所以对这个参数的调优是一个持续过程，逐步调整到最佳状态</td></tr><tr><td align="center">-XX:ConcGCThreads&#x3D;n</td><td align="left">并发垃圾收集器使用的线程数量</td><td align="center">默认值随JVM运行平台不同而不同</td></tr><tr><td align="center">-XX:G1MixedGCLiveThresholdPercent&#x3D;65</td><td align="left">混合垃圾回收周期中要包括的旧区域设置占用率阈值</td><td align="center">默认占用率65%</td></tr><tr><td align="center">-XX:G1MixedGCCountTarget&#x3D;8</td><td align="left">设置标记周期完成后，堆存活数据上限为G1MixedGCLiveThresholdPercent的旧区域执行混合垃圾回收的目标次数</td><td align="center">默认8次，混合回收的目标是要控制在此目标次数以内</td></tr><tr><td align="center">-XX:G1OldCSetRegionThresholdPercent&#x3D;1</td><td align="left">描述Mixed GC时，Old Region被加入到Cse中</td><td align="center">默认，G1只把10%的Old Region加入到Cset中</td></tr></tbody></table><h2 id="七、JVM-常用命令和常用工具"><a href="#七、JVM-常用命令和常用工具" class="headerlink" title="七、JVM 常用命令和常用工具"></a>七、JVM 常用命令和常用工具</h2><h4 id="1-JVM-常用命令"><a href="#1-JVM-常用命令" class="headerlink" title="1 JVM 常用命令"></a>1 JVM 常用命令</h4><h5 id="jps：查看当前执行的所有-JAVA-进程"><a href="#jps：查看当前执行的所有-JAVA-进程" class="headerlink" title="jps：查看当前执行的所有 JAVA 进程"></a>jps：查看当前执行的所有 JAVA 进程</h5><h5 id="jinfo：实时查看-JVM-参数"><a href="#jinfo：实时查看-JVM-参数" class="headerlink" title="jinfo：实时查看 JVM 参数"></a>jinfo：实时查看 JVM 参数</h5><p>jinfo -flag InitialHeapSize PID：JAVA 进程堆内存</p><p>jinfo -flag UseG1GC PID：JAVA 进程是否使用 G1GC </p><p>jinfo -flag UseParallelGC PID：JAVA 进程是否使用 Parallel</p><p>减号就表示没有使用</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115095141255.png" alt="image-20221115095141255"></p><h5 id="jstat：虚拟机性能信息"><a href="#jstat：虚拟机性能信息" class="headerlink" title="jstat：虚拟机性能信息"></a>jstat：虚拟机性能信息</h5><p>jstat -class PID 1000：每秒查看一次虚拟机中类加载信息</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115095326825.png" alt="image-20221115095326825"></p><h5 id="jmap：打印快照"><a href="#jmap：打印快照" class="headerlink" title="jmap：打印快照"></a>jmap：打印快照</h5><p>jmap -heap PID：查看堆存储快照 </p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115095632363.png" alt="image-20221115095632363"></p><p>jmap -dump:format&#x3D;b,file&#x3D;heap.hprof PID：在出现内存溢出异常时，将堆内存的信息下载到文件中</p><p>运行后就会生成heap.hprof文件，但是用notepad都打不开，需要使用工具</p><p>就是如果已经出现内存溢出异常的时候，这个Java程序就已经停掉了，停掉之后就没有PID了，没有PID就用不了这个命令</p><p>正常是怎么做的：就是下面</p><h4 id="2-JVM-常用工具"><a href="#2-JVM-常用工具" class="headerlink" title="2 JVM 常用工具"></a>2 JVM 常用工具</h4><p>一般情况下，我们会让项目在发生 OOM 异常时自动下载堆内存信息，进行错误的排 查。此时我们需要给 JVM 配置如下代码：</p><pre><code>-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=heap.hprof</code></pre><h5 id="JVM-堆内存文件查看工具："><a href="#JVM-堆内存文件查看工具：" class="headerlink" title="JVM 堆内存文件查看工具："></a>JVM 堆内存文件查看工具：</h5><p><strong>MemoryAnalyzer</strong>（Mat）、PerfMa</p><p>加了之后，溢出之后就会自动在根目录生成文件</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115101209379.png" alt="image-20221115101209379"></p><p>解压之后运行打开，然后用它打开heap.hprof文件就行</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115101331956.png" alt="image-20221115101331956"></p><p>那如何来找哪个对象太多造成内存溢出呢？</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115101415394.png" alt="image-20221115101415394"></p><p>然后就可以看见了，六万多个Person对象</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115101440339.png" alt="image-20221115101440339"></p><p>如果项目很大，多的对象很多，就可以让它帮我们分析</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115101602259.png" alt="image-20221115101602259"></p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115101700335.png" alt="image-20221115101700335"></p><p>这个工具其实还有很多功能，可以找到每一个对象对应的GC Root是什么</p><p>看英文就知道，就是最大最多的对象问什么一直或者没有被GC掉</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115101825928.png" alt="image-20221115101825928"></p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115102003710.png" alt="image-20221115102003710"></p><p>然后还有其他工具，这个就是英文的，用<strong>PerfMa</strong>就是中文的，需要注册</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115102200912.png" alt="image-20221115102200912"></p><p>类视图<img src="/2022/11/16/jvm-bi-ji/image-20221115102310483.png" alt="image-20221115102310483"></p><p>功能还是很强大的</p><h4 id="如何解决OOM异常？"><a href="#如何解决OOM异常？" class="headerlink" title="如何解决OOM异常？"></a>如何解决OOM异常？</h4><p>给JVM配置一下，让他出现OOM的时候自动下载内存信息文件，然后用MAT或者PerfMa查看</p><p>如果我们要进行垃圾回收调优，首先需要将 GC 信息打印出来，此时我们需要给 JVM 配置如下代码：</p><pre><code>-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xloggc:gc.log</code></pre><p>生成的文件时可以直接打开查看的</p><h5 id="垃圾收集器-log-文件查看工具："><a href="#垃圾收集器-log-文件查看工具：" class="headerlink" title="垃圾收集器 log 文件查看工具："></a>垃圾收集器 log 文件查看工具：</h5><p> GCViewer</p><p>运行 GCViewer：输入命令 java -jar gcviewer-1.36-SNAPSHOT.jar</p><p>直接使用java -jar 运行就行，然后用它去打开log文件</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115103112088.png" alt="image-20221115103112088"></p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115103236079.png" alt="image-20221115103236079"></p><p>就是我们每次对GC进行调优的时候，用这个工具来帮助我们分析</p><p>然后还有一个停顿次数，这个也是越少越好的</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115103401780.png" alt="image-20221115103401780"></p><h5 id="JVM-监控工具："><a href="#JVM-监控工具：" class="headerlink" title="JVM 监控工具："></a>JVM 监控工具：</h5><p>JVisualVM、Jconsole</p><p>这两个都是JDK自带的</p><p>VisualVM 的性能分析功能甚至比起 JProfiler、YourKit 等专业且收费的 Profiling 工具都不会逊色多少，而且VisualVM 还有一个很大的优点：不需要被监视的程序基于特殊 Agent 运行，因此他对应用程序的实际性能的影响很小，使得他可以直接应用在生产环境中。</p><p>一开始就具备了插件扩展功能的特性</p><p>平常看看这个表就可以了，一般没什么问题</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115103618350.png" alt="image-20221115103618350"></p><p>然后这两个都是可以进行一个远程连接的</p><h2 id="八、-垃圾收集器调优"><a href="#八、-垃圾收集器调优" class="headerlink" title="八、 垃圾收集器调优"></a>八、 垃圾收集器调优</h2><p>默认用的就ParallelGC</p><h4 id="1-对比各个垃圾收集器的指标"><a href="#1-对比各个垃圾收集器的指标" class="headerlink" title="1 对比各个垃圾收集器的指标"></a>1 对比各个垃圾收集器的指标</h4><pre><code>-XX:+UseConcMarkSweepGC：使用 CMSGC-XX:+UseG1GC：使用 G1GC</code></pre><p>建立一个springboot空项目来对比一下</p><p>默认的就直接打印日志就行</p><p>CMS</p><p><strong><img src="/2022/11/16/jvm-bi-ji/image-20221115111305283.png" alt="image-20221115111305283"></strong></p><p>但是打开文件之后，你会发现还会有一个ParNewGC</p><p>怎么回事，因为当时学的时候说过，CMS就只是用于老年代的GC，所有要再搭配一个</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115111435409.png" alt="image-20221115111435409"></p><p>G1</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115111651538.png" alt="image-20221115111651538"></p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115111815305.png" alt="image-20221115111815305"></p><p>那后面就针对这个G1GC进行调优</p><h4 id="2-G1GC"><a href="#2-G1GC" class="headerlink" title="2 G1GC"></a>2 G1GC</h4><p>就是原来30M的内粗，现在改成500M</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115112059503.png" alt="image-20221115112059503"></p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115112108560.png" alt="image-20221115112108560"></p><p>换句话说，就是垃圾桶大了，然后倒垃圾要更久</p><p>然后项目经理过来说，10ms的停顿时间还是有点太长了，能不能压到10ms以下</p><p>就是设置了之后，它每次都会尽量往5ms一下压，但是不能保证每次都小于5ms</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115112422734.png" alt="image-20221115112422734"></p><p>其实就是不断调MaxGCPauseMillis去达到要求</p><h4 id="3-G1GC-调优指南"><a href="#3-G1GC-调优指南" class="headerlink" title="3 G1GC 调优指南"></a>3 G1GC 调优指南</h4><ul><li>不要手动设置新生代和老年代的大小，只设置堆的大小。 （因为G1的新生代老年代位置不固定）</li><li>不断调优暂停时间目标 <ul><li>一般情况设置到 100ms 或者 200ms 都是可以的，但如果设置成 50ms 就不太合 理。暂停时间太短，会导致 GC 跟不上垃圾产生的速度。</li></ul></li><li>适当增加堆内存大小</li></ul><h2 id="九、JVM-调优思路"><a href="#九、JVM-调优思路" class="headerlink" title="九、JVM 调优思路"></a>九、JVM 调优思路</h2><h4 id="1-高并发环境下如何配置堆和垃圾回收器？"><a href="#1-高并发环境下如何配置堆和垃圾回收器？" class="headerlink" title="1 高并发环境下如何配置堆和垃圾回收器？"></a>1 高并发环境下如何配置堆和垃圾回收器？</h4><p>之前不是说不要手动调整堆内存设置young和old，但是特殊情况才占就行，比如下面的一分钟</p><p>但是这个计算我就没看懂，young占JVM三分一—-1.3G没问题，但是old区怎么就算成young的百分之80&#x3D;1G</p><p>说是young还有两个s，所以eden就是1G</p><p>OK，，其实算的没有问题</p><p>说的是老年代一般占66%，新生代三分一</p><p><img src="/2022/11/16/jvm-bi-ji/image-20221115113715231.png" alt="image-20221115113715231"></p><p>不这么调整的话不是还得买服务器</p><h4 id="2-生产环境-JVM-问题的排查"><a href="#2-生产环境-JVM-问题的排查" class="headerlink" title="2 生产环境 JVM 问题的排查"></a>2 生产环境 JVM 问题的排查</h4><p><img src="/2022/11/16/jvm-bi-ji/image-20221115114255043.png" alt="image-20221115114255043"></p><h4 id="3-常见面试题"><a href="#3-常见面试题" class="headerlink" title="3 常见面试题"></a>3 常见面试题</h4><h5 id="OOM产生原因？"><a href="#OOM产生原因？" class="headerlink" title="OOM产生原因？"></a>OOM产生原因？</h5><ul><li>方法区无法满足新的内存分配需求</li><li>堆没有内存完成实例分配，并且堆也无法再扩展时</li><li>常量池无法申请到内存</li><li>设置参数忽略直接内存，各内存区域总和大于物理内存限制，动态扩展时OOM</li></ul><h5 id="内存泄漏和内存溢出是一样的概念吗"><a href="#内存泄漏和内存溢出是一样的概念吗" class="headerlink" title="内存泄漏和内存溢出是一样的概念吗?"></a>内存泄漏和内存溢出是一样的概念吗?</h5><p> 不一样，内存泄漏指不再使用的对象无法得到及时的回收，持续占用内存空间，造成内存空间的浪费。内存溢出指程序运行要用到的内存大于能提供的最大内存。内存泄漏很容易导致内存溢出，内存溢出不一定是内存泄漏导致的。 </p><h5 id="GC-Root-不可达的对象一定会被回收吗？"><a href="#GC-Root-不可达的对象一定会被回收吗？" class="headerlink" title="GC Root 不可达的对象一定会被回收吗？"></a>GC Root 不可达的对象一定会被回收吗？</h5><p>不一定，不可达的对象也不是非死不可的，G1 收集器最终就会筛选要回收的对象。</p><h5 id="方法区中的类会被回收吗"><a href="#方法区中的类会被回收吗" class="headerlink" title="方法区中的类会被回收吗?"></a>方法区中的类会被回收吗?</h5><p>有可能。需要满足以下三个条件：（1）该类的所有的实例都已经被回收了。（2）该 类的 ClassLoader 已经被回收了。（3）java.lang.class 对象没有任何地方使用</p><h5 id="CMS-和-G1-的区别"><a href="#CMS-和-G1-的区别" class="headerlink" title="CMS 和 G1 的区别"></a>CMS 和 G1 的区别</h5><p>cms 只能适用于老年代，g1 可以用于老年代和新生代。 cms 使用了标记——清除算法，会产生大量碎片，g1 使用标记——整理算法，减 少了碎片的产生。 g1 更加灵活，它将内存分为了一块块 region，并且停顿时间可控。</p><h1 id="JavaGuide"><a href="#JavaGuide" class="headerlink" title="JavaGuide"></a>JavaGuide</h1><h1 id="内存区域详解"><a href="#内存区域详解" class="headerlink" title="内存区域详解"></a>内存区域详解</h1><h3 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h3><p>Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有用于存放编译期生成的各种字面量（Literal）和符号引用（Symbolic Reference）的 <strong>常量池表(Constant Pool Table)</strong> 。</p><p>字面量是源代码中的固定值的表示法，即通过字面我们就能知道其值的含义。字面量包括整数、浮点数和字符串字面量，符号引用包括类符号引用、字段符号引用、方法符号引用和接口方法符号引用。</p><p>常量池表会在类加载后存放到方法区的运行时常量池中。</p><p>运行时常量池的功能类似于传统编程语言的符号表，尽管它包含了比典型符号表更广泛的数据。</p><p>既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 <code>OutOfMemoryError</code> 错误。</p><h3 id="字符串常量池"><a href="#字符串常量池" class="headerlink" title="# 字符串常量池"></a><a href="#%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0">#</a> 字符串常量池</h3><p><strong>字符串常量池</strong> 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。</p><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 在堆中创建字符串对象”ab“</span><span class="token comment" spellcheck="true">// 将字符串对象”ab“的引用保存在字符串常量池中</span>String aa <span class="token operator">=</span> <span class="token string">"ab"</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 直接返回字符串常量池中字符串对象”ab“的引用</span>String bb <span class="token operator">=</span> <span class="token string">"ab"</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>aa<span class="token operator">==</span>bb<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// true</span></code></pre><p>HotSpot 虚拟机中字符串常量池的实现是 <code>src/hotspot/share/classfile/stringTable.cpp</code> ,<code>StringTable</code> 本质上就是一个<code>HashSet&lt;String&gt;</code> ,容量为 <code>StringTableSize</code>（可以通过 <code>-XX:StringTableSize</code> 参数来设置）。</p><p><strong><code>StringTable</code> 中保存的是字符串对象的引用，字符串对象的引用指向堆中的字符串对象。</strong></p><p>JDK1.7 之前，字符串常量池存放在永久代。JDK1.7 字符串常量池和静态变量从永久代移动了 Java 堆中。</p><h3 id="对象的创建"><a href="#对象的创建" class="headerlink" title="对象的创建"></a>对象的创建</h3><p>Java 对象的创建过程我建议最好是能默写出来，并且要掌握每一步在做什么。</p><h4 id="Step1-类加载检查"><a href="#Step1-类加载检查" class="headerlink" title="# Step1:类加载检查"></a><a href="#step1-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%A3%80%E6%9F%A5">#</a> Step1:类加载检查</h4><p>虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。</p><h4 id="Step2-分配内存"><a href="#Step2-分配内存" class="headerlink" title="# Step2:分配内存"></a><a href="#step2-%E5%88%86%E9%85%8D%E5%86%85%E5%AD%98">#</a> Step2:分配内存</h4><p>在<strong>类加载检查</strong>通过后，接下来虚拟机将为新生对象<strong>分配内存</strong>。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。<strong>分配方式</strong>有 <strong>“指针碰撞”</strong> 和 <strong>“空闲列表”</strong> 两种，<strong>选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定</strong>。</p><p><strong>内存分配的两种方式</strong> （补充内容，需要掌握）：</p><ul><li>指针碰撞 ： <ul><li>适用场合 ：堆内存规整（即没有内存碎片）的情况下。</li><li>原理 ：用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可。</li><li>使用该分配方式的 GC 收集器：Serial, ParNew</li></ul></li><li>空闲列表 ： <ul><li>适用场合 ： 堆内存不规整的情况下。</li><li>原理 ：虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录。</li><li>使用该分配方式的 GC 收集器：CMS</li></ul></li></ul><p>选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”），值得注意的是，复制算法内存也是规整的。</p><p><strong>内存分配并发问题（补充内容，需要掌握）</strong></p><p>在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：</p><ul><li><strong>CAS+失败重试：</strong> CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。<strong>虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。</strong></li><li><strong>TLAB：</strong> 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配</li></ul><h4 id="Step3-初始化零值"><a href="#Step3-初始化零值" class="headerlink" title="# Step3:初始化零值"></a><a href="#step3-%E5%88%9D%E5%A7%8B%E5%8C%96%E9%9B%B6%E5%80%BC">#</a> Step3:初始化零值</h4><p>内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。</p><h4 id="Step4-设置对象头"><a href="#Step4-设置对象头" class="headerlink" title="# Step4:设置对象头"></a><a href="#step4-%E8%AE%BE%E7%BD%AE%E5%AF%B9%E8%B1%A1%E5%A4%B4">#</a> Step4:设置对象头</h4><p>初始化零值完成之后，<strong>虚拟机要对对象进行必要的设置</strong>，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 <strong>这些信息存放在对象头中。</strong> 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。</p><h4 id="Step5-执行-init-方法"><a href="#Step5-执行-init-方法" class="headerlink" title="# Step5:执行 init 方法"></a><a href="#step5-%E6%89%A7%E8%A1%8C-init-%E6%96%B9%E6%B3%95">#</a> Step5:执行 init 方法</h4><p>在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，<code>&lt;init&gt;</code> 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 <code>&lt;init&gt;</code> 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来</p><h3 id="对象的访问定位"><a href="#对象的访问定位" class="headerlink" title="对象的访问定位"></a>对象的访问定位</h3><p>建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有：<strong>使用句柄</strong>、<strong>直接指针</strong>。</p><h4 id="句柄"><a href="#句柄" class="headerlink" title="# 句柄"></a><a href="#%E5%8F%A5%E6%9F%84">#</a> 句柄</h4><p>如果使用句柄的话，那么 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息。</p><p><img src="/2022/11/16/jvm-bi-ji/access-location-of-object-handle.png" alt="对象的访问定位-使用句柄"></p><h4 id="直接指针"><a href="#直接指针" class="headerlink" title="# 直接指针"></a><a href="#%E7%9B%B4%E6%8E%A5%E6%8C%87%E9%92%88">#</a> 直接指针</h4><p>如果使用直接指针访问，reference 中存储的直接就是对象的地址。</p><p><img src="/2022/11/16/jvm-bi-ji/access-location-of-object-handle-direct-pointer.png" alt="对象的访问定位-直接指针"></p><p>这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。</p><p>HotSpot 虚拟机主要使用的就是这种方式来进行对象访问</p><h1 id="JVM垃圾回收详解"><a href="#JVM垃圾回收详解" class="headerlink" title="JVM垃圾回收详解"></a>JVM垃圾回收详解</h1><p>常见面试题 ：</p><ul><li>如何判断对象是否死亡（两种方法）。</li><li>简单的介绍一下强引用、软引用、弱引用、虚引用（虚引用与软引用和弱引用的区别、使用软引用能带来的好处）。</li><li>如何判断一个常量是废弃常量</li><li>如何判断一个类是无用的类</li><li>垃圾收集有哪些算法，各自的特点？</li><li>HotSpot 为什么要分为新生代和老年代？</li><li>常见的垃圾回收器有哪些？</li><li>介绍一下 CMS,G1 收集器。</li><li>Minor Gc 和 Full GC 有什么不同呢？</li></ul><p><strong>认晋升年龄并不都是 15，这个是要区分垃圾收集器的，CMS 就是 6</strong></p><p><strong>哪些对象可以作为 GC Roots 呢？</strong></p><ul><li>虚拟机栈(栈帧中的本地变量表)中引用的对象</li><li>本地方法栈(Native 方法)中引用的对象</li><li>方法区中类静态属性引用的对象</li><li>方法区中常量引用的对象</li><li>所有被同步锁持有的对象</li></ul><p><strong>对象可以被回收，就代表一定会被回收吗？</strong></p><p>即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 <code>finalize</code> 方法。当对象没有覆盖 <code>finalize</code> 方法，或 <code>finalize</code> 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。</p><p>被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。</p><h3 id="如何判断一个常量是废弃常量？"><a href="#如何判断一个常量是废弃常量？" class="headerlink" title="如何判断一个常量是废弃常量？"></a>如何判断一个常量是废弃常量？</h3><p>运行时常量池主要回收的是废弃的常量。那么，我们如何判断一个常量是废弃常量呢？</p><p>假如在字符串常量池中存在字符串 “abc”，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，”abc” 就会被系统清理出常量池了</p><h3 id="如何判断一个类是无用的类"><a href="#如何判断一个类是无用的类" class="headerlink" title="如何判断一个类是无用的类"></a>如何判断一个类是无用的类</h3><p>方法区主要回收的是无用的类</p><ul><li>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。</li><li>加载该类的 <code>ClassLoader</code> 已经被回收。</li><li>该类对应的 <code>java.lang.Class</code> 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</li></ul><p>虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。</p><h3 id="Parallel-Scavenge-收集器"><a href="#Parallel-Scavenge-收集器" class="headerlink" title="Parallel Scavenge 收集器"></a>Parallel Scavenge 收集器</h3><p><strong>Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）</strong></p><p><strong>新生代采用标记-复制算法，老年代采用标记-整理算法。</strong></p><p><strong>这是 JDK1.8 默认收集器</strong></p><p>JDK1.8 默认使用的是 Parallel Scavenge + Parallel Old，如果指定了-XX:+UseParallelGC 参数，则默认指定了-XX:+UseParallelOldGC，可以使用-XX:-UseParallelOldGC 来禁用该功能</p><h3 id="CMS-收集器"><a href="#CMS-收集器" class="headerlink" title="CMS 收集器"></a>CMS 收集器</h3><p><strong>CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。</strong></p><p><strong>CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。</strong></p><p>垃圾收集器来说更加复杂一些。整个过程分为四个步骤：</p><ul><li><strong>初始标记：</strong> 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；</li><li><strong>并发标记：</strong> 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。</li><li><strong>重新标记：</strong> 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短</li><li><strong>并发清除：</strong> 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。</li></ul><p>主要优点：<strong>并发收集、低停顿</strong>。但是它有下面三个明显的缺点：</p><ul><li><strong>对 CPU 资源敏感；</strong></li><li><strong>无法处理浮动垃圾；</strong></li><li><strong>它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。</strong></li></ul><h3 id="G1-收集器"><a href="#G1-收集器" class="headerlink" title="G1 收集器"></a>G1 收集器</h3><p><strong>G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)</strong> 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）</p><h1 id="类文件结构详解"><a href="#类文件结构详解" class="headerlink" title="类文件结构详解"></a>类文件结构详解</h1><h2 id="一-概述"><a href="#一-概述" class="headerlink" title="一 概述"></a>一 概述</h2><p>在 Java 中，JVM 可以理解的代码就叫做<code>字节码</code>（即扩展名为 <code>.class</code> 的文件），它不面向任何特定的处理器，只面向虚拟机。</p><p>可以说<code>.class</code>文件是不同的语言在 Java 虚拟机之间的重要桥梁，同时也是支持 Java 跨平台很重要的一个原因。</p><h2 id="二-Class-文件结构总结"><a href="#二-Class-文件结构总结" class="headerlink" title="二 Class 文件结构总结"></a>二 Class 文件结构总结</h2><p>根据 Java 虚拟机规范，Class 文件通过 <code>ClassFile</code> 定义，有点类似 C 语言的结构体。</p><p><code>ClassFile</code> 的结构如下：</p><pre class=" language-java"><code class="language-java">ClassFile <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    u4             magic<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//Class 文件的标志</span>    u2             minor_version<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 的小版本号</span>    u2             major_version<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 的大版本号</span>    u2             constant_pool_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//常量池的数量</span>    cp_info        constant_pool<span class="token punctuation">[</span>constant_pool_count<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//常量池</span>    u2             access_flags<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 的访问标记</span>    u2             this_class<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//当前类</span>    u2             super_class<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//父类</span>    u2             interfaces_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//接口</span>    u2             interfaces<span class="token punctuation">[</span>interfaces_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//一个类可以实现多个接口</span>    u2             fields_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 文件的字段属性</span>    field_info     fields<span class="token punctuation">[</span>fields_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//一个类可以有多个字段</span>    u2             methods_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 文件的方法数量</span>    method_info    methods<span class="token punctuation">[</span>methods_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//一个类可以有个多个方法</span>    u2             attributes_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//此类的属性表中的属性数</span>    attribute_info attributes<span class="token punctuation">[</span>attributes_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//属性表集合</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p>IDEA 插件 <code>jclasslib</code> 查看的，你可以更直观看到 Class 文件结构。</p><p><img src="/2022/11/16/jvm-bi-ji/image-20210401170711475.png" alt="img"></p><p>使用 <code>jclasslib</code> 不光可以直观地查看某个类对应的字节码文件，还可以查看类的基本信息、常量池、接口、属性、函数等信息。</p><h3 id="2-1-魔数（Magic-Number）"><a href="#2-1-魔数（Magic-Number）" class="headerlink" title="2.1 魔数（Magic Number）"></a>2.1 魔数（Magic Number）</h3><pre class=" language-java"><code class="language-java">    u4             magic<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//Class 文件的标志</span></code></pre><p>每个 Class 文件的头 4 个字节称为魔数（Magic Number）,它的唯一作用是<strong>确定这个文件是否为一个能被虚拟机接收的 Class 文件</strong>。</p><h3 id="2-2-Class-文件版本号（Minor-amp-Major-Version）"><a href="#2-2-Class-文件版本号（Minor-amp-Major-Version）" class="headerlink" title="2.2 Class 文件版本号（Minor&amp;Major Version）"></a>2.2 Class 文件版本号（Minor&amp;Major Version）</h3><pre class=" language-java"><code class="language-java">    u2             minor_version<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 的小版本号</span>    u2             major_version<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 的大版本号</span></code></pre><p>紧接着魔数的四个字节存储的是 Class 文件的版本号：第 5 和第 6 位是<strong>次版本号</strong>，第 7 和第 8 位是<strong>主版本号</strong>。</p><p>每当 Java 发布大版本（比如 Java 8，Java9）的时候，主版本号都会加 1。你可以使用 <code>javap -v</code> 命令来快速查看 Class 文件的版本号信息。</p><p>高版本的 Java 虚拟机可以执行低版本编译器生成的 Class 文件，但是低版本的 Java 虚拟机不能执行高版本编译器生成的 Class 文件。所以，我们在实际开发的时候要确保开发的的 JDK 版本和生产环境的 JDK 版本保持一致。</p><h3 id="2-3-常量池（Constant-Pool）"><a href="#2-3-常量池（Constant-Pool）" class="headerlink" title="2.3 常量池（Constant Pool）"></a>2.3 常量池（Constant Pool）</h3><pre class=" language-java"><code class="language-java">    u2             constant_pool_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//常量池的数量</span>    cp_info        constant_pool<span class="token punctuation">[</span>constant_pool_count<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//常量池</span></code></pre><p>紧接着主次版本号之后的是常量池，常量池的数量是 <code>constant_pool_count-1</code>（<strong>常量池计数器是从 1 开始计数的，将第 0 项常量空出来是有特殊考虑的，索引值为 0 代表“不引用任何一个常量池项”</strong>）。</p><p>常量池主要存放两大常量：字面量和符号引用。字面量比较接近于 Java 语言层面的的常量概念，如文本字符串、声明为 final 的常量值等。而符号引用则属于编译原理方面的概念。包括下面三类常量：</p><ul><li>类和接口的全限定名</li><li>字段的名称和描述符</li><li>方法的名称和描述符</li></ul><p>常量池中每一项常量都是一个表，这 14 种表有一个共同的特点：<strong>开始的第一位是一个 u1 类型的标志位 -tag 来标识常量的类型，代表当前这个常量属于哪种常量类型．</strong></p><table><thead><tr><th align="center">类型</th><th align="center">标志（tag）</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">CONSTANT_utf8_info</td><td align="center">1</td><td align="center">UTF-8 编码的字符串</td></tr><tr><td align="center">CONSTANT_Integer_info</td><td align="center">3</td><td align="center">整形字面量</td></tr><tr><td align="center">CONSTANT_Float_info</td><td align="center">4</td><td align="center">浮点型字面量</td></tr><tr><td align="center">CONSTANT_Long_info</td><td align="center">５</td><td align="center">长整型字面量</td></tr><tr><td align="center">CONSTANT_Double_info</td><td align="center">６</td><td align="center">双精度浮点型字面量</td></tr><tr><td align="center">CONSTANT_Class_info</td><td align="center">７</td><td align="center">类或接口的符号引用</td></tr><tr><td align="center">CONSTANT_String_info</td><td align="center">８</td><td align="center">字符串类型字面量</td></tr><tr><td align="center">CONSTANT_Fieldref_info</td><td align="center">９</td><td align="center">字段的符号引用</td></tr><tr><td align="center">CONSTANT_Methodref_info</td><td align="center">10</td><td align="center">类中方法的符号引用</td></tr><tr><td align="center">CONSTANT_InterfaceMethodref_info</td><td align="center">11</td><td align="center">接口中方法的符号引用</td></tr><tr><td align="center">CONSTANT_NameAndType_info</td><td align="center">12</td><td align="center">字段或方法的符号引用</td></tr><tr><td align="center">CONSTANT_MothodType_info</td><td align="center">16</td><td align="center">标志方法类型</td></tr><tr><td align="center">CONSTANT_MethodHandle_info</td><td align="center">15</td><td align="center">表示方法句柄</td></tr><tr><td align="center">CONSTANT_InvokeDynamic_info</td><td align="center">18</td><td align="center">表示一个动态方法调用点</td></tr></tbody></table><p><code>.class</code> 文件可以通过<code>javap -v class类名</code> 指令来看一下其常量池中的信息(<code>javap -v class类名-&gt; temp.txt</code> ：将结果输出到 temp.txt 文件)。</p><h3 id="2-4-访问标志-Access-Flags"><a href="#2-4-访问标志-Access-Flags" class="headerlink" title="# 2.4 访问标志(Access Flags)"></a><a href="#_2-4-%E8%AE%BF%E9%97%AE%E6%A0%87%E5%BF%97-access-flags">#</a> 2.4 访问标志(Access Flags)</h3><p>在常量池结束之后，紧接着的两个字节代表访问标志，这个标志用于识别一些类或者接口层次的访问信息，包括：这个 Class 是类还是接口，是否为 <code>public</code> 或者 <code>abstract</code> 类型，如果是类的话是否声明为 <code>final</code> 等等。</p><p>类访问和属性修饰符:</p><p><img src="/2022/11/16/jvm-bi-ji/%E8%AE%BF%E9%97%AE%E6%A0%87%E5%BF%97.png" alt="类访问和属性修饰符"></p><p>我们定义了一个 Employee 类</p><pre class=" language-java"><code class="language-java"><span class="token keyword">package</span> top<span class="token punctuation">.</span>snailclimb<span class="token punctuation">.</span>bean<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Employee</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>   <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p>通过<code>javap -v class类名</code> 指令来看一下类的访问标志。</p><p><img src="/2022/11/16/jvm-bi-ji/%E6%9F%A5%E7%9C%8B%E7%B1%BB%E7%9A%84%E8%AE%BF%E9%97%AE%E6%A0%87%E5%BF%97.png" alt="查看类的访问标志"></p><h3 id="2-5-当前类（This-Class）、父类（Super-Class）、接口（Interfaces）索引集合"><a href="#2-5-当前类（This-Class）、父类（Super-Class）、接口（Interfaces）索引集合" class="headerlink" title="# 2.5 当前类（This Class）、父类（Super Class）、接口（Interfaces）索引集合"></a><a href="#_2-5-%E5%BD%93%E5%89%8D%E7%B1%BB-this-class-%E3%80%81%E7%88%B6%E7%B1%BB-super-class-%E3%80%81%E6%8E%A5%E5%8F%A3-interfaces-%E7%B4%A2%E5%BC%95%E9%9B%86%E5%90%88">#</a> 2.5 当前类（This Class）、父类（Super Class）、接口（Interfaces）索引集合</h3><pre class=" language-java"><code class="language-java">    u2             this_class<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//当前类</span>    u2             super_class<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//父类</span>    u2             interfaces_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//接口</span>    u2             interfaces<span class="token punctuation">[</span>interfaces_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//一个类可以实现多个接口</span></code></pre><p>类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名，由于 Java 语言的单继承，所以父类索引只有一个，除了 <code>java.lang.Object</code> 之外，所有的 java 类都有父类，因此除了 <code>java.lang.Object</code> 外，所有 Java 类的父类索引都不为 0。</p><p>接口索引集合用来描述这个类实现了那些接口，这些被实现的接口将按 <code>implements</code> (如果这个类本身是接口的话则是<code>extends</code>) 后的接口顺序从左到右排列在接口索引集合中。</p><h3 id="2-6-字段表集合（Fields）"><a href="#2-6-字段表集合（Fields）" class="headerlink" title="# 2.6 字段表集合（Fields）"></a><a href="#_2-6-%E5%AD%97%E6%AE%B5%E8%A1%A8%E9%9B%86%E5%90%88-fields">#</a> 2.6 字段表集合（Fields）</h3><pre class=" language-java"><code class="language-java">    u2             fields_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 文件的字段的个数</span>    field_info     fields<span class="token punctuation">[</span>fields_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//一个类会可以有个字段</span></code></pre><p>字段表（field info）用于描述接口或类中声明的变量。字段包括类级变量以及实例变量，但不包括在方法内部声明的局部变量。</p><p><strong>field info(字段表) 的结构:</strong></p><p><img src="/2022/11/16/jvm-bi-ji/%E5%AD%97%E6%AE%B5%E8%A1%A8%E7%9A%84%E7%BB%93%E6%9E%84.png" alt="字段表的结构 "></p><ul><li><strong>access_flags:</strong> 字段的作用域（<code>public</code> ,<code>private</code>,<code>protected</code>修饰符），是实例变量还是类变量（<code>static</code>修饰符）,可否被序列化（transient 修饰符）,可变性（final）,可见性（volatile 修饰符，是否强制从主内存读写）。</li><li><strong>name_index:</strong> 对常量池的引用，表示的字段的名称；</li><li><strong>descriptor_index:</strong> 对常量池的引用，表示字段和方法的描述符；</li><li><strong>attributes_count:</strong> 一个字段还会拥有一些额外的属性，attributes_count 存放属性的个数；</li><li><strong>attributes[attributes_count]:</strong> 存放具体属性具体内容。</li></ul><p>上述这些信息中，各个修饰符都是布尔值，要么有某个修饰符，要么没有，很适合使用标志位来表示。而字段叫什么名字、字段被定义为什么数据类型这些都是无法固定的，只能引用常量池中常量来描述。</p><p><strong>字段的 access_flag 的取值:</strong></p><p><img src="/2022/11/16/jvm-bi-ji/image-20201031084342859.png" alt="字段的 access_flag 的取值"></p><h3 id="2-7-方法表集合（Methods）"><a href="#2-7-方法表集合（Methods）" class="headerlink" title="# 2.7 方法表集合（Methods）"></a><a href="#_2-7-%E6%96%B9%E6%B3%95%E8%A1%A8%E9%9B%86%E5%90%88-methods">#</a> 2.7 方法表集合（Methods）</h3><pre class=" language-java"><code class="language-java">    u2             methods_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Class 文件的方法的数量</span>    method_info    methods<span class="token punctuation">[</span>methods_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//一个类可以有个多个方法</span></code></pre><p>methods_count 表示方法的数量，而 method_info 表示方法表。</p><p>Class 文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方式。方法表的结构如同字段表一样，依次包括了访问标志、名称索引、描述符索引、属性表集合几项。</p><p><strong>method_info(方法表的) 结构:</strong></p><p><img src="/2022/11/16/jvm-bi-ji/%E6%96%B9%E6%B3%95%E8%A1%A8%E7%9A%84%E7%BB%93%E6%9E%84.png" alt="方法表的结构"></p><p><strong>方法表的 access_flag 取值：</strong></p><p><img src="/2022/11/16/jvm-bi-ji/image-20201031084248965.png" alt="方法表的 access_flag 取值"></p><p>注意：因为<code>volatile</code>修饰符和<code>transient</code>修饰符不可以修饰方法，所以方法表的访问标志中没有这两个对应的标志，但是增加了<code>synchronized</code>、<code>native</code>、<code>abstract</code>等关键字修饰方法，所以也就多了这些关键字对应的标志。</p><h3 id="2-8-属性表集合（Attributes）"><a href="#2-8-属性表集合（Attributes）" class="headerlink" title="# 2.8 属性表集合（Attributes）"></a><a href="#_2-8-%E5%B1%9E%E6%80%A7%E8%A1%A8%E9%9B%86%E5%90%88-attributes">#</a> 2.8 属性表集合（Attributes）</h3><pre class=" language-java"><code class="language-java">   u2             attributes_count<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//此类的属性表中的属性数</span>   attribute_info attributes<span class="token punctuation">[</span>attributes_count<span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//属性表集合</span></code></pre><p>在 Class 文件，字段表，方法表中都可以携带自己的属性表集合，以用于描述某些场景专有的信息。与 Class 文件中其它的数据项目要求的顺序、长度和内容不同，属性表集合的限制稍微宽松一些，不再要求各个属性表具有严格的顺序，并且只要不与已有的属性名重复，任何人实现的编译器都可以向属性表中写 入自己定义的属性信息，Java 虚拟机运行时会忽略掉它不认识的属性。</p><h1 id="类加载过程详解"><a href="#类加载过程详解" class="headerlink" title="类加载过程详解"></a>类加载过程详解</h1><h2 id="类的生命周期"><a href="#类的生命周期" class="headerlink" title="类的生命周期"></a>类的生命周期</h2><p>一个类的完整生命周期如下：</p><p><img src="/2022/11/16/jvm-bi-ji/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B-%E5%AE%8C%E5%96%84.png" alt="img"></p><h2 id="类加载过程"><a href="#类加载过程" class="headerlink" title="# 类加载过程"></a><a href="#%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B">#</a> 类加载过程</h2><p>Class 文件需要加载到虚拟机中之后才能运行和使用，那么虚拟机是如何加载这些 Class 文件呢？</p><p>系统加载 Class 类型的文件主要三步：<strong>加载-&gt;连接-&gt;初始化</strong>。连接过程又可分为三步：<strong>验证-&gt;准备-&gt;解析</strong>。</p><h3 id="加载"><a href="#加载" class="headerlink" title="# 加载"></a><a href="#%E5%8A%A0%E8%BD%BD">#</a> 加载</h3><p>类加载过程的第一步，主要完成下面 3 件事情：</p><ol><li>通过全类名获取定义此类的二进制字节流</li><li>将字节流所代表的静态存储结构转换为方法区的运行时数据结构</li><li>在内存中生成一个代表该类的 <code>Class</code> 对象，作为方法区这些数据的访问入口</li></ol><p>加载阶段和连接阶段的部分内容是交叉进行的，加载阶段尚未结束，连接阶段可能就已经开始了。</p><h3 id="验证"><a href="#验证" class="headerlink" title="#验证"></a><a href="https://javaguide.cn/java/jvm/class-loading-process.html#%E9%AA%8C%E8%AF%81">#</a>验证</h3><p><img src="/2022/11/16/jvm-bi-ji/%E9%AA%8C%E8%AF%81%E9%98%B6%E6%AE%B5.png" alt="验证阶段示意图"></p><h3 id="准备"><a href="#准备" class="headerlink" title="#准备"></a><a href="https://javaguide.cn/java/jvm/class-loading-process.html#%E5%87%86%E5%A4%87">#</a>准备</h3><p><strong>准备阶段是正式为类变量分配内存并设置类变量初始值的阶段</strong>，这些内存都将在方法区中分配。</p><p>这里所设置的初始值”通常情况”下是数据类型默认的零值（如 0、0L、null、false 等），比如我们定义了<code>public static int value=111</code> ，那么 value 变量在准备阶段的初始值就是 0 而不是 111（初始化阶段才会赋值）。特殊情况：比如给 value 变量加上了 final 关键字<code>public static final int value=111</code> ，那么准备阶段 value 的值就被赋值为 111。</p><h3 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h3><p>解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符 7 类符号引用进行。</p><p>符号引用就是一组符号来描述目标，可以是任何字面量。<strong>直接引用</strong>就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。</p><h3 id="初始化"><a href="#初始化" class="headerlink" title="#初始化"></a><a href="https://javaguide.cn/java/jvm/class-loading-process.html#%E5%88%9D%E5%A7%8B%E5%8C%96">#</a>初始化</h3><p>初始化阶段是执行初始化方法 <code>&lt;clinit&gt; ()</code>方法的过程，是类加载的最后一步，这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)。</p><p>说明： <code>&lt;clinit&gt; ()</code>方法是编译之后自动生成的。</p><p>对于<code>&lt;clinit&gt; ()</code> 方法的调用，虚拟机会自己确保其在多线程环境中的安全性。因为 <code>&lt;clinit&gt; ()</code> 方法是带锁线程安全，所以在多线程环境下进行类初始化的话可能会引起多个线程阻塞，并且这种阻塞很难被发现。</p><p>对于初始化阶段，虚拟机严格规范了有且只有 5 种情况下，必须对类进行初始化(只有主动去使用类才会初始化类)：</p><p>1.当遇到 <code>new</code> 、 <code>getstatic</code>、<code>putstatic</code> 或 <code>invokestatic</code> 这 4 条直接码指令时，比如 <code>new</code> 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。</p><p>2.使用 <code>java.lang.reflect</code> 包的方法对类进行反射调用时</p><p>3.初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。</p><p>4.当虚拟机启动时，用户需要定义一个要执行的主类 (包含 <code>main</code> 方法的那个类)，虚拟机会先初始化这个类。</p><h2 id="卸载"><a href="#卸载" class="headerlink" title="#卸载"></a><a href="https://javaguide.cn/java/jvm/class-loading-process.html#%E5%8D%B8%E8%BD%BD">#</a>卸载</h2><p>卸载类即该类的 Class 对象被 GC。</p><p>卸载类需要满足 3 个要求:</p><ol><li>该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象。</li><li>该类没有在其他任何地方被引用</li><li>该类的类加载器的实例已被 GC</li></ol><p>所以，在 JVM 生命周期内，由 jvm 自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。</p><p>只要想通一点就好了，jdk 自带的 <code>BootstrapClassLoader</code>, <code>ExtClassLoader</code>, <code>AppClassLoader</code> 负责加载 jdk 提供的类，所以它们(类加载器的实例)肯定不会被回收。而我们自定义的类加载器的实例是可以被回收的，所以使用我们自定义加载器加载的类是可以被卸载掉的。</p><h1 id="类加载器详解"><a href="#类加载器详解" class="headerlink" title="类加载器详解"></a>类加载器详解</h1><h3 id="双亲委派模型的好处"><a href="#双亲委派模型的好处" class="headerlink" title="双亲委派模型的好处"></a>双亲委派模型的好处</h3><p>双亲委派模型保证了 Java 程序的稳定运行，可以<strong>避免类的重复加载</strong>（<strong>JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类</strong>），也<strong>保证了 Java 的核心 API 不被篡改</strong>。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 <code>java.lang.Object</code> 类的话，那么程序运行的时候，系统就会出现多个不同的 <code>Object</code> 类</p><h3 id="如果我们不想用双亲委派模型怎么办？"><a href="#如果我们不想用双亲委派模型怎么办？" class="headerlink" title="如果我们不想用双亲委派模型怎么办？"></a>如果我们不想用双亲委派模型怎么办？</h3><p>自定义加载器的话，需要继承 <code>ClassLoader</code> 。如果我们不想打破双亲委派模型，就重写 <code>ClassLoader</code> 类中的 <code>findClass()</code> 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 <code>loadClass()</code> 方法</p><h1 id="最重要的JVM参数总结"><a href="#最重要的JVM参数总结" class="headerlink" title="最重要的JVM参数总结"></a>最重要的JVM参数总结</h1><h2 id="2-堆内存相关"><a href="#2-堆内存相关" class="headerlink" title="2.堆内存相关"></a>2.堆内存相关</h2><h3 id="2-1-显式指定堆内存–Xms和-Xmx"><a href="#2-1-显式指定堆内存–Xms和-Xmx" class="headerlink" title="2.1.显式指定堆内存–Xms和-Xmx"></a>2.1.显式指定堆内存<code>–Xms</code>和<code>-Xmx</code></h3><p>与性能有关的最常见实践之一是根据应用程序要求初始化堆内存。如果我们需要指定最小和最大堆大小（推荐显示指定大小），以下参数可以帮助你实现：</p><pre class=" language-text"><code class="language-text">-Xms<heap size>[unit] -Xmx<heap size>[unit]</code></pre><ul><li><strong>heap size</strong> 表示要初始化内存的具体大小。</li><li><strong>unit</strong> 表示要初始化内存的单位。单位为<em><strong>“ g”</strong></em> (GB) 、<em><strong>“ m”</strong></em>（MB）、<em><strong>“ k”</strong></em>（KB）。</li></ul><p>举个栗子🌰，如果我们要为JVM分配最小2 GB和最大5 GB的堆内存大小，我们的参数应该这样来写：</p><pre class=" language-text"><code class="language-text">-Xms2G -Xmx5G</code></pre><h3 id="2-2-显式新生代内存-Young-Generation"><a href="#2-2-显式新生代内存-Young-Generation" class="headerlink" title="2.2.显式新生代内存(Young Generation)"></a>2.2.显式新生代内存(Young Generation)</h3><p>默认情况下，YG 的最小大小为 1310 <em>MB</em>，最大大小为<em>无限制</em>。</p><p>一共有两种指定 新生代内存(Young Ceneration)大小的方法：</p><p><strong>1.通过<code>-XX:NewSize</code>和<code>-XX:MaxNewSize</code>指定</strong></p><p>举个栗子🌰，如果我们要为 新生代分配 最小256m 的内存，最大 1024m的内存我们的参数应该这样来写：</p><pre><code>-XX:NewSize=256m-XX:MaxNewSize=1024m</code></pre><p><strong>2.通过<code>-Xmn&lt;young size&gt;[unit] </code>指定</strong></p><p>举个栗子🌰，如果我们要为 新生代分配256m的内存（NewSize与MaxNewSize设为一致），我们的参数应该这样来写：</p><pre><code>-Xmn256m </code></pre><h3 id="2-3-显式指定永久代-x2F-元空间的大小"><a href="#2-3-显式指定永久代-x2F-元空间的大小" class="headerlink" title="2.3.显式指定永久代&#x2F;元空间的大小"></a>2.3.显式指定永久代&#x2F;元空间的大小</h3><p><strong>从Java 8开始，如果我们没有指定 Metaspace 的大小，随着更多类的创建，虚拟机会耗尽所有可用的系统内存</strong></p><pre><code>-XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小）-XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。</code></pre><h2 id="3-垃圾收集相关"><a href="#3-垃圾收集相关" class="headerlink" title="3.垃圾收集相关"></a>3.垃圾收集相关</h2><h3 id="3-1-垃圾回收器"><a href="#3-1-垃圾回收器" class="headerlink" title="# 3.1.垃圾回收器"></a><a href="#_3-1-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8">#</a> 3.1.垃圾回收器</h3><p>为了提高应用程序的稳定性，选择正确的<a href="http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html">垃圾收集open in new window</a>算法至关重要。</p><p>JVM具有四种类型的<em>GC</em>实现：</p><ul><li>串行垃圾收集器</li><li>并行垃圾收集器</li><li>CMS垃圾收集器</li><li>G1垃圾收集器</li></ul><p>可以使用以下参数声明这些实现：</p><pre class=" language-text"><code class="language-text">-XX:+UseSerialGC-XX:+UseParallelGC-XX:+UseParNewGC-XX:+UseG1GC</code></pre><h3 id="3-2-GC记录"><a href="#3-2-GC记录" class="headerlink" title="3.2.GC记录"></a>3.2.GC记录</h3><p>为了严格监控应用程序的运行状况，我们应该始终检查JVM的<em>垃圾回收</em>性能。最简单的方法是以人类可读的格式记录<em>GC</em>活动。</p><p>使用以下参数，我们可以记录<em>GC</em>活动：</p><pre class=" language-text"><code class="language-text">-XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=< number of log files > -XX:GCLogFileSize=< file size >[ unit ]-Xloggc:/path/to/gc.log</code></pre>]]></content>
      
      
      <categories>
          
          <category> JVM </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Swagger</title>
      <link href="/2022/11/16/xiu-gai-swagger-wen-dang-xiang-ying-ma/"/>
      <url>/2022/11/16/xiu-gai-swagger-wen-dang-xiang-ying-ma/</url>
      
        <content type="html"><![CDATA[<h1 id="Swagger"><a href="#Swagger" class="headerlink" title="Swagger"></a>Swagger</h1><h3 id="修改Swagger接口文档网络请求返回状态码"><a href="#修改Swagger接口文档网络请求返回状态码" class="headerlink" title="修改Swagger接口文档网络请求返回状态码"></a>修改Swagger接口文档网络请求返回状态码</h3><p>常量类</p><pre class=" language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Constants</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">enum</span> ResponseCode <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">/**         * 成功         */</span>        <span class="token function">SUCCESS</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token string">"成功"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token function">UN_ERROR</span><span class="token punctuation">(</span><span class="token number">1001</span><span class="token punctuation">,</span> <span class="token string">"未知失败"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token function">ILLEGAL_PARAMETER</span><span class="token punctuation">(</span><span class="token number">1002</span><span class="token punctuation">,</span> <span class="token string">"非法参数"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token function">PARAM_IS_BLANK</span><span class="token punctuation">(</span><span class="token number">1003</span><span class="token punctuation">,</span> <span class="token string">"参数为空"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token function">INDEX_DUP</span><span class="token punctuation">(</span><span class="token number">1004</span><span class="token punctuation">,</span> <span class="token string">"主键冲突"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token function">NO_UPDATE</span><span class="token punctuation">(</span><span class="token number">1005</span><span class="token punctuation">,</span> <span class="token string">"SQL操作无更新"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token function">USER_NOT_LOGGED_IN</span><span class="token punctuation">(</span><span class="token number">2001</span><span class="token punctuation">,</span> <span class="token string">"用户未登录"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token function">USER_LOGIN_ERROR</span><span class="token punctuation">(</span><span class="token number">2002</span><span class="token punctuation">,</span> <span class="token string">"用户不存在或密码错误"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token function">USER_NOT_EXIST</span><span class="token punctuation">(</span><span class="token number">2003</span><span class="token punctuation">,</span> <span class="token string">"用户不存在"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token function">INSERT_FAIL</span><span class="token punctuation">(</span><span class="token number">3001</span><span class="token punctuation">,</span> <span class="token string">"添加失败"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token function">DELETE_FAIL</span><span class="token punctuation">(</span><span class="token number">3002</span><span class="token punctuation">,</span> <span class="token string">"删除失败"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token function">UPDATE_FAIL</span><span class="token punctuation">(</span><span class="token number">3003</span><span class="token punctuation">,</span> <span class="token string">"更新失败"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token function">QUERY_FAIL</span><span class="token punctuation">(</span><span class="token number">3004</span><span class="token punctuation">,</span> <span class="token string">"查询为空"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">private</span> Integer code<span class="token punctuation">;</span>        <span class="token keyword">private</span> String info<span class="token punctuation">;</span>        <span class="token function">ResponseCode</span><span class="token punctuation">(</span>Integer code<span class="token punctuation">,</span> String info<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">this</span><span class="token punctuation">.</span>code <span class="token operator">=</span> code<span class="token punctuation">;</span>            <span class="token keyword">this</span><span class="token punctuation">.</span>info <span class="token operator">=</span> info<span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">public</span> Integer <span class="token function">getCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> code<span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">public</span> String <span class="token function">getInfo</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> info<span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p>添加一个配置类</p><pre class=" language-java"><code class="language-java"><span class="token annotation punctuation">@Configuration</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">SwaggerConfig</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Bean</span>    <span class="token keyword">public</span> Docket <span class="token function">docket</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        List<span class="token operator">&lt;</span>Response<span class="token operator">></span> responseList <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Arrays<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span>Constants<span class="token punctuation">.</span>ResponseCode<span class="token punctuation">.</span><span class="token function">values</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span>resultCode <span class="token operator">-</span><span class="token operator">></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            responseList<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>            <span class="token keyword">new</span> <span class="token class-name">ResponseBuilder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">code</span><span class="token punctuation">(</span>resultCode<span class="token punctuation">.</span><span class="token function">getCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">description</span><span class="token punctuation">(</span>resultCode<span class="token punctuation">.</span><span class="token function">getInfo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">Docket</span><span class="token punctuation">(</span>DocumentationType<span class="token punctuation">.</span>OAS_30<span class="token punctuation">)</span>                <span class="token punctuation">.</span><span class="token function">globalResponses</span><span class="token punctuation">(</span>GET<span class="token punctuation">,</span> responseList<span class="token punctuation">)</span>                <span class="token punctuation">.</span><span class="token function">globalResponses</span><span class="token punctuation">(</span>POST<span class="token punctuation">,</span> responseList<span class="token punctuation">)</span>                <span class="token punctuation">.</span><span class="token function">globalResponses</span><span class="token punctuation">(</span>PUT<span class="token punctuation">,</span> responseList<span class="token punctuation">)</span>                <span class="token punctuation">.</span><span class="token function">globalResponses</span><span class="token punctuation">(</span>DELETE<span class="token punctuation">,</span> responseList<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Other </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Git推送到Github时出现OpenSSL SSL_read: Connection was reset, errno 10054错误解决方法</title>
      <link href="/2022/05/10/git-tui-song-dao-github-shi-chu-xian-openssl-ssl-read-connection-was-reset-errno-10054-cuo-wu-jie-jue-fang-fa/"/>
      <url>/2022/05/10/git-tui-song-dao-github-shi-chu-xian-openssl-ssl-read-connection-was-reset-errno-10054-cuo-wu-jie-jue-fang-fa/</url>
      
        <content type="html"><![CDATA[<p>突然想把学习写的项目代码放到Github上,也是好久没推送代码了，报了个fatal: unable to access ‘<a href="https://github.com/ZG-jian/Demo.git/&#39;">https://github.com/ZG-jian/Demo.git/&#39;</a>: OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 10054</p><p><strong>找了一下解决方案：</strong></p><p>然后我是觉得我推的东西很多，就用的方法4，然后报错 Support for password authentication was removed on August 13, 2021. Please use a personal access token instead，解决完就成功推送了</p><p>方法1:自己配置的用户名邮箱可能输入错误了：</p><p>查看用户名，邮箱</p><pre class=" language-none"><code class="language-none">git config user.namegit config user.email</code></pre><p>修改用户名，邮箱：</p><pre class=" language-none"><code class="language-none">git config --global user.name "xxx"git config --global user.email"xxx"</code></pre><p>移除仓库，重新添加：</p><pre class=" language-none"><code class="language-none">git remote rm origingit remote add origin https://github.com/XXX</code></pre><p>方法2：移除本地代理：</p><pre class=" language-none"><code class="language-none">git config --global --unset-all remote.origin.proxy</code></pre><p> 方法3：修改解除<a href="https://so.csdn.net/so/search?q=SSL&spm=1001.2101.3001.7020">SSL</a>认证</p><pre class=" language-none"><code class="language-none">git config --global http.sslVerify "false"</code></pre><p>方法4：文件太大，修改缓冲区大小（缓冲区大小修改为500M）</p><pre class=" language-none"><code class="language-none">git config http.postBuffer 5242880003</code></pre><p>方法5：更新DNS缓存</p><pre class=" language-none"><code class="language-none">ipconfig /flushdns</code></pre>]]></content>
      
      
      <categories>
          
          <category> Other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git推送报错Support for password authentication was removed</title>
      <link href="/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/"/>
      <url>/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/</url>
      
        <content type="html"><![CDATA[<p>​        好久没有往<a href="https://so.csdn.net/so/search?q=Github&spm=1001.2101.3001.7020">Github</a>提交代码了，今天偶然提交代码的时候给报了一个 Support for password authentication was removed on August 13, 2021. Please use a personal access token instead.的错误</p><p>​        大概意思就是，你原先的密码凭证从2021年8月13日开始就不能用了，必须使用个人访问令牌（personal access token），就是把你的密码替换成token！</p><h2 id="为什么要把密码换成token"><a href="#为什么要把密码换成token" class="headerlink" title="为什么要把密码换成token"></a>为什么要把密码换成token</h2><p>​        <strong>下面是Github官方的解释：</strong> 近年来，GitHub 客户受益于 <a href="https://link.zhihu.com/?target=http://GitHub.com">http://GitHub.com</a> 的许多安全增强功能，例如双因素身份验证、登录警报、经过验证的设备、防止使用泄露密码和 WebAuthn 支持。 这些功能使攻击者更难获取在多个网站上重复使用的密码并使用它来尝试访问您的 GitHub 帐户。 尽管有这些改进，但由于历史原因，未启用双因素身份验证的客户仍能够仅使用其GitHub 用户名和密码继续对 Git 和 API 操作进行身份验证。</p><p>​        从 2021 年 8 月 13 日开始，我们将在对 Git 操作进行身份验证时不再接受帐户密码，并将要求使用基于令牌（token）的身份验证，例如个人访问令牌（针对开发人员）或 OAuth 或 GitHub 应用程序安装令牌（针对集成商） <a href="https://link.zhihu.com/?target=http://GitHub.com">http://GitHub.com</a> 上所有经过身份验证的 Git 操作。 您也可以继续在您喜欢的地方使用 SSH 密钥。如果你要使用ssh密钥可以参考<a href="https://link.csdn.net/?target=https://link.zhihu.com/?target=https%253A//cloud.tencent.com/developer/article/1861466">https://link.csdn.net/?target=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fcloud.tencent.com%2Fdeveloper%2Farticle%2F1861466</a></p><p><strong>修改为token的好处：</strong></p><p>​        令牌（token）与基于密码的身份验证相比，令牌提供了许多安全优势： - 唯一： 令牌特定于 GitHub，可以按使用或按设备生成 - 可撤销：可以随时单独撤销令牌，而无需更新未受影响的凭据 - 有限 ： 令牌可以缩小范围以仅允许用例所需的访问 - 随机：令牌不需要记住或定期输入的更简单密码可能会受到的字典类型或蛮力尝试的影响</p><h2 id="如何生成token"><a href="#如何生成token" class="headerlink" title="如何生成token"></a>如何生成token</h2><p>1，打开Github，在个人设置页面，找到【Setting】，然后打开找到【Devloper Settting】，如下图。</p><p><img src="/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/Users/jianjian/blog/source/_posts/Git%E6%8E%A8%E9%80%81%E6%8A%A5%E9%94%99Support-for-password-authentication-was-removed/image-20220510195245993.png" alt="image-20220510195245993"></p><p>然后，选择个人访问令牌【Personal access tokens】，然后选中生成令牌【Generate new token】。</p><p><img src="/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/Users/jianjian/blog/source/_posts/Git%E6%8E%A8%E9%80%81%E6%8A%A5%E9%94%99Support-for-password-authentication-was-removed/image-20220510195254365.png" alt="image-20220510195254365"></p><p><img src="/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/Users/jianjian/blog/source/_posts/Git%E6%8E%A8%E9%80%81%E6%8A%A5%E9%94%99Support-for-password-authentication-was-removed/image-20220510195258529.png" alt="image-20220510195258529"></p><p><img src="/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/Users/jianjian/blog/source/_posts/Git%E6%8E%A8%E9%80%81%E6%8A%A5%E9%94%99Support-for-password-authentication-was-removed/image-20220510195302153.png" alt="image-20220510195302153"></p><p>在上个步骤中，选择要授予此令牌token的范围或权限。</p><ul><li>要使用token从命令行访问仓库，请选择repo</li><li>要使用token从命令行删除仓库，请选择delete_repo</li><li>其他根据需要进行勾选</li></ul><p>然后，点击【Generate token】生成令牌。</p><p><img src="/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/Users/jianjian/blog/source/_posts/Git%E6%8E%A8%E9%80%81%E6%8A%A5%E9%94%99Support-for-password-authentication-was-removed/image-20220510195305372.png" alt="image-20220510195305372"></p><p>生成token后，记得把你的token保存下来，以便进行后面的操作。把token直接添加远程仓库链接中，这样就可以避免同一个仓库每次提交代码都要输入token了。</p><pre class=" language-none"><code class="language-none">git remote set-url origin https://<your_token>@github.com/<USERNAME>/<REPO>.git<your_token>：换成你自己得到的token<USERNAME>：是你自己github的用户名<REPO>：是你的仓库名称示例git remote set-url origin https://ghp_JKXAvm5QHR3yaqxxxxxxxx@github.com/ZG-jian/Demo.git</code></pre>]]></content>
      
      
      <categories>
          
          <category> Other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL高版本配置</title>
      <link href="/2022/05/10/mysql-gao-ban-ben-pei-zhi/"/>
      <url>/2022/05/10/mysql-gao-ban-ben-pei-zhi/</url>
      
        <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>springboot+<a href="https://so.csdn.net/so/search?q=Mybatis&spm=1001.2101.3001.7020">Mybatis</a>+Mysql 在配置数据库连接的数据源信息时，不同版本的驱动配置不同，否则连接报错</p><h3 id="配置说明"><a href="#配置说明" class="headerlink" title="配置说明"></a>配置说明</h3><p>高本版的需要把驱动配置成：</p><pre class=" language-none"><code class="language-none">driver-class-name: com.mysql.cj.jdbc.Driver</code></pre><p>据我所知，5.8+的版本的mysql，驱动都应该配置这个驱动。</p><p>5.8以下的版本配置不变：</p><pre><code>driver-class-name: com.mysql.jdbc.Driver</code></pre><p>附上一个完整的连接信息：(mysql 8.0)</p><pre><code>spring:  datasource:    username: root    password: 123456    url: jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=UTC    driver-class-name: com.mysql.cj.jdbc.Driver</code></pre><p>maven依赖：</p><pre><code>&lt;dependency&gt;      &lt;groupId&gt;mysql&lt;/groupId&gt;      &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;      &lt;version&gt;8.0.11&lt;/version&gt;  &lt;/dependency&gt;</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker没运行就拉取报错</title>
      <link href="/2022/05/10/docker-mei-yun-xing-jiu-la-qu-bao-cuo/"/>
      <url>/2022/05/10/docker-mei-yun-xing-jiu-la-qu-bao-cuo/</url>
      
        <content type="html"><![CDATA[<p>今天在重启服务器，然后查看镜像和pull的时候报错</p><p>Cannot connect to the Docker daemon at unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock. Is the docker daemon running?</p><p>翻译过来就是：无法连接到Docker守护进程在unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F; Docker .sock。docker守护进程正在运行吗?</p><p>这个主要的问题就是<a href="https://so.csdn.net/so/search?q=docker&spm=1001.2101.3001.7020">docker</a>没有启动起来导致的…</p><p>然后只要这样</p><pre class=" language-none"><code class="language-none">systemctl start dockersystemctl status docker</code></pre><p> 看到running的标志，就是运行成功了…</p><p>为了避免日后重启再次出现类似情况，增加一个开机自动启动docker…</p><p>systemctl enable docker</p>]]></content>
      
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Navicat连接docker容器中的mysql报错10060：unknow error</title>
      <link href="/2022/05/05/shi-yong-navicat-lian-jie-docker-rong-qi-zhong-de-mysql-bao-cuo-10060-unknow-error/"/>
      <url>/2022/05/05/shi-yong-navicat-lian-jie-docker-rong-qi-zhong-de-mysql-bao-cuo-10060-unknow-error/</url>
      
        <content type="html"><![CDATA[<p>解决方案：</p><p>如果你确定不是防火墙什么的问题，而且你是<strong>挂起的虚拟机然后运行</strong>的话，你可以直接reboot重启虚拟机，然后会发现mysql容器就会停止运行，你再把它跑起来就可以正常运行了。</p><p>出了这个问题，你重启容器也是一样连接不上</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis笔记</title>
      <link href="/2022/04/25/redis-bi-ji/"/>
      <url>/2022/04/25/redis-bi-ji/</url>
      
        <content type="html"><![CDATA[<hr><h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><h3 id="Linux安装"><a href="#Linux安装" class="headerlink" title="Linux安装"></a>Linux安装</h3><p>企业种用的最多的部署方案还是Linux</p><p>先上传至&#x2F;opt下，然后解压至&#x2F;usr&#x2F;local</p><pre class=" language-bash"><code class="language-bash"><span class="token function">tar</span> -zxvf redis-6.2.6.tar.gz -C /usr/local/</code></pre><p>进去redis目录</p><p>安装GCC</p><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> -y gcc</code></pre><p>我们需要把源代码编译成可以执行的文件（redis根目录下）</p><p>编译完成，src就是编译完成后生成的目录</p><p><img src="/2022/04/25/redis-bi-ji/image-20220419200825015.png" alt="image-20220419200825015"></p><p>安装</p><p><img src="/2022/04/25/redis-bi-ji/image-20220419200914603.png" alt="image-20220419200914603"></p><p>进去src里面ls一下</p><p>然后就是文件作用，现在的话记住两个就行，一个是server，一个是cli</p><h4 id="服务启动"><a href="#服务启动" class="headerlink" title="服务启动"></a>服务启动</h4><h5 id="前台启动"><a href="#前台启动" class="headerlink" title="前台启动"></a>前台启动</h5><p>src下执行,端口为6379</p><pre class=" language-bash"><code class="language-bash">./redis-server</code></pre><p><img src="/2022/04/25/redis-bi-ji/image-20220419201207779.png" alt="image-20220419201207779"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220419201130113.png" alt="image-20220419201130113"></p><h5 id="后台启动"><a href="#后台启动" class="headerlink" title="后台启动"></a>后台启动</h5><p>修改redis.conf文件（回根目录）  257行左右  直接&#x2F;daemonize搜索就行</p><pre class=" language-none"><code class="language-none">daemonize yes    #由no改为yes</code></pre><p>然后就可以后台运行了</p><p><img src="/2022/04/25/redis-bi-ji/image-20220419201558533.png" alt="image-20220419201558533"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220419201644659.png" alt="image-20220419201644659"></p><p>然后也可以通过redis-cli连接到服务，这就说明单机版的redis就安装成功了</p><p><img src="/2022/04/25/redis-bi-ji/image-20220419201726223.png" alt="image-20220419201726223"></p><h3 id="Docker安装Redis"><a href="#Docker安装Redis" class="headerlink" title="Docker安装Redis"></a>Docker安装Redis</h3><p>先停一下之前的redis，直接kill -9 停掉</p><p><img src="/2022/04/25/redis-bi-ji/image-20220419201928012.png" alt="image-20220419201928012"></p><p>没安装docker就先y安装docker</p><p>yum -y install docker </p><p>然后启动一下docker</p><p>service docker start</p><p>直接拉一下redis</p><pre class=" language-none"><code class="language-none">docker pull redis</code></pre><p>启动一下容器</p><pre class=" language-none"><code class="language-none">docker run -d --name myredis -p 6379:6379 redis</code></pre><p>然后可以docker ps看一下</p><p>进去看看,然后再连一下，就很简单</p><pre class=" language-bash"><code class="language-bash">docker <span class="token function">exec</span> -it myredis /bin/bash</code></pre><p><img src="/2022/04/25/redis-bi-ji/image-20220419202614073.png" alt="image-20220419202614073"></p><p>然后两次exit退出来</p><h2 id="基本知识"><a href="#基本知识" class="headerlink" title="基本知识"></a>基本知识</h2><p>Redis能读的速度是110000次&#x2F;s，写81000次&#x2F;s</p><h4 id="默认16数据库"><a href="#默认16数据库" class="headerlink" title="默认16数据库"></a>默认16数据库</h4><p>​        Redis是一个字典结构的存储服务器，一个Redis实例提供了多个用来存储数据的字典，客户端可以指定将数据存储在哪个字典中。</p><p>16数据库是可以在配置文件种找到的，配置文件的databases 给的就是16    </p><h5 id="Redis-使用的到底是多线程还是单线程？"><a href="#Redis-使用的到底是多线程还是单线程？" class="headerlink" title="Redis 使用的到底是多线程还是单线程？"></a>Redis 使用的到底是多线程还是单线程？</h5><p>单线程，瓶颈在内存大小或者网络带宽</p><p>​        因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络 带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。</p><h5 id="IO多路复用技术"><a href="#IO多路复用技术" class="headerlink" title="IO多路复用技术"></a>IO多路复用技术</h5><p>难讲，自己找找看吧</p><h5 id="切换数据库"><a href="#切换数据库" class="headerlink" title="切换数据库"></a>切换数据库</h5><p>select </p><p>不指定就会存0库</p><p><img src="/2022/04/25/redis-bi-ji/image-20220419210536436.png" alt="image-20220419210536436"></p><h5 id="清空数据库"><a href="#清空数据库" class="headerlink" title="清空数据库"></a>清空数据库</h5><p>flushdb  —-清除当前库</p><h5 id="删除所有库"><a href="#删除所有库" class="headerlink" title="删除所有库"></a>删除所有库</h5><p>flushall   </p><h3 id="Key键"><a href="#Key键" class="headerlink" title="Key键"></a>Key键</h3><h5 id="keys"><a href="#keys" class="headerlink" title="keys"></a>keys</h5><p>查看所有key</p><pre class=" language-none"><code class="language-none">keys *</code></pre><p>有3个通配符 *, ? ,[] </p><p>*: 通配任意多个字符 </p><p>?: 通配单个字符 </p><p>[]: 通配括号内的某1个字符</p><h6 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h6><p>​    生产已经禁止。因为长时间阻塞redis而导致其他客户端的命令请求一直处于阻塞状态。 更安全的做法是采用scan。</p><pre class=" language-none"><code class="language-none">root@6c068b3fbf29:/data# redis-cli --scan "u*""user1""user</code></pre><h5 id="exists"><a href="#exists" class="headerlink" title="exists"></a>exists</h5><p>判断某个key是否存在，返回1表示存在，0不存在。 </p><p>语法结构：</p><pre class=" language-bash"><code class="language-bash">exists key</code></pre><p>示例：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#查看k1是否存在，如果存在返回1</span>exists k1<span class="token comment" spellcheck="true"># 查看k1 k2 k3是否存在，如果k1 k2存在，k3不存在，则返回2</span>exists k1 k2 k3</code></pre><h5 id="type"><a href="#type" class="headerlink" title="type"></a>type</h5><p>查看当前key 所储存的值的类型。返回当前key所储存的值的类型，如string 、list等。 </p><p>语法结构：</p><p>type key</p><h5 id="del"><a href="#del" class="headerlink" title="del"></a>del</h5><p>删除已存在的key，不存在的 key 会被忽略。</p><p>语法结构：</p><p>del key</p><p>示例： 可以设置多个key，返回删除成功的个数。</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 删除k1，如果成功返回1，失败返回0</span>del k1<span class="token comment" spellcheck="true"># 删除k1 k2 k3，如果k1 k2存在，k3不存在，则返回2</span>del k1 k2 k3</code></pre><h5 id="expire"><a href="#expire" class="headerlink" title="expire"></a>expire</h5><p>给key设置time秒的过期时间。设置成功返回 1 。 当 key 不存在返回 0。</p><pre class=" language-bash"><code class="language-bash">expire key <span class="token function">time</span></code></pre><p>示例：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 给k1设置10秒后过期</span>expire k1 10</code></pre><h5 id="ttl"><a href="#ttl" class="headerlink" title="ttl"></a>ttl</h5><p>以秒为单位返回 key 的剩余过期时间。</p><p>ttl key</p><p>注意： 当 key 不存在时，返回 -2 。 当 key 存在但没有设置剩余生存时间时，返回 -1 。 否则，以秒为单 位，返回 key 的剩余生存时间。</p><h5 id="persist"><a href="#persist" class="headerlink" title="persist"></a>persist</h5><p>移除给定 key 的过期时间，使得 key 永不过期。</p><p>persist key</p><p>注意： 当过期时间移除成功时，返回 1 。 如果 key 不存在或 key 没有设置过期时间，返回 0 。</p><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><p>最大字符串512M，但是非常不建议大字符串</p><h5 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h5><p>String是Redis最基本的类型，一个key对应一个value。String是二进制安全的，意味着String可以包含 任何数据，比如序列化对象或者一张图片。String最多可以放512M的数据。</p><h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="set"><a href="#set" class="headerlink" title="set"></a>set</h5><p>用于设置给定 key 的值。如果 key 已经存储其他值， set 就重写旧值，且无视类型。</p><p>set key value</p><h5 id="get"><a href="#get" class="headerlink" title="get"></a>get</h5><p>用于获取指定 key 的值。如果 key 不存在，返回 nil 。</p><p>get key</p><h5 id="append"><a href="#append" class="headerlink" title="append"></a>append</h5><p>将给定的value追加到key原值末尾。 </p><p>语法格式:</p><pre class=" language-none"><code class="language-none">append key value</code></pre><p>注意： </p><ul><li>如果 key 已经存在并且是一个字符串， append 命令将 value 追加到 key 原来的值的末尾。 </li><li>如果 key 不存在， append 就简单地将给定 key 设为 value ，就像执行 set key value 一 样</li></ul><h5 id="strlen"><a href="#strlen" class="headerlink" title="strlen"></a>strlen</h5><p>获取指定 key 所储存的字符串值的长度。当 key 储存的不是字符串值时，返回一个错误。</p><pre class=" language-none"><code class="language-none">strlen key</code></pre><h5 id="setex"><a href="#setex" class="headerlink" title="setex"></a>setex</h5><p>给指定的 key 设置值及time 秒的过期时间。如果 key 已经存在， setex命令将会替换旧的值，并设置过 期时间。</p><pre class=" language-none"><code class="language-none">setex key time value</code></pre><p>示例：</p><pre class=" language-none"><code class="language-none">#向Redis中设置一个k1的键值对并且10秒后过期127.0.0.1:6379> setex k1 10 v1OK</code></pre><h5 id="setnx"><a href="#setnx" class="headerlink" title="setnx"></a>setnx</h5><pre class=" language-none"><code class="language-none">setnx key value</code></pre><p>只有在key不存在时设置key的值</p><p>key存在就返回0，不存在返回1</p><p>这个功能实现分布式锁用的比较多</p><h5 id="getrange"><a href="#getrange" class="headerlink" title="getrange"></a>getrange</h5><p>获取指定区间范围内的值，类似between……..and 的关系</p><pre class=" language-none"><code class="language-none">getrange key start end</code></pre><h5 id="setrange"><a href="#setrange" class="headerlink" title="setrange"></a>setrange</h5><p>​        从偏移量offset开始，覆写value（对于新的value长度如果小于旧值从offset到结束的长度时，长度小于的部分会保持不变），并返回当前value的长度</p><pre class=" language-bash"><code class="language-bash">setrange key offset value</code></pre><p>从1开始计数</p><h5 id="incr"><a href="#incr" class="headerlink" title="incr"></a>incr</h5><pre class=" language-bash"><code class="language-bash">incr key</code></pre><p>将 key 中储存的数字值增一。</p><p>注意： 如果 key 不存在，那么 key 的值会先被初始化为 0 ，然后再执行 incr 操作。 如字符串类型的值不能表示为数字、或者是其他类型，那么返回一个错误。</p><h5 id="incrby-x2F-decrby-key-step"><a href="#incrby-x2F-decrby-key-step" class="headerlink" title="incrby&#x2F;decrby key step"></a>incrby&#x2F;decrby key step</h5><pre class=" language-none"><code class="language-none"> incrby k1 10</code></pre><p>将key存储的数字值按照step进行增减。</p><h5 id="mset"><a href="#mset" class="headerlink" title="mset"></a>mset</h5><p>同时设置一个或多个 key-value 。</p><pre class=" language-none"><code class="language-none">mset key1 value1 key2 value2</code></pre><h5 id="mget"><a href="#mget" class="headerlink" title="mget"></a>mget</h5><p>返回所有(一个或多个)给定 key 的值。</p><p>mget key1 key2</p><p>注意: 如果给定的 key 里面，有某个 key 不存在，那么这个 key 返回特殊值 nil 。</p><h5 id="getset"><a href="#getset" class="headerlink" title="getset"></a>getset</h5><p>将给定key值设为value，并返回key的旧值（old value），简单一句话（先get然后立即set）。</p><p>getset key value</p><h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><h5 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h5><p>​        List是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右 边）。底层是一个双向链表，对两段操作性能极高，通过索引操作中间的节点性能较差。</p><p>​         一个List最多可以包含 $2^{32}-1$个元素 （ 每个列表超过40亿个元素）。</p><h4 id="常用命令-1"><a href="#常用命令-1" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="lpush-x2F-rpush"><a href="#lpush-x2F-rpush" class="headerlink" title="lpush&#x2F;rpush"></a>lpush&#x2F;rpush</h5><p>从左边（头部）&#x2F;右边（尾部）插入一个或多个值。</p><p>语法结构：</p><pre class=" language-none"><code class="language-none">lpush/rpush key1 value1 value2 value3……</code></pre><p>如：#从左边放入v1 v2 v3</p><p>lpush k1 v1 v2 v3</p><p>#从右边放入v4 v5 v6</p><p>rpush k1 v4 v5 v6</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425093418660.png" alt="image-20220425093418660"></p><h5 id="lrange"><a href="#lrange" class="headerlink" title="lrange"></a>lrange</h5><p>​        返回key列表中的start和end之间的元素（包含start和end）。 其中 0 表示列表的第一个元素，-1表示 最后一个元素。</p><pre class=" language-none"><code class="language-none">lrange key start end</code></pre><p>示例：</p><pre class=" language-none"><code class="language-none">#取出列表里前3个值，结果为v3 v2 v1127.0.0.1:6379> lrange k1 0 2#取出列表里全部值，结果为v3 v2 v1 v4 v5 v6127.0.0.1:6379> lrange k1 0 -1</code></pre><h5 id="lpop-x2F-rpop"><a href="#lpop-x2F-rpop" class="headerlink" title="lpop&#x2F;rpop"></a>lpop&#x2F;rpop</h5><p>移除并返回第一个值或最后一个值。</p><pre class=" language-none"><code class="language-none">lpop/rpop keylpop k1 从列表中删除v3，并返回，当前列表全部值v2 v1 v4 v5 v6rpop k1 从列表中删除v6，并返回，当前列表全部值v2 v1 v4 v5</code></pre><p>注意： 值在键在，值光键亡。</p><h5 id="lindex"><a href="#lindex" class="headerlink" title="lindex"></a>lindex</h5><p>获取列表index位置的值(从左开始  0开始计算)。</p><pre class=" language-none"><code class="language-none">lindex key index</code></pre><h5 id="llen"><a href="#llen" class="headerlink" title="llen"></a>llen</h5><p>获取列表长度。</p><p>llen key</p><h5 id="lrem"><a href="#lrem" class="headerlink" title="lrem"></a>lrem</h5><p>从左边开始删除与value相同的count个元素。</p><pre class=" language-none"><code class="language-none">lrem key count value#从左边开始删除k1列表中2个v1元素lrem k1 2 v1</code></pre><h5 id="linsert"><a href="#linsert" class="headerlink" title="linsert"></a>linsert</h5><p>在列表中value值的前边&#x2F;后边插入一个new value值（从左开始）。</p><pre class=" language-none"><code class="language-none">linsert key before/after value newvalue#示例  在v1前面插入一个v5linsert k1 before v1 v5 </code></pre><h5 id="lset"><a href="#lset" class="headerlink" title="lset"></a>lset</h5><p>将索引为index的值设置为value</p><pre class=" language-none"><code class="language-none">lset key index value</code></pre><h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>消息队列 </li><li>排行榜 </li><li>最新列表</li></ul><h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><p>Redis的Set是String类型的无序集合</p><h5 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h5><p>​        与List类似是一个列表功能，但Set是自动排重的，当需要存储一个列表数据，又不希望出现重复数据 时，Set是一个很好的选择。</p><p>​        Set是String类型的无序集合，它底层其实是一个value为null的hash表，所以添加、删除、查找的时间 复杂度都是O(1)</p><h4 id="常用命令-2"><a href="#常用命令-2" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="sadd"><a href="#sadd" class="headerlink" title="sadd"></a>sadd</h5><p>将一个或多个元素添加到集合key中，已经存在的元素将被忽略。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420161239626.png" alt="image-20220420161239626"></p><h5 id="smembers"><a href="#smembers" class="headerlink" title="smembers"></a>smembers</h5><p>取出该集合的所有元素。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420161344467.png" alt="image-20220420161344467"></p><h5 id="sismember"><a href="#sismember" class="headerlink" title="sismember"></a>sismember</h5><p>判断集合key中是否含有value元素，如有返回1，否则返回0。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420161429941.png" alt="image-20220420161429941"></p><h5 id="scard"><a href="#scard" class="headerlink" title="scard"></a>scard</h5><p>返回该集合的元素个数。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420161503192.png" alt="image-20220420161503192"></p><h5 id="srem"><a href="#srem" class="headerlink" title="srem"></a>srem</h5><p>删除集合中的一个或多个成员元素，不存在的成员元素会被忽略。</p><pre class=" language-none"><code class="language-none">srem key value1 value2……</code></pre><p><img src="/2022/04/25/redis-bi-ji/image-20220420161533211.png" alt="image-20220420161533211"></p><h5 id="spop"><a href="#spop" class="headerlink" title="spop"></a>spop</h5><p>随机删除集合中一个元素并返回该元素。</p><p>spop key</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420161630043.png" alt="image-20220420161630043"></p><h5 id="srandmember"><a href="#srandmember" class="headerlink" title="srandmember"></a>srandmember</h5><p>随机取出集合中count个元素，但不会删除。</p><pre class=" language-none"><code class="language-none">srandmember key count</code></pre><h5 id="smove"><a href="#smove" class="headerlink" title="smove"></a>smove</h5><p>将value元素从sourcekey集合移动到destinationkey集合中。</p><pre class=" language-none"><code class="language-none">smove sourcekey destinationkey value</code></pre><p>注意： 如果 sourcekey集合不存在或不包含指定的 value元素，则 smove 命令不执行任何操作，仅返回 0 。</p><h5 id="sinter"><a href="#sinter" class="headerlink" title="sinter"></a>sinter</h5><p>返回两个集合的交集元素。</p><pre class=" language-none"><code class="language-none">sinter key1 key2</code></pre><h5 id="sunion"><a href="#sunion" class="headerlink" title="sunion"></a>sunion</h5><p>返回两个集合的并集元素。</p><pre class=" language-none"><code class="language-none">sunion key1 key2</code></pre><h5 id="sdiff"><a href="#sdiff" class="headerlink" title="sdiff"></a>sdiff</h5><p>返回两个集合的差集元素（key1中的，不包含key2）</p><pre class=" language-none"><code class="language-none">sdiff key1 key2</code></pre><h4 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>黑白名单 </li><li>随机展示 </li><li>好友 </li><li>关注人 </li><li>粉丝 </li><li>感兴趣的人集合</li></ul><h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><p><img src="/2022/04/25/redis-bi-ji/image-20220425100900244.png" alt="image-20220425100900244"></p><h5 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h5><p>​        Hash是一个键值对的集合。Hash 是一个 String 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。</p><ul><li>Hash存储结构优化 <ul><li>如果field数量较少，存储结构优化为类数组结构 </li><li>如果field数量较多，存储结构使用HashMap结构</li></ul></li></ul><h4 id="常用命令-3"><a href="#常用命令-3" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="hset"><a href="#hset" class="headerlink" title="hset"></a>hset</h5><p>给key集合中的field赋值value。</p><pre class=" language-none"><code class="language-none">127.0.0.1:6379> hset user name JueJue(integer) 1127.0.0.1:6379> hset user age 3(integer) 1</code></pre><p>注意： </p><ul><li>如果哈希表不存在，一个新的哈希表被创建并进行HSET 操作。 </li><li>如果字段已经存在于哈希表中，旧值将被重写。</li></ul><h5 id="hget"><a href="#hget" class="headerlink" title="hget"></a>hget</h5><p>从key哈希中，取出field字段的值。</p><pre class=" language-none"><code class="language-none">hget key field</code></pre><h5 id="hmset"><a href="#hmset" class="headerlink" title="hmset"></a>hmset</h5><p>批量设置哈希的字段及值。</p><pre class=" language-none"><code class="language-none">hmset key field1 value1 field2 value2……</code></pre><h5 id="hexists"><a href="#hexists" class="headerlink" title="hexists"></a>hexists</h5><p>判断指定key中是否存在field  </p><pre class=" language-none"><code class="language-none">hexists key field</code></pre><p>注意： </p><p>如果哈希表含有给定字段，返回 1 。 如果哈希表不含有给定字段，或 key 不存在，返回 0 。</p><h5 id="hkeys"><a href="#hkeys" class="headerlink" title="hkeys"></a>hkeys</h5><p>获取该哈希中所有的field。</p><pre class=" language-none"><code class="language-none">hkeys key</code></pre><h5 id="hvals-key"><a href="#hvals-key" class="headerlink" title="hvals key"></a>hvals key</h5><p>获取该哈希中所有的value。</p><pre class=" language-none"><code class="language-none">hvals key</code></pre><h5 id="hincrby"><a href="#hincrby" class="headerlink" title="hincrby"></a>hincrby</h5><p>为哈希表key中的field字段的值加上增量increment。</p><pre class=" language-none"><code class="language-none">hincrby key field increment</code></pre><p>注意： </p><ul><li>增量也可以为负数，相当于对指定字段进行减法操作。 </li><li>如果哈希表的 key 不存在，一个新的哈希表被创建并执行 hincrby 命令。 </li><li>如果指定的字段不存在，那么在执行命令前，字段的值被初始化为 0 。 </li><li>对一个储存字符串值的字段执行 hincrby 命令将造成一个错误。</li></ul><p>hincrby user1 age 10 对user中的age字段做运算，增加10</p><h5 id="hdel"><a href="#hdel" class="headerlink" title="hdel"></a>hdel</h5><p>删除哈希表 key 中的一个或多个指定字段，不存在的字段将被忽略。</p><pre class=" language-none"><code class="language-none">hdel key field1 field2……</code></pre><h5 id="hsetnx"><a href="#hsetnx" class="headerlink" title="hsetnx"></a>hsetnx</h5><p>给key哈希表中不存在的的字段赋值 。</p><pre class=" language-none"><code class="language-none">hsetnx key field value</code></pre><p>注意： </p><ul><li>如果哈希表不存在，一个新的哈希表被创建并进行 hsetnx 操作。 </li><li>如果字段已经存在于哈希表中，操作无效。 </li><li>如果 key 不存在，一个新哈希表被创建并执行 hsetnx 命令。</li></ul><h4 id="使用场景-2"><a href="#使用场景-2" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>购物车 </li><li>存储对象</li></ul><h3 id="Zset"><a href="#Zset" class="headerlink" title="Zset"></a>Zset</h3><h5 id="简介-4"><a href="#简介-4" class="headerlink" title="简介"></a>简介</h5><p>​        Zset与Set非常相似，是一个没有重复元素的String集合。不同之处是Zset的每个元素都关联了一个分数 （score），这个分数被用来按照从低分到高分的方式排序集合中的元素。集合的元素是唯一的，但分数 可以重复。</p><p>注意： 因为元素是有序的，所以可以根据分数（score）或者次序（position）来获取一个范围内的元素。</p><h4 id="常用命令-4"><a href="#常用命令-4" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="zadd"><a href="#zadd" class="headerlink" title="zadd"></a>zadd</h5><p>将一个或多个元素（value）及分数（score）加入到有序集key中。</p><pre class=" language-none"><code class="language-none">zadd key score1 value1 score2 value2…… </code></pre><h6 id="注意：-1"><a href="#注意：-1" class="headerlink" title="注意："></a>注意：</h6><ul><li>如果某个元素已经是有序集的元素，那么更新这个元素的分数值，并通过重新插入这个元 素，来保证该元素在正确的位置上。 </li><li>分数值可以是整数值或双精度浮点数。 </li><li>如果有序集合 key 不存在，则创建一个空的有序集并执行 zadd 操作。</li></ul><h5 id="zrange"><a href="#zrange" class="headerlink" title="zrange"></a>zrange</h5><p>返回key集合中的索引start和索引end之间的元素（包含start和end）。</p><pre class=" language-none"><code class="language-none">zrange key start end [withscores]# 示例zrange k1 0 -1 返回集合中所有元素zrange k1 0 -1 withscores 返回集合中所有元素，并携带元素分数</code></pre><p>注意： </p><ul><li>其中元素的位置按分数值递增(从小到大)来排序。 其中 0 表示列表的第一个元素，-1表示最 后一个元素。 </li><li>withscores是可选参数，是否返回分数</li></ul><h5 id="zrangebyscore"><a href="#zrangebyscore" class="headerlink" title="zrangebyscore"></a>zrangebyscore</h5><p>​        返回key集合中的分数minscore和分数maxscore 之间的元素（包含minscore 和maxscore ）。其中元素的位置按分数值递增(从小到大)来排序。</p><p>​        withscores是可选参数，是否返回分数</p><pre class=" language-none"><code class="language-none">zrangebyscore key minscore maxscore [withscores]</code></pre><h5 id="zincrby"><a href="#zincrby" class="headerlink" title="zincrby"></a>zincrby</h5><p>为元素value的<strong>score</strong>加上<strong>increment</strong>的值。</p><pre class=" language-none"><code class="language-none">zincrby key increment valuezincrby k1 50 java 给java元素加上50分</code></pre><h5 id="zrem"><a href="#zrem" class="headerlink" title="zrem"></a>zrem</h5><p>删除该集合下value的元素。</p><pre class=" language-none"><code class="language-none">zrem k1 php 删除php</code></pre><h5 id="zcount"><a href="#zcount" class="headerlink" title="zcount"></a>zcount</h5><p>统计该集合在minscore 到maxscore分数区间中元素的个数。</p><pre class=" language-none"><code class="language-none">zcount key minscore maxscore</code></pre><h5 id="zrank"><a href="#zrank" class="headerlink" title="zrank"></a>zrank</h5><p>返回value在集合中的排名，从0开始。</p><pre class=" language-none"><code class="language-none">zrank key value</code></pre><h4 id="使用场景-3"><a href="#使用场景-3" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>延时队列 </li><li>排行榜 </li><li>限流</li></ul><h3 id="Bitmaps"><a href="#Bitmaps" class="headerlink" title="Bitmaps"></a>Bitmaps</h3><p>Bitmaps本身不是一种数据结构，实际上就是字符串，但是它可以对字符串的位进行操作</p><h5 id="简介-5"><a href="#简介-5" class="headerlink" title="简介"></a>简介</h5><p>​        在计算机中，用二进制（位）作为存储信息的基本单位，1个字节等于8位。 例如 “abc” 字符串是由 3 个字节组成，计算机存储时使用其二进制表示，”abc”分别对应的ASCII码是 97、98、99，对应的二进制是01100001、01100010、01100011，在内存中表示如下：</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425111357601.png" alt="image-20220425111357601"></p><p>合理地使用位能够有效地提高内存使用率和开发效率。 </p><p>Redis提供了Bitmaps这个 “数据结构” 可以实现对位的操作：</p><h4 id="常用命令-5"><a href="#常用命令-5" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="setbit"><a href="#setbit" class="headerlink" title="setbit"></a>setbit</h5><p>设置Bitmaps中某个偏移量的值。</p><pre class=" language-none"><code class="language-none">setbit key offset value</code></pre><h5 id="getbit"><a href="#getbit" class="headerlink" title="getbit"></a>getbit</h5><p>获取Bitmaps中某个偏移量的值。</p><pre class=" language-none"><code class="language-none">getbit key offset</code></pre><p> 如果偏移量未设置值，则也返回0。</p><h5 id="bitcount"><a href="#bitcount" class="headerlink" title="bitcount"></a>bitcount</h5><p>​        统计字符串被设置为1的bit数量。一般情况下，给定的整个字符串都会被进行统计，可以选择通过额外 的start和end参数，指定字节组范围内进行统计（包括start和end），0表示第一个元素，-1表示最后一 个元素。</p><pre class=" language-none"><code class="language-none">bitcount key [start end]</code></pre><h5 id="bitop"><a href="#bitop" class="headerlink" title="bitop"></a>bitop</h5><p>将多个bitmaps通过求交集&#x2F;并集方式合并成一个新的bitmaps。</p><pre class=" language-none"><code class="language-none">bitop and/or destkey sourcekey1 sourcekey2……</code></pre><h4 id="使用场景-4"><a href="#使用场景-4" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>活跃天数 </li><li>打卡天数 </li><li>登录天数 </li><li>用户签到 </li><li>统计活跃用户 </li><li>统计用户是否在线 </li><li>实现布隆过滤器</li></ul><h3 id="Geospatia"><a href="#Geospatia" class="headerlink" title="Geospatia"></a>Geospatia</h3><h5 id="简介-6"><a href="#简介-6" class="headerlink" title="简介"></a>简介</h5><p>​        GEO，Geographic,地理信息的缩写。该类型就是元素的二维坐标，在地图上就是经纬度。Redis基于该 类型，提供了经纬度设置、查询、范围查询、距离查询、经纬度Hash等常见操作。</p><h4 id="常用命令-6"><a href="#常用命令-6" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="geoadd"><a href="#geoadd" class="headerlink" title="geoadd"></a>geoadd</h5><p>​        用于存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称 (member)添加到指定的 key 中。</p><pre class=" language-none"><code class="language-none">geoadd key longitude latitude member# 将北京的经纬度和名称添加到chinageoadd china 116.405285 39.904989 beijing# 将成都和上海的经纬度、名称添加到chinageoadd china 104.065735 30.659462 chengdu 121.472644 31.231706 shanghai</code></pre><h5 id="geopos"><a href="#geopos" class="headerlink" title="geopos"></a>geopos</h5><p>从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。</p><pre class=" language-none"><code class="language-none">geopos key member [member ……]##返回china中名称为shanghai和beijing的经纬度geopos chinacity shanghai beijing</code></pre><h5 id="geodist"><a href="#geodist" class="headerlink" title="geodist"></a>geodist</h5><p>用于返回两个给定位置之间的距离。</p><pre class=" language-none"><code class="language-none">geodist key member1 member2 [m|km|ft|mi]</code></pre><p>参数说明： </p><p>m ：米，默认单位。 </p><p>km ：千米。 </p><p>mi ：英里。 </p><p>ft ：英尺。</p><h5 id="georadius"><a href="#georadius" class="headerlink" title="georadius"></a>georadius</h5><p>​        以给定的经纬度（longitude latitude）为中心， 返回键包含的位置元素当中， 与中心的距离不超过给 定最大距离（radius ）的所有位置元素。</p><pre class=" language-none"><code class="language-none">georadius key longitude latitude radius m|km|ft|mi#获取经纬度110 30为中心，在china内1200公里范围内的所有元素。georadius china 110 30 1200 km</code></pre><h4 id="使用场景-5"><a href="#使用场景-5" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>附近的电影院 </li><li>附近的好友 </li><li>离最近的火锅店</li></ul><h3 id="Hyperloglog"><a href="#Hyperloglog" class="headerlink" title="Hyperloglog"></a>Hyperloglog</h3><h5 id="简介-7"><a href="#简介-7" class="headerlink" title="简介"></a>简介</h5><p>​        在我们做站点流量统计的时候一般会统计页面UV(独立访客:unique visitor)和PV(即页面浏览量：page view)。redis HyperLogLog是用来做基数统计的算法，HyperLogLog的优点是：在输入元素的数量或者 体积非常非常大时，计算基数所需的空间总是固定的、并且使很小的。</p><h6 id="什么是基数"><a href="#什么是基数" class="headerlink" title="什么是基数"></a>什么是基数</h6><p>​        比如数据集{1,3,5,7,5,7,8}，那么这个数据集的基数集为{1,3,5,7,8},基数(不重复元素)为5.基数估计就是在 误差可接受的范围内，快速计算基数。</p><h4 id="常用命令-7"><a href="#常用命令-7" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="pfadd"><a href="#pfadd" class="headerlink" title="pfadd"></a>pfadd</h5><p>将所有元素参数添加到 Hyperloglog 数据结构中。</p><p>如果至少有个元素被添加返回 1， 否则返回 0。</p><pre class=" language-none"><code class="language-none">pfadd key element1 element2……pfadd book1 uid1 uid2 uid3</code></pre><p>注意： 添加元素到HyperLogLog中，如果内部有变动返回1，没有返回0。</p><h5 id="pfcount"><a href="#pfcount" class="headerlink" title="pfcount"></a>pfcount</h5><p>计算Hyperloglog 近似基数，可以计算多个Hyperloglog ，统计基数总数。</p><pre class=" language-none"><code class="language-none">pfcount key1 key2……</code></pre><h5 id="pfmerge"><a href="#pfmerge" class="headerlink" title="pfmerge"></a>pfmerge</h5><p>将一个或多个Hyperloglog（sourcekey1） 合并成一个Hyperloglog （destkey ）。</p><pre class=" language-none"><code class="language-none">pfmerge destkey sourcekey1 sourcekey2……</code></pre><h4 id="使用场景-6"><a href="#使用场景-6" class="headerlink" title="使用场景"></a>使用场景</h4><p>​        基数不大，数据量不大就用不上，会有点大材小用浪费空间，有局限性，就是只能统计基数数量，而没 办法去知道具体的内容是什么，和bitmap相比，属于两种特定统计情况，简单来说，HyperLogLog 去 重比 bitmaps 方便很多，一般可以bitmap和hyperloglog配合使用，bitmap标识哪些用户活跃。</p><ul><li>网站PV统计 </li><li>网站UV统计 </li><li>统计访问量(IP数) </li><li>统计在线用户数 </li><li>统计每天搜索不同词条的个数 </li><li>统计文章真实阅读数</li></ul><h3 id="可视化工具"><a href="#可视化工具" class="headerlink" title="可视化工具"></a>可视化工具</h3><p>直接安装就行</p><p>关闭防火墙也还是连接不上，但是我直接连上去了，我是防火墙一直关着，然后只是端口给错了才没连上</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420190437878.png" alt="image-20220420190437878"></p><p>视频里关闭防火墙连不上说是只允许本地访问，要修改配置文件才能远程访问</p><p>是不是我虚拟机配置了本地的ip就给了windows</p><p>注释掉这个</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420190651893.png" alt="image-20220420190651893"></p><p>关掉安全模式后重启</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420190838527.png" alt="image-20220420190838527"></p><p>搞错了，，md一直连接的是docker里的，然后docker里的好像也不用配置就可以直接远程连接上，我说这么管理界面的数据和虚拟机的数据不一样。</p><h3 id="Java整合Redis-Jedis"><a href="#Java整合Redis-Jedis" class="headerlink" title="Java整合Redis_Jedis"></a>Java整合Redis_Jedis</h3><p>？？？为什么文档没有这玩意，直接就到压测了</p><p>手写吧</p><p>创建maven项目，添加依赖</p><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>redis.clients<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>jedis<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.6.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>4.13.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></code></pre><p>运行成功</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420202933246.png" alt="image-20220420202933246"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220420202949899.png" alt="image-20220420202949899"></p><p>list操作</p><p>一点问题没有</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420203616406.png" alt="image-20220420203616406"></p><p>Set</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420204038939.png" alt="image-20220420204038939"></p><p>hash</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420210058735.png" alt="image-20220420210058735"></p><p>zset</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420210441400.png" alt="image-20220420210441400"></p><p>bitmaps</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420211514033.png" alt="image-20220420211514033"></p><p>geo</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420212002745.png" alt="image-20220420212002745"></p><p>hyperloglog</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420212232637.png" alt="image-20220420212232637"></p><h3 id="Java整合Redis-Spring-Data-Redis"><a href="#Java整合Redis-Spring-Data-Redis" class="headerlink" title="Java整合Redis_Spring-Data-Redis"></a>Java整合Redis_Spring-Data-Redis</h3><h3 id="简介-8"><a href="#简介-8" class="headerlink" title="简介"></a>简介</h3><p>Spring-Data-Redis是spring大家族的一部分，通过简单的配置访问Redis服务，对Reids底层开发包(Jedis, JRedis, and RJC)进行了高度封装，RedisTemplate提供了Redis各种操作、异常处理及序列化，支持发布订阅。</p><h3 id="RedisTemplate介绍"><a href="#RedisTemplate介绍" class="headerlink" title="RedisTemplate介绍"></a><strong>RedisTemplate介绍</strong></h3><p>Spring封装了RedisTemplate对象来进行对Redis的各种操作，它支持所有的Redis原生的api。</p><pre class=" language-none"><code class="language-none">1org.springframework.data.redis.core2Class RedisTemplate<K,V></code></pre><blockquote><p>  <strong>注意：</strong></p><ul><li><strong>K</strong>：模板中的Redis key的类型，模板中的Redis key的类型（通常为String）如：RedisTemplate&lt;String, Object&gt;。</li><li><strong>V</strong>：模板中的Redis value的类型</li></ul></blockquote><h3 id="RedisTemplate中定义了对5种数据结构操作"><a href="#RedisTemplate中定义了对5种数据结构操作" class="headerlink" title="RedisTemplate中定义了对5种数据结构操作"></a><strong>RedisTemplate中定义了对5种数据结构操作</strong></h3><pre class=" language-JAVA"><code class="language-JAVA">redisTemplate.opsForValue();//操作字符串redisTemplate.opsForHash();//操作hashredisTemplate.opsForList();//操作listredisTemplate.opsForSet();//操作setredisTemplate.opsForZSet();//操作有序set</code></pre><h3 id="StringRedisTemplate与RedisTemplate"><a href="#StringRedisTemplate与RedisTemplate" class="headerlink" title="StringRedisTemplate与RedisTemplate"></a><strong>StringRedisTemplate与RedisTemplate</strong></h3><ul><li><p>两者的关系是StringRedisTemplate继承RedisTemplate。</p></li><li><p>两者的数据是不共通的；也就是说StringRedisTemplate只能管理StringRedisTemplate里面的数据，RedisTemplate只能管理RedisTemplate中的数据。</p></li><li><p>SDR默认采用的序列化策略有两种，一种是String的序列化策略，一种是JDK的序列化策略。</p><p>StringRedisTemplate默认采用的是String的序列化策略，保存的key和value都是采用此策略序列化保存的。</p><p>RedisTemplate默认采用的是JDK的序列化策略，保存的key和value都是采用此策略序列化保存的。</p></li></ul><p>测试方法写这一行</p><pre class=" language-none"><code class="language-none">redisTemplate.opsForValue().set("key1","value1");</code></pre><p>因为序列化方式不同，这种方式使用的是JDK的序列化 </p><p><img src="/2022/04/25/redis-bi-ji/image-20220421094909095.png" alt="image-20220421094909095"></p><p>加了配置类改序列化就好了</p><p>自定义序列化类</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.spirngdataredisdemo.conf;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;/** * 自定义序列化 */@Configurationpublic class RedisConfig &#123;    @Bean    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory redisConnectionFactory)&#123;        RedisTemplate<String, Object> redisTemplate = new RedisTemplate<>();        //添加序列化机制        redisTemplate.setKeySerializer(new StringRedisSerializer());        redisTemplate.setValueSerializer(new GenericJackson2JsonRedisSerializer());        redisTemplate.setHashKeySerializer(new StringRedisSerializer());        redisTemplate.setHashValueSerializer(new GenericJackson2JsonRedisSerializer());        redisTemplate.setConnectionFactory(redisConnectionFactory);        return redisTemplate;    &#125;&#125;</code></pre><p><img src="/2022/04/25/redis-bi-ji/image-20220421102104191.png" alt="image-20220421102104191"></p><p>添加List</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421102453038.png" alt="image-20220421102453038"></p><p>hash</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421102933751.png" alt="image-20220421102933751"></p><p>set</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421103247187.png" alt="image-20220421103247187"></p><p>zSet</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421104619834.png" alt="image-20220421104619834"></p><p>不多说了</p><pre class=" language-JAVA"><code class="language-JAVA">    /**     * 测试RedisTemplate操作redis服务     */    @Test    public void test()&#123;        //保存数据        redisTemplate.opsForValue().set("key1","value1");        //获取数据        redisTemplate.opsForValue().get("key1");    &#125;    @Test    void ListTest()&#123;//        redisTemplate.opsForList().rightPush("k2","v1");//        redisTemplate.opsForList().rightPush("k2","v2");//        redisTemplate.opsForList().rightPush("k2","v3");//        redisTemplate.opsForList().rightPush("k2","v4");        //获取元素        String k2 = (String) redisTemplate.opsForList().rightPop("k2");        System.out.println(k2);    &#125;    /**     * hash操作     */    @Test    public void hashTest()&#123;//        redisTemplate.opsForHash().put("user","name","JueJue");//        redisTemplate.opsForHash().put("user","age","20");        //获取元素        String s = (String) redisTemplate.opsForHash().get("user", "name");        System.out.println(s);    &#125;    /**     * set操作     */    @Test    public void setTest()&#123;//        redisTemplate.opsForSet().add("sss1","vvv1");//        redisTemplate.opsForSet().add("sss1","v2");//        redisTemplate.opsForSet().add("sss1","v2");//        redisTemplate.opsForSet().add("sss1","v3");        //获取数据        Set s = redisTemplate.opsForSet().members("sss1");        for (Object o : s) &#123;            System.out.println(o.toString());        &#125;        //获取set集合长度        System.out.println(redisTemplate.opsForSet().size("sss1"));    &#125;    @Test    public void zsetTest()&#123;        //添加元素//        redisTemplate.opsForZSet().add("z1","Java",66);//        redisTemplate.opsForZSet().add("z1","C",67);//        redisTemplate.opsForZSet().add("z1","C++",68);        //获取元素        Set k1 = redisTemplate.opsForZSet().range("z1", 0, -1);        for (Object o : k1) &#123;            System.out.println(o);        &#125;        System.out.println("-------------------------");        Set set = redisTemplate.opsForZSet().rangeByScore("z1", 60, 67);        for (Object o : set) &#123;            System.out.println(o);        &#125;    &#125;</code></pre><h2 id="Redis构建Web应用-网页缓存"><a href="#Redis构建Web应用-网页缓存" class="headerlink" title="Redis构建Web应用_网页缓存"></a>Redis构建Web应用_网页缓存</h2><p>就是用户发请求到nginx，然后反向代理负载均衡发到tomcat，之前没有加缓存，就会直接查询数据库</p><p>​        加了之后，请求到了；就会判断缓存中有没有，有就直接返回，没有就走数据库查询，如果数据库中有就把数据加到缓存中，下次查就有缓存了</p><p>创建springboot项目</p><p>写好之后，启动项目就会帮我们创建表</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421152448503.png" alt="image-20220421152448503"></p><p>然后随便添加一条数据，去浏览器地址栏访问</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421152747515.png" alt="image-20220421152747515"></p><p>上代码</p><pre class=" language-JAVA"><code class="language-JAVA">public GoodsEntity getById2(Long id)&#123;        //从数据库中查询商品信息        Optional<GoodsEntity> optionalGoodsEntity = goodsRepository.findById(id);        if (optionalGoodsEntity.isPresent())&#123;            return optionalGoodsEntity.get();        &#125;    return null;&#125;</code></pre><p>这个就是没有缓存的，那它的并发有多少呢？我们也不知道，所以 用一个压测的工具试一试（Jmeter）</p><p>使用</p><p>bin下运行这个</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421190842291.png" alt="image-20220421190842291"></p><p>新建线程组，然后写线程数和循环数，我就是1000*10&#x3D;10000了</p><p>然后还是右键新建取样器Http请求和监听器的报告</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421190123297.png" alt="image-20220421190123297"><img src="/2022/04/25/redis-bi-ji/image-20220421190321543.png" alt="image-20220421190321543"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220421190934598.png" alt="image-20220421190934598"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220421190246781.png" alt="image-20220421190246781"></p><p>一万并发达到4000（没有加缓存）</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421183607570.png" alt="image-20220421183607570"></p><p>写好之后，重启先去浏览器发起一次请求</p><pre class=" language-JAVA"><code class="language-JAVA">@Autowiredprivate StringRedisTemplate stringRedisTemplate;/** * 根据id查询商品信息 * @param id 商品id * @return */public GoodsEntity getById(Long id)&#123;    //查询缓存    String goodsString = stringRedisTemplate.opsForValue().get("goods:" + id);    //判定有没有缓存    if (StringUtils.isEmpty(goodsString))&#123;        //从数据库中查询商品信息        Optional<GoodsEntity> optionalGoodsEntity = goodsRepository.findById(id);        if (optionalGoodsEntity.isPresent())&#123;            GoodsEntity goodsEntity = optionalGoodsEntity.get();            //对象转Json字符串（fastJson）            String goodsEntityJson = JSON.toJSONString(goodsEntity);            //添加缓存            stringRedisTemplate.opsForValue().set("goods:" + id,goodsEntityJson);            //保存完缓存了，就可以返回了            return goodsEntity;        &#125;    &#125;else &#123;        //把字符串转对象        GoodsEntity goodsEntity = JSON.parseObject(goodsString, GoodsEntity.class);        return goodsEntity;    &#125;    return null;&#125;</code></pre><p>然后去redis管理页面就可以看见刚刚加的缓存</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421185105903.png" alt="image-20220421185105903"></p><p>然后进行压力测试</p><p>先清除一下</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421185312803.png" alt="image-20220421185312803"></p><p>屌炸了，牛逼</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421185350415.png" alt="image-20220421185350415"></p><p>再测试几次甚至能到9817</p><p>配置文件</p><pre class=" language-properties"><code class="language-properties"><span class="token comment" spellcheck="true">########################################################</span><span class="token comment" spellcheck="true">### 配置连接池数据库访问配置</span><span class="token comment" spellcheck="true">########################################################</span><span class="token attr-name">spring.datasource.driver-class-name</span><span class="token punctuation">=</span><span class="token attr-value">com.mysql.jdbc.Driver</span><span class="token attr-name">spring.datasource.url</span><span class="token punctuation">=</span><span class="token attr-value">jdbc:mysql://localhost:3306/goods?characterEncoding=utf-8&amp;&amp;useSSL=false</span><span class="token attr-name">spring.datasource.username</span><span class="token punctuation">=</span><span class="token attr-value">root</span><span class="token attr-name">spring.datasource.password</span><span class="token punctuation">=</span><span class="token attr-value">123456</span><span class="token comment" spellcheck="true"># 初始化大小，最小，最大</span><span class="token comment" spellcheck="true">#spring.datasource.initialSize=5</span><span class="token comment" spellcheck="true">#spring.datasource.minIdle=5</span><span class="token comment" spellcheck="true">#spring.datasource.maxActive=20</span><span class="token comment" spellcheck="true"># 配置获取连接等待超时的时间</span><span class="token comment" spellcheck="true">#spring.datasource.maxWait=60000</span><span class="token comment" spellcheck="true"># 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒</span><span class="token comment" spellcheck="true">#spring.datasource.timeBetweenEvictionRunsMillis=60000</span><span class="token comment" spellcheck="true"># 配置一个连接在池中最小生存的时间，单位是毫秒</span><span class="token comment" spellcheck="true">#spring.datasource.minEvictableIdleTimeMillis=300000</span><span class="token comment" spellcheck="true">#spring.datasource.validationQuery=SELECT 1 FROM DUAL</span><span class="token comment" spellcheck="true">#spring.datasource.testWhileIdle=true</span><span class="token comment" spellcheck="true">#spring.datasource.testOnBorrow=false</span><span class="token comment" spellcheck="true">#spring.datasource.testOnReturn=false</span><span class="token comment" spellcheck="true"># 打开PSCache，并且指定每个连接上PSCache的大小</span><span class="token comment" spellcheck="true">#spring.datasource.poolPreparedStatements=true</span><span class="token comment" spellcheck="true">#spring.datasource.maxPoolPreparedStatementPerConnectionSize=20</span><span class="token comment" spellcheck="true"># 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙</span><span class="token comment" spellcheck="true">#spring.datasource.filters=stat,wall,log4j</span><span class="token comment" spellcheck="true"># 通过connectProperties属性来打开mergeSql功能；慢SQL记录</span><span class="token comment" spellcheck="true">#spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000</span><span class="token comment" spellcheck="true"># 合并多个DruidDataSource的监控数据</span><span class="token comment" spellcheck="true">#spring.datasource.useGlobalDataSourceStat=true</span><span class="token comment" spellcheck="true">########################################################</span><span class="token comment" spellcheck="true">### Java Persistence Api --y   JPA配置</span><span class="token comment" spellcheck="true">########################################################</span><span class="token comment" spellcheck="true"># Specify the DBMS</span><span class="token attr-name">spring.jpa.database</span> <span class="token punctuation">=</span> <span class="token attr-value">MYSQL</span><span class="token comment" spellcheck="true"># Show or not log for each sql query</span><span class="token attr-name">spring.jpa.show-sql</span> <span class="token punctuation">=</span> <span class="token attr-value">true</span><span class="token comment" spellcheck="true"># Hibernate ddl auto (create, create-drop, update)</span><span class="token attr-name">spring.jpa.hibernate.ddl-auto</span> <span class="token punctuation">=</span> <span class="token attr-value">update</span><span class="token comment" spellcheck="true"># Naming strategy</span><span class="token comment" spellcheck="true">#[org.hibernate.cfg.ImprovedNamingStrategy  #org.hibernate.cfg.DefaultNamingStrategy]</span><span class="token attr-name">spring.jpa.hibernate.naming-strategy</span> <span class="token punctuation">=</span> <span class="token attr-value">org.hibernate.cfg.ImprovedNamingStrategy</span><span class="token comment" spellcheck="true"># stripped before adding them to the entity manager)</span><span class="token attr-name">spring.jpa.properties.hibernate.dialect</span> <span class="token punctuation">=</span> <span class="token attr-value">org.hibernate.dialect.MySQL5Dialect</span><span class="token comment" spellcheck="true">########################################################</span><span class="token comment" spellcheck="true">### 配置连接池数据库访问配置</span><span class="token comment" spellcheck="true">########################################################</span><span class="token comment" spellcheck="true">#Redis服务器连接地址</span><span class="token attr-name">spring.redis.host</span><span class="token punctuation">=</span><span class="token attr-value">192.168.8.11</span><span class="token comment" spellcheck="true">#Redis服务器连接端口</span><span class="token attr-name">spring.redis.port</span><span class="token punctuation">=</span><span class="token attr-value">6379</span><span class="token comment" spellcheck="true">#连接池最大连接数（使用负值表示没有限制）</span><span class="token attr-name">spring.redis.pool.max-active</span><span class="token punctuation">=</span><span class="token attr-value">8</span><span class="token comment" spellcheck="true">#连接池最大阻塞等待时间（使用负值表示没有限制）</span><span class="token attr-name">spring.redis.pool.max-wait</span><span class="token punctuation">=</span><span class="token attr-value">-1</span><span class="token comment" spellcheck="true">#连接池中的最大空闲连接</span><span class="token attr-name">spring.redis.pool.max-idle</span><span class="token punctuation">=</span><span class="token attr-value">8</span><span class="token comment" spellcheck="true">#连接池中的最小空闲连接</span><span class="token attr-name">spring.redis.pool.min-idle</span><span class="token punctuation">=</span><span class="token attr-value">0</span><span class="token comment" spellcheck="true">#连接超时时间（毫秒）</span><span class="token attr-name">spring.redis.timeout</span><span class="token punctuation">=</span><span class="token attr-value">30000</span><span class="token attr-name">logging.pattern.console</span><span class="token punctuation">=</span><span class="token attr-value">%d&amp;#123;MM/dd HH:mm:ss.SSS&amp;#125; %clr(%-5level) ---  [%-15thread] %cyan(%-50logger&amp;#123;50&amp;#125;):%msg%n</span></code></pre><h2 id="其他功能"><a href="#其他功能" class="headerlink" title="其他功能"></a>其他功能</h2><h3 id="发布与订阅"><a href="#发布与订阅" class="headerlink" title="发布与订阅"></a>发布与订阅</h3><p>先在一个终端上订阅channel</p><p>SUBSCRIBE channel</p><p>然后再开两个别的终端连上去，其中一个也订阅，就有两个订阅了</p><p>第三个就是发布者</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421193244222.png" alt="image-20220421193244222"></p><p>终端1和终端2的页面是一样的</p><p>所以这就是发布订阅的功能，以后想搞聊天，博客等等可以使用一下</p><h3 id="慢查询"><a href="#慢查询" class="headerlink" title="慢查询"></a>慢查询</h3><p>慢查询日志帮助开发和运维人员定位系统存在的慢操作</p><p>慢查询就是工作的时候某一条命令，它的执行效率特别差的时候可以给他找出来优化一下</p><p>开发和运维都会用到，工作中解决问题</p><h5 id="什么是慢查询"><a href="#什么是慢查询" class="headerlink" title="什么是慢查询"></a>什么是慢查询</h5><p>慢查询，顾名思义就是比较慢的查询，但是究竟是哪里慢呢？</p><h5 id="Redis命令执行的整个过程"><a href="#Redis命令执行的整个过程" class="headerlink" title="Redis命令执行的整个过程"></a>Redis命令执行的整个过程</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220421213049982.png" alt="image-20220421213049982"></p><p>两点说明： 1. 慢查询发生在第3阶段 2. 客户端超时不一定慢查询，但慢查询是客户端超时的一个可能因素 3. 慢查询日志是存放在Redis内存列表中。</p><h5 id="什么是慢查询日志"><a href="#什么是慢查询日志" class="headerlink" title="什么是慢查询日志"></a>什么是慢查询日志</h5><p>慢查询日志是Redis服务端在命令执行前后计算每条命令的执行时长，当超过某个阈值是记录下来的日 志。日志中记录了慢查询发生的时间，还有执行时长、具体什么命令等信息，它可以用来帮助开发和运 维人员定位系统中存在的慢查询。</p><h5 id="何获取慢查询日志"><a href="#何获取慢查询日志" class="headerlink" title="何获取慢查询日志"></a>何获取慢查询日志</h5><p>可以使用 slowlog get 命令获取慢查询日志，在 slowlog get 后面还可以加一个数字，用于指定获取 慢查询日志的条数，比如，获取3条慢查询日志： SLOWLOG get 3</p><h5 id="获取慢查询日志的长度"><a href="#获取慢查询日志的长度" class="headerlink" title="获取慢查询日志的长度"></a>获取慢查询日志的长度</h5><p>可以使用 slowlog len 命令获取慢查询日志的长度。</p><h5 id="怎么配置慢查询的参数"><a href="#怎么配置慢查询的参数" class="headerlink" title="怎么配置慢查询的参数"></a>怎么配置慢查询的参数</h5><ul><li>命令执行时长的指定阈值 slowlog-log-slower-than。</li></ul><p>​        slowlog-log-slower-than的作用是指定命令执行时长的阈值，执行命令的时长超过这个阈值时就会被记 录下来。</p><ul><li>存放慢查询日志的条数 slowlog-max-len。</li></ul><p>​         slowlog-max-len的作用是指定慢查询日志最多存储的条数。实际上，Redis使用了一个列表存放慢查询 日志，slowlog-max-len就是这个列表的最大长度。</p><h4 id="如何进行配置"><a href="#如何进行配置" class="headerlink" title="如何进行配置"></a>如何进行配置</h4><h5 id="查看慢日志配置"><a href="#查看慢日志配置" class="headerlink" title="查看慢日志配置"></a>查看慢日志配置</h5><p>客户端redis-cli连接上去之后config get slow*</p><pre class=" language-bash"><code class="language-bash">127.0.0.1:6379<span class="token operator">></span> config get slow*1<span class="token punctuation">)</span> <span class="token string">"slowlog-max-len"</span>2<span class="token punctuation">)</span> <span class="token string">"128"</span>3<span class="token punctuation">)</span> <span class="token string">"slowlog-log-slower-than"</span>4<span class="token punctuation">)</span> <span class="token string">"10000"</span>10000阈值，单位微秒，此处为10毫秒，128慢日志记录保存数量的阈值，此处保存128条。</code></pre><h5 id="修改Redis配置文件"><a href="#修改Redis配置文件" class="headerlink" title="修改Redis配置文件"></a>修改Redis配置文件</h5><p>比如，把slowlog-log-slower-than设置为1000，slowlog-max-len设置为1200：</p><pre class=" language-none"><code class="language-none">slowlog-log-slower-than 1000slowlog-max-len 1200</code></pre><h5 id="使用-config-set-命令动态修改。"><a href="#使用-config-set-命令动态修改。" class="headerlink" title="使用 config set 命令动态修改。"></a>使用 config set 命令动态修改。</h5><p>比如，还是把slowlog-log-slower-than设置为1000，slowlog-max-len设置为1200：</p><pre class=" language-bash"><code class="language-bash"><span class="token operator">></span> config <span class="token keyword">set</span> slowlog-log-slower-than 1000OK<span class="token operator">></span> config <span class="token keyword">set</span> slowlog-max-len 1200OK<span class="token operator">></span> config rewriteOK</code></pre><h4 id="实践建议"><a href="#实践建议" class="headerlink" title="实践建议"></a>实践建议</h4><p><strong>slowlog-max-len配置建议</strong></p><ul><li><p>线上建议调大慢查询列表，记录慢查询时Redis会对长命令做截断操作，并不会占用大量内存。 </p></li><li><p>增大慢查询列表可以减缓慢查询被剔除的可能，例如线上可设置为1000以上。</p></li></ul><p><strong>slowlog-log-slower-than配置建议</strong></p><ul><li><p>默认值超过10毫秒判定为慢查询，需要根据Redis并发量调整该值。 </p></li><li><p>由于Redis采用单线程响应命令，对于高流量的场景，如果命令执行时间在1毫秒以上，那么Redis 最多可支撑OPS不到1000。因此对于高OPS场景的Redis建议设置为1毫秒。</p></li></ul><h3 id="流水线popelines"><a href="#流水线popelines" class="headerlink" title="流水线popelines"></a>流水线popelines</h3><p>回去redisdemo项目</p><p>减少网络时间开销</p><p>回去之前的redisdemo项目测试</p><h5 id="1次网络命令通信模型"><a href="#1次网络命令通信模型" class="headerlink" title="1次网络命令通信模型"></a>1次网络命令通信模型</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220421212701439.png" alt="image-20220421212701439"></p><p>经历了1次时间 &#x3D; 1次网络时间 + 1次命令时间。</p><h5 id="批量网络命令通信模型"><a href="#批量网络命令通信模型" class="headerlink" title="批量网络命令通信模型"></a>批量网络命令通信模型</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220421212717693.png" alt="image-20220421212717693"></p><p>经历了 n次时间 &#x3D; n次网络时间 + n次命令时间</p><h5 id="什么是流水线？"><a href="#什么是流水线？" class="headerlink" title="什么是流水线？"></a>什么是流水线？</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220421212733784.png" alt="image-20220421212733784"></p><p>经历了 1次pipeline(n条命令) &#x3D; 1次网络时间 + n次命令时间，这大大减少了网络时间的开销，这就是流 水线。</p><p>案例展示 从北京到上海的一条命令的生命周期有多长？</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421212808232.png" alt="image-20220421212808232"></p><p>执行一条命令在redis端可能需要几百微秒，而在网络光纤中传输只花费了13毫秒。</p><p>注意： 在执行批量操作而没有使用pipeline功能，会将大量的时间耗费在每一次网络传输的过程上；而使 用pipeline后，只需要经过一次网络传输，然后批量在redis端进行命令操作。这会大大提高了效 率。</p><p>实现：先引入jedis依赖包</p><pre class=" language-JAVA"><code class="language-JAVA">/** * 没有pipeline测试 */@Testpublic void pipelineTest()&#123;    //开始时间    long startTime = System.currentTimeMillis();    //添加元素    for (int i = 0; i < 10000; i++) &#123;        jedis.hset("hashkey"+i,"field"+i,"value"+i);    &#125;    //结束时间    long endTime = System.currentTimeMillis();    System.out.println(endTime-startTime);&#125;/** * pipeline测试 */@Testpublic void pipelineTest2()&#123;    //开始时间    long startTime = System.currentTimeMillis();    //添加元素    for (int i = 0; i < 100; i++) &#123;        Pipeline pipeline = jedis.pipelined();        for (int j = i*100; j < (i+1)*100; j++) &#123;            pipeline.hset("hashkey"+j,"field"+j,"value"+j);        &#125;        pipeline.syncAndReturnAll();    &#125;    //结束时间    long endTime = System.currentTimeMillis();    System.out.println(endTime-startTime);&#125;</code></pre><p>没有pipeline的——–2765毫秒</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421204624848.png" alt="image-20220421204624848"></p><p>pipeline测试—-79毫秒</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421205148053.png" alt="image-20220421205148053"></p><p>所以以后批量添加的时候就要使用pipeline</p><h3 id="Redis数据安全"><a href="#Redis数据安全" class="headerlink" title="Redis数据安全"></a>Redis数据安全</h3><p>​        由于Redis的数据都存放在内存中，如果没有配置持久化，Redis重启后数据就全丢失了，于是需要开启 Redis的持久化功能，将数据保存到磁盘上，当Redis重启后，可以从磁盘中恢复数据。</p><h4 id="持久化机制概述"><a href="#持久化机制概述" class="headerlink" title="持久化机制概述"></a>持久化机制概述</h4><p>​        对于Redis而言，持久化机制是指把内存中的数据存为硬盘文件， 这样当Redis重启或服务器故障时能根 据持久化后的硬盘文件恢复数 据。</p><h4 id="持久化机制的意义"><a href="#持久化机制的意义" class="headerlink" title="持久化机制的意义"></a>持久化机制的意义</h4><p>redis持久化的意义，在于<strong>故障恢复</strong>。比如部署了一个redis，作为cache缓存，同时也可以保存一些比较 重要的数据。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421212535122.png" alt="image-20220421212535122"></p><p>也可以定期把磁盘里的文件备份到云存储服务上去，就可以保证数据永久不丢失</p><h5 id="Redis提供了两个不同形式的持久化方式"><a href="#Redis提供了两个不同形式的持久化方式" class="headerlink" title="Redis提供了两个不同形式的持久化方式"></a>Redis提供了两个不同形式的持久化方式</h5><p>RDB(Redis DataBase) ——-其实就是把数据以快照的形式保存在磁盘上</p><p>AOF(Append Only File)———-可以理解为追加文件的方式</p><h4 id="持久化机制实战"><a href="#持久化机制实战" class="headerlink" title="持久化机制实战"></a>持久化机制实战</h4><h5 id="RDB是什么"><a href="#RDB是什么" class="headerlink" title="RDB是什么"></a>RDB是什么</h5><p>​        在指定的时间间隔内将内存的数据集快照写入磁盘，也就是行话讲的快照，它恢复时是将快照文件直接 读到内存里。</p><h5 id="配置dump-rdb文件"><a href="#配置dump-rdb文件" class="headerlink" title="配置dump.rdb文件"></a>配置dump.rdb文件</h5><p>400多行就是生成文件的名字，:set nu 就可设置行号</p><p>改一下生成文件的路径<br>rdb文件的保存位置，也可以修改。默认在Redis启动时命令行所在的目录下。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220422095200309.png" alt="image-20220422095200309"></p><h5 id="触发机制-主要三种方式"><a href="#触发机制-主要三种方式" class="headerlink" title="触发机制-主要三种方式"></a>触发机制-主要三种方式</h5><h6 id="RDB配置"><a href="#RDB配置" class="headerlink" title="RDB配置"></a>RDB配置</h6><p>快照默认配置： </p><ul><li>save 3600 1：表示3600秒内（一小时）如果至少有1个key的值变化，则保存。 </li><li>save 300 100：表示300秒内（五分钟）如果至少有100个 key 的值变化，则保存。 </li><li>save 60 10000：表示60秒内如果至少有 10000个key的值变化，则保存。</li></ul><h6 id="配置新的保存规则"><a href="#配置新的保存规则" class="headerlink" title="配置新的保存规则"></a>配置新的保存规则</h6><p>给redis.conf添加新的快照策略，30秒内如果有5次key的变化，则触发快照。配置修改后，需要重启 Redis服务。</p><p>加一个save 5 1做演示  5s内有一个key改变就出发</p><h5 id="flushall"><a href="#flushall" class="headerlink" title="flushall"></a>flushall</h5><p>执行flushall命令，也会触发rdb规则。</p><p>加两个数据触发就可以看见</p><p><img src="/2022/04/25/redis-bi-ji/image-20220422100616324.png" alt="image-20220422100616324"></p><p>然后加入redis出问题，那启动的时候就会自动的把这个文件加载到内存中</p><h5 id="save与bgsave"><a href="#save与bgsave" class="headerlink" title="save与bgsave"></a>save与bgsave</h5><p>手动触发Redis进行RDB持久化的命令有两种：</p><ol><li>save 该命令会阻塞当前Redis服务器，执行save命令期间，Redis不能处理其他命令，直到RDB过程完成 为止，不建议使用。</li><li>bgsave 执行该命令时，Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。</li></ol><h5 id="高级配置"><a href="#高级配置" class="headerlink" title="高级配置"></a>高级配置</h5><h6 id="stop-writes-on-bgsave-error"><a href="#stop-writes-on-bgsave-error" class="headerlink" title="stop-writes-on-bgsave-error"></a>stop-writes-on-bgsave-error</h6><p>默认值是yes。当Redis无法写入磁盘的话，直接关闭Redis的写操作。</p><h6 id="rdbcompression"><a href="#rdbcompression" class="headerlink" title="rdbcompression"></a>rdbcompression</h6><p>​        默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算 法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照 会比较大。</p><h6 id="rdbchecksum"><a href="#rdbchecksum" class="headerlink" title="rdbchecksum"></a>rdbchecksum</h6><p>默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加 大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。</p><h6 id="恢复数据"><a href="#恢复数据" class="headerlink" title="恢复数据"></a>恢复数据</h6><p>只需要将rdb文件放在Redis的启动目录，Redis启动时会自动加载dump.rdb并恢复数据。</p><p>kill掉都可以恢复，只要有这个文件就会默认帮我们去加载</p><p><img src="/2022/04/25/redis-bi-ji/image-20220422101157274.png" alt="image-20220422101157274"></p><h5 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h5><ul><li>适合大规模的数据恢复 </li><li>对数据完整性和一致性要求不高更适合使用 </li><li>节省磁盘空间 </li><li>恢复速度快</li></ul><h5 id="劣势"><a href="#劣势" class="headerlink" title="劣势"></a>劣势</h5><p>在备份周期在一定间隔时间做一次备份，所以如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。</p><h4 id="AOF持久化机制"><a href="#AOF持久化机制" class="headerlink" title="AOF持久化机制"></a>AOF持久化机制</h4><p>AOF持久化机制通俗的理解就是日志记录</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425190344559.png" alt="image-20220425190344559"></p><h5 id="AOF是什么"><a href="#AOF是什么" class="headerlink" title="AOF是什么"></a>AOF是什么</h5><p>以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来。</p><p>默认不开启AOF，改一下开启 改完要重启redis服务<br>可以在redis.conf中配置文件名称，默认为appendonly.aof。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220422110902027.png" alt="image-20220422110902027"></p><h6 id="注意：-2"><a href="#注意：-2" class="headerlink" title="注意："></a>注意：</h6><p>AOF文件的保存路径，同RDB的路径一致，如果AOF和RDB同时启动，<strong>Redis默认读取AOF的数据。</strong></p><h5 id="AOF同步频率设置"><a href="#AOF同步频率设置" class="headerlink" title="AOF同步频率设置"></a>AOF同步频率设置</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220425190527044.png" alt="image-20220425190527044"></p><h6 id="参数："><a href="#参数：" class="headerlink" title="参数："></a>参数：</h6><p>1.appendfsync always </p><p>​    始终同步，每次Redis的写入都会立刻记入日志，性能较差但数据完整性比较好。 </p><p>2.appendfsync everysec </p><p>​    每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失。 </p><p>3.appendfsync no </p><p>​    redis不主动进行同步，把同步时机交给操作系统。</p><h5 id="优势-1"><a href="#优势-1" class="headerlink" title="优势"></a>优势</h5><ul><li>备份机制更稳健，丢失数据概率更低。 </li><li>可读的日志文本，通过操作AOF稳健，可以处理误操作。</li></ul><p>劣势 </p><ul><li>比起RDB占用更多的磁盘空间。 </li><li>恢复备份速度要慢。 </li><li>每次读写都同步的话，有一定的性能压力。</li></ul><p>保存的都是一堆命令</p><p><img src="/2022/04/25/redis-bi-ji/image-20220422111132449.png" alt="image-20220422111132449"></p><p>然后手动清除一下，再去aof文件中的最后一行把这个手动删除的命令删掉保存退出</p><p>然后你再启动的时候就会把aof文件里的命令再跑一遍</p><p><strong>基本上都是选每秒同步</strong></p><h4 id="如何选择持久化机制"><a href="#如何选择持久化机制" class="headerlink" title="如何选择持久化机制"></a>如何选择持久化机制</h4><h6 id="不要仅仅使用RDB"><a href="#不要仅仅使用RDB" class="headerlink" title="不要仅仅使用RDB"></a>不要仅仅使用RDB</h6><p>​        RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机， 那么会丢失最近5分钟的数据。</p><h6 id="也不要仅仅使用AOF"><a href="#也不要仅仅使用AOF" class="headerlink" title="也不要仅仅使用AOF"></a>也不要仅仅使用AOF</h6><p>1.你通过AOF做冷备，没有RDB做冷备，来的恢复速度更快。 </p><p>2.RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug。</p><p>冷备份，比如每天晚上十二点保存一个RDB的快照到云平台上</p><p>想恢复就直接拷去redis就行</p><h5 id="综合使用AOF和RDB两种持久化机制"><a href="#综合使用AOF和RDB两种持久化机制" class="headerlink" title="综合使用AOF和RDB两种持久化机制"></a>综合使用AOF和RDB两种持久化机制</h5><p>​        用AOF来保证数据不丢失，作为数据恢复的第一选择，用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复。</p><h3 id="Redis事务"><a href="#Redis事务" class="headerlink" title="Redis事务"></a>Redis事务</h3><p>数据库事务的四大特性 </p><ul><li>A：Atomic，原子性，将所有SQL作为原子工作单元执行，要么全部执行，要么全部不执行； </li><li>C：Consistent，一致性，事务完成后，所有数据的状态都是一致的，即A账户只要减去了100，B 账户则必定加上了100； </li><li>I：Isolation，隔离性，如果有多个事务并发执行，每个事务作出的修改必须与其他事务隔离； </li><li>D：Duration，持久性，即事务完成后，对数据库数据的修改被持久化存储。</li></ul><h5 id="Redis事务-1"><a href="#Redis事务-1" class="headerlink" title="Redis事务"></a>Redis事务</h5><p>​        Redis事务是一组命令的集合，一个事务中的所有命令都将被序列化，按照一次性、顺序性、排他性的执 行一系列的命令</p><h5 id="Redis事务三大特性"><a href="#Redis事务三大特性" class="headerlink" title="Redis事务三大特性"></a>Redis事务三大特性</h5><ol><li>单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其 他客户端发送来的命令请求所打断； </li><li>没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令 都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”。 </li><li>不保证原子性：redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚；</li></ol><h5 id="Redis事务执行的三个阶段"><a href="#Redis事务执行的三个阶段" class="headerlink" title="Redis事务执行的三个阶段"></a>Redis事务执行的三个阶段</h5><ul><li>开启：以 MULTI 开始一个事务； </li><li>入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面； </li><li>执行：由 EXEC 命令触发事务；</li></ul><h4 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h4><h5 id="Multi、Exec、discard"><a href="#Multi、Exec、discard" class="headerlink" title="Multi、Exec、discard"></a>Multi、Exec、discard</h5><p>​        事务从输入Multi命令开始，输入的命令都会依次压入命令缓冲队列中，并不会执行，直到输入Exec后， Redis会将之前的命令缓冲队列中的命令依次执行。组队过程中，可以通过discard来放弃组队。</p><h5 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h5><p>正常事务提交</p><p><strong><img src="/2022/04/25/redis-bi-ji/image-20220424080022115.png" alt="image-20220424080022115"></strong></p><p>取消</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424080124561.png" alt="image-20220424080124561"></p><p>事务里面出现<strong>语法错误</strong>，就会全部失败，就是一种连带责任</p><p>还有一种就是冤有头债有主</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424080509486.png" alt="image-20220424080509486"></p><h2 id="Redis集群"><a href="#Redis集群" class="headerlink" title="Redis集群"></a>Redis集群</h2><p><img src="/2022/04/25/redis-bi-ji/image-20220425191427072.png" alt="image-20220425191427072"></p><h4 id="什么是主从复制"><a href="#什么是主从复制" class="headerlink" title="什么是主从复制"></a>什么是主从复制</h4><p>主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后 者称为从节点(slave),数据的复制是单向的，只能由主节点到从节点。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425191658932.png" alt="image-20220425191658932"></p><p>写操作从主机点，从节点处理读操作</p><h4 id="主从复制的作用"><a href="#主从复制的作用" class="headerlink" title="主从复制的作用"></a>主从复制的作用</h4><p>1.<strong>数据冗余：</strong>主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 </p><p>2.<strong>故障恢复：</strong>当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服 务的冗余。 </p><p>3.<strong>负载均衡：</strong>在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务 （即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是 在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</p><p>4.<strong>高可用基石：</strong>除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是 Redis高可用的基础。</p><h4 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h4><p>学习就可以去一台机器搭建三个redis</p><p>就是新加三个配置文件，并针对端口做不同修改</p><p>redis6379.conf  redis6380.conf  6381.conf</p><p>就对应改下面三个地方</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425192020449.png" alt="image-20220425192020449"></p><p>启动三台</p><pre class=" language-none"><code class="language-none">./redis-server ../redis6379.conf./redis-server ../redis6380.conf./redis-server ../redis6381.conf</code></pre><p>查看是否搭建完成</p><p><strong><img src="/2022/04/25/redis-bi-ji/image-20220424084531105.png" alt="image-20220424084531105"></strong></p><p>然后再开几个终端连接上去</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424084757643.png" alt="image-20220424084757643"></p><p>但是还没有去配置认老大</p><p>就是在小弟这里配置</p><h5 id="配从库不配主库"><a href="#配从库不配主库" class="headerlink" title="配从库不配主库"></a>配从库不配主库</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220424084928252.png" alt="image-20220424084928252"></p><p>然后三台机器都可以看一下</p><p>主节点</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424085423087.png" alt="image-20220424085423087"></p><p>从节点</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424085519137.png" alt="image-20220424085519137"><img src="/2022/04/25/redis-bi-ji/image-20220424085538862.png" alt="image-20220424085538862"></p><p>然后你可以去试一试他们的数据是否同步    然后你会发现数据就是同步的</p><p>试一试从节点能不能保存数据（不能），只能读操作</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424085749352.png" alt="image-20220424085749352"></p><h4 id="主从复制原理剖析"><a href="#主从复制原理剖析" class="headerlink" title="主从复制原理剖析"></a>主从复制原理剖析</h4><p>主从复制可以分为3个阶段六个过程</p><ul><li>连接建立阶段</li><li>数据同步阶段</li><li>命令传播阶段</li></ul><p>复制过程大致分为6个过程</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425193232590.png" alt="image-20220425193232590"></p><p>1、保存主节点（master）信息。</p><p>2、从节点（slave）内部通过每秒运行的定时任务维护复制相关逻辑，当定时任务发现存在新的主 节点后，会尝试与该节点建立网络连接</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425193317658.png" alt="image-20220425193317658"></p><p>3、从节点与主节点建立网络连接 </p><p>从节点会建立一个 socket 套接字，从节点建立了一个端口为51234的套接字，专门用于接受主节点发送 的复制命令。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425193335769.png" alt="image-20220425193335769"></p><p>4、发送ping命令 </p><p>连接建立成功后从节点发送 ping 请求进行首次通信</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425193400062.png" alt="image-20220425193400062"></p><h6 id="作用："><a href="#作用：" class="headerlink" title="作用："></a>作用：</h6><ul><li>检测主从之间网络套接字是否可用。 </li><li>检测主节点当前是否可以接受命令 。</li></ul><p>4、权限验证。</p><p>​        如果主节点设置了 requirepass 参数，则需要密码验证，从节点必须配置 masterauth 参数保证与主节 点相同的密码才能通过验证；如果验证失败复制将终止，从节点重新发起复制流程。</p><p>5、同步数据集。 </p><p>​        主从复制连接正常通信后，对于首次建立复制的场景，主节点会把持有的数据全部发送给从节点，这部 分操作是耗时最长的步骤。</p><p>主节点那900多行有一个requirepass（注释掉的）  </p><p>如果你把他放开之后，就代表reids设置了密码  从节点连接的时候就要密码，不然到不了第五步的同步数据</p><h5 id="主从同步策略"><a href="#主从同步策略" class="headerlink" title="主从同步策略"></a>主从同步策略</h5><p>​        主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</p><pre class=" language-none"><code class="language-none">$3 \r \nset \r \n$4 \r \nname \r \n</code></pre><p><img src="/2022/04/25/redis-bi-ji/image-20220425193634389.png" alt="image-20220425193634389"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220425193756367.png" alt="image-20220425193756367"></p><p>偏移量相等说明master的数据就全部同步过去了。</p><p>6、命令持续复制。 </p><p>​        当主节点把当前的数据同步给从节点后，便完成了复制的建立流程。接下来主节点会持续地把写命令发 送给从节点，保证主从数据一致性。</p><h3 id="哨兵监控"><a href="#哨兵监控" class="headerlink" title="哨兵监控"></a>哨兵监控</h3><h4 id="Redis主从复制缺点"><a href="#Redis主从复制缺点" class="headerlink" title="Redis主从复制缺点"></a>Redis主从复制缺点</h4><p>当主机 Master 宕机以后，我们需要人工解决切换。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425193848246.png" alt="image-20220425193848246"></p><p>暴漏问题： 一旦主节点宕机，写服务无法使用，就需要手动去切换，重新选取主节点，手动设置主从关系。</p><h5 id="主从切换技术"><a href="#主从切换技术" class="headerlink" title="主从切换技术"></a>主从切换技术</h5><p>​        当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造 成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑<strong>哨兵模式。</strong></p><h5 id="哨兵概述"><a href="#哨兵概述" class="headerlink" title="哨兵概述"></a>哨兵概述</h5><p>​        哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独 立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。</p><h5 id="哨兵作用"><a href="#哨兵作用" class="headerlink" title="哨兵作用"></a>哨兵作用</h5><ul><li>集群监控：负责监控redis master和slave进程是否正常工作 </li><li>消息通知：如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员 </li><li>故障转移：如果master node挂掉了，会自动转移到slave node上</li><li>配置中心：如果故障转移发生了，通知client客户端新的master地址</li></ul><h4 id="哨兵监控环境搭建"><a href="#哨兵监控环境搭建" class="headerlink" title="哨兵监控环境搭建"></a>哨兵监控环境搭建</h4><p>参数就是3给2，5给3 7给4，懂我意思吧</p><p>新建sentinel-26379.conf文件</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#端口</span>port 26379<span class="token comment" spellcheck="true">#守护进程运行</span>daemonize <span class="token function">yes</span><span class="token comment" spellcheck="true">#日志文件</span>logfile <span class="token string">"26379.log"</span>sentinel monitor mymaster 127.0.0.1 6379 2</code></pre><h6 id="参数：-1"><a href="#参数：-1" class="headerlink" title="参数："></a>参数：</h6><p>sentinel monitor mymaster 192.168.92.128 6379 2 配置的含义是：该哨兵节点监控 192.168.92.128:6379这个主节点，该主节点的名称是mymaster，最后的2的含义与主节点的故障 判定有关：至少需要2个哨兵节点同意，才能判定主节点故障并进行故障转移。</p><p>然后写好一个sentinel配置文件之后，复制俩份，复制的两份都只改端口和日志文件。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424093534583.png" alt="image-20220424093534583"></p><p>学习嘛，也是一台机器搭建三个哨兵，生产环境就是一台机器放一个哨兵</p><p>启动方式，两种</p><p>记一种就算了，第一种</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 第一种</span>redis-sentinel 配置文件名字<span class="token comment" spellcheck="true">#第二种</span>redis-server 配置文件名字--sentinel</code></pre><p>连接进去哨兵</p><p>查看哨兵节点状态</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424094229091.png" alt="image-20220424094229091"></p><h4 id="哨兵工作原理"><a href="#哨兵工作原理" class="headerlink" title="哨兵工作原理"></a>哨兵工作原理</h4><h5 id="监控阶段"><a href="#监控阶段" class="headerlink" title="监控阶段"></a>监控阶段</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220425195154281.png" alt="image-20220425195154281"></p><p>注意： </p><ul><li>sentinel(哨兵1)—–&gt;向master(主)和slave(从)发起info，拿到全信息。 </li><li>sentinel(哨兵2)—–&gt;向master(主)发起info，就知道已经存在的sentinel(哨兵1)的信息，并且 连接slave(从)。 </li><li>sentinel(哨兵2)—–&gt;向sentinel(哨兵1)发起subscribe(订阅)。</li></ul><h5 id="通知阶段"><a href="#通知阶段" class="headerlink" title="通知阶段"></a>通知阶段</h5><p>sentinel不断的向master和slave发起通知，收集信息。</p><h5 id="故障转移阶段"><a href="#故障转移阶段" class="headerlink" title="故障转移阶段"></a>故障转移阶段</h5><p>​        通知阶段sentinel发送的通知没得到master的回应，就会把master标记为SRI_S_DOWN,并且把master 的状态发给各个sentinel，其他sentinel听到master挂了，说我不信，我也去看看，并把结果共享给各 个sentinel，当有一半的sentinel都认为master挂了的时候，就会把master标记为SRI_0_DOWN</p><p>问题来了： 这时就要把master给换掉了，到底谁当Master呢。</p><p>自己最先接到哪个sentinel的竞选通知就会把票投给它。</p><p>剔除一些情况： 1. 不在线的 2. 响应慢的 3. 与原来master断开时间久的 4. 优先级原则</p><h4 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h4><h4 id="演示故障转移"><a href="#演示故障转移" class="headerlink" title="演示故障转移"></a>演示故障转移</h4><p>直接kill掉主节点</p><p>kill完之后在哨兵节点种查看一下</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424102845205.png" alt="image-20220424102845205"></p><p>主节点不是6379么，然后现在变成6380，自动切换，所以这就是哨兵故障转移过程</p><p>注意：这里还是比较快切换过来的，但是一般来说会需要一段时间</p><p>然后我们重启一下6379看看</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424103503039.png" alt="image-20220424103503039"></p><p>故障转移，哨兵和所有的配置文件都会被改写</p><p>比如看一下，这块就是新加的内容</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424103744511.png" alt="image-20220424103744511"></p><h5 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h5><ul><li>哨兵系统中的主从节点，与普通的主从节点并没有什么区别，故障发现和转移是由哨兵来控制和完 成的。 </li><li>哨兵节点本质上是redis节点。 </li><li>每个哨兵节点，只需要配置监控主节点，便可以自动发现其他的哨兵节点和从节点。 </li><li>在哨兵节点启动和故障转移阶段，各个节点的配置文件会被重写(config rewrite)。</li></ul><h3 id="Cluster模式概述"><a href="#Cluster模式概述" class="headerlink" title="Cluster模式概述"></a>Cluster模式概述</h3><p>redis集群是一个由多个主从节点群组成的分布式服务集群</p><p>Redis有三种集群模式 </p><p>主从模式 </p><p>Sentinel模式 </p><p>Cluster模式</p><h4 id="哨兵模式的缺点"><a href="#哨兵模式的缺点" class="headerlink" title="哨兵模式的缺点"></a>哨兵模式的缺点</h4><ul><li>当master挂掉的时候，sentinel 会选举出来一个 master，选举的时候是没有办法去访问 Redis的，会存在访问瞬断的情况； </li><li>哨兵模式，对外只有master节点可以写，slave节点只能用于读。尽管Redis单节点最多支持 10W的QPS，但是在电商大促的时候，写数据的压力全部在master上。</li><li>Redis的单节点内存不能设置过大，若数据过大在主从同步将会很慢；在节点启动的时候，时间特别长；</li></ul><p>最大缺点：哨兵选举期间，不能对外提供服务</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425195649429.png" alt="image-20220425195649429"></p><h5 id="Redis集群的优点"><a href="#Redis集群的优点" class="headerlink" title="Redis集群的优点"></a>Redis集群的优点</h5><ul><li>Redis集群有多个master，可以减小访问瞬断问题的影响 </li><li>Redis集群有多个master，可以提供更高的并发量　 </li><li>Redis集群可以分片存储，这样就可以存储更多的数据</li></ul><h4 id="Cluster模式搭建"><a href="#Cluster模式搭建" class="headerlink" title="Cluster模式搭建"></a>Cluster模式搭建</h4><p>​        Redis的集群搭建最少需要3个master节点，我们这里搭建3个master，每个下面挂一个slave节点，总 共6个Redis节点；</p><p>​        直接复制虚拟机，docker复制过去三台redis机器，视频里是三台上传好jar包，然后xshell都连接上点一个发送到所有会话，然后进行编译安装</p><p>重启之后都出现一个问题，三步解决</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424135120486.png" alt="image-20220424135120486"></p><p>搭建机器为Redis-1、2、3  自动分配，所以是8.17 18 19这三个ip</p><p>先使用发送键盘输入的所有会话</p><p>然后创建redis目录下创建一个redis-cluster目录</p><p>里面再创建8001、8002两个目录</p><p>配置文件分别拷贝进去一份</p><p>接着进行修改</p><p>先改端口6379改为8001，然后开启后台运行（daemonize yes）</p><p>然后</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424140725656.png" alt="image-20220424140725656"></p><p>接着</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424140818190.png" alt="image-20220424140818190"></p><p>改一下Xshell编码，加一个注释</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141144801.png" alt="image-20220424141144801"></p><p>启动集群模式</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141249738.png" alt="image-20220424141249738"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141404202.png" alt="image-20220424141404202"></p><p>修改集群离线的超时时间</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141534159.png" alt="image-20220424141534159"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141637020.png" alt="image-20220424141637020"></p><p>继续，关闭保护模式</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141721657.png" alt="image-20220424141721657"></p><p>开启AOF</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141752025.png" alt="image-20220424141752025"></p><p>要配密码自己配，我不搞</p><p>但是配了密码就要在下面加一个masterauth xxx</p><p>拷贝一份去8002，修改  g就是全局修改</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424142748129.png" alt="image-20220424142748129"></p><p>这样所有配置文件就都弄好了，关闭一下防火墙（我是一直都关了的）</p><p>然后就可以开始启动服务了，这样就启动好了6台</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424143103158.png" alt="image-20220424143103158"></p><p>看一下也没有问题</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424143154967.png" alt="image-20220424143154967"></p><p>这样准备工作就完事了，就不用发送到所有会话了</p><p>如果配置了密码，就要</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424143324043.png" alt="image-20220424143324043"></p><p>1的意思就是每一个master下面有一个slave</p><pre class=" language-none"><code class="language-none">./redis-cli --cluster create --cluster-replicas 1 192.168.8.17:8001 192.168.8.17:8002 192.168.8.18:8001 192.168.8.18:8002 192.168.8.19:8001 192.168.8.19:8002</code></pre><p>然后回车输入yes，看见两个绿的就说明cluster模式就已经创建成功了</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424143701248.png" alt="image-20220424143701248"></p><p>可以查看帮助</p><pre class=" language-none"><code class="language-none">./redis-cli --cluster help</code></pre><p>然后可以通过add-node一直去水平无限拓展添加节点</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424144014581.png" alt="image-20220424144014581"></p><p>还可以check查看集群状态</p><p>连进去看看，连接到某一个连接</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424144124446.png" alt="image-20220424144124446"></p><p>-c：以集群方式连接</p><p>-h：ip地址是哪</p><p>-p：端口号</p><p>查看集群信息</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424144329706.png" alt="image-20220424144329706"></p><p>16384就是槽</p><p>到现在cluster模式就搭建完成了</p><h4 id="Cluster模式原理分析"><a href="#Cluster模式原理分析" class="headerlink" title="Cluster模式原理分析"></a>Cluster模式原理分析</h4><p>​        Redis Cluster将所有数据划分为16384个slots(槽位)，每个节点负责其中一部分槽位。槽位的信息存储 于每个节点中。只有master节点会被分配槽位，slave节点不会分配槽位。</p><p>槽位定位算法： k1 &#x3D; 127001 </p><p>​        Cluster 默认会对 key 值使用 crc16 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位。 </p><p>​        HASH_SLOT &#x3D; CRC16(key) % 16384</p><p>看我添加完就给我自动切换机器</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424144942831.png" alt="image-20220424144942831"></p><p>要是不在这个槽位，他就获取不到</p><p>我一获取，又给我自动切换了19的机器</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424145128067.png" alt="image-20220424145128067"></p><p>想把一堆数据放到同一个槽位里该怎么做？？</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424145736419.png" alt="image-20220424145736419"></p><p>获取也要加括号</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424145853865.png" alt="image-20220424145853865"></p><h5 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h5><p>myself代表就是当前连接的</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424150008375.png" alt="image-20220424150008375"></p><p>现在来干掉17的master</p><p>lsof -i:8001</p><p>kill -9 PID</p><p>然后去另一台机器上查看</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424150249548.png" alt="image-20220424150249548"></p><p>然后18的两个都是master了</p><h4 id="Java操作Redis集群"><a href="#Java操作Redis集群" class="headerlink" title="Java操作Redis集群"></a>Java操作Redis集群</h4><p>就是现在是cluster的集群</p><p>打开之前的redisdemo项目</p><pre class=" language-JAVA"><code class="language-JAVA">  @Test    public void clusterTest() &#123;        //构建Set集合保存redis节点        Set<HostAndPort> redisNodes = new HashSet<>();        redisNodes.add(new HostAndPort("192.168.8.17", 8001));        redisNodes.add(new HostAndPort("192.168.8.17", 8002));        redisNodes.add(new HostAndPort("192.168.8.18", 8001));        redisNodes.add(new HostAndPort("192.168.8.18", 8002));        redisNodes.add(new HostAndPort("192.168.8.19", 8001));        redisNodes.add(new HostAndPort("192.168.8.19", 8002));        //构建JedisCluster实例  建立连接        JedisCluster jedisCluster = new JedisCluster(redisNodes);        //添加元素//        jedisCluster.set("name","JueJue");        System.out.println(jedisCluster.get("name"));    &#125;</code></pre><p>针对Jedis完事</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424151219473.png" alt="image-20220424151219473"></p><p>针对Springdata-redis</p><p>新建一个springboot项目</p><p>添加lombok和redis依赖</p><p>直接去把之前的配置文件拿过来改一下</p><pre class=" language-properties"><code class="language-properties"><span class="token comment" spellcheck="true">#Redis服务器连接地址</span><span class="token attr-name">spring.redis.host</span><span class="token punctuation">=</span><span class="token attr-value">192.168.8.11</span><span class="token comment" spellcheck="true">#Redis服务器连接端口</span><span class="token attr-name">spring.redis.port</span><span class="token punctuation">=</span><span class="token attr-value">6379</span><span class="token comment" spellcheck="true">#连接池最大连接数（使用负值表示没有限制）</span><span class="token attr-name">spring.redis.pool.max-active</span><span class="token punctuation">=</span><span class="token attr-value">8</span><span class="token comment" spellcheck="true">#连接池最大阻塞等待时间（使用负值表示没有限制）</span><span class="token attr-name">spring.redis.pool.max-wait</span><span class="token punctuation">=</span><span class="token attr-value">-1</span><span class="token comment" spellcheck="true">#连接池中的最大空闲连接</span><span class="token attr-name">spring.redis.pool.max-idle</span><span class="token punctuation">=</span><span class="token attr-value">8</span><span class="token comment" spellcheck="true">#连接池中的最小空闲连接</span><span class="token attr-name">spring.redis.pool.min-idle</span><span class="token punctuation">=</span><span class="token attr-value">0</span><span class="token comment" spellcheck="true">#连接超时时间（毫秒）</span><span class="token attr-name">spring.redis.timeout</span><span class="token punctuation">=</span><span class="token attr-value">30000</span></code></pre><p>就是原来是单机，现在改成cluster.nodes</p><pre class=" language-properties"><code class="language-properties"><span class="token comment" spellcheck="true">#Redis服务器连接地址</span><span class="token attr-name">spring.redis.cluster.nodes</span><span class="token punctuation">=</span><span class="token attr-value">192.168.8.17:8001,192.168.8.17:8002,192.168.8.18:8001,192.168.8.18:8002,192.168.8.19:8001,192.168.8.19:8002</span><span class="token comment" spellcheck="true">#Redis服务器连接端口</span><span class="token attr-name">spring.redis.port</span><span class="token punctuation">=</span><span class="token attr-value">6379</span><span class="token comment" spellcheck="true">#连接池最大连接数（使用负值表示没有限制）</span><span class="token attr-name">spring.redis.pool.max-active</span><span class="token punctuation">=</span><span class="token attr-value">8</span><span class="token comment" spellcheck="true">#连接池最大阻塞等待时间（使用负值表示没有限制）</span><span class="token attr-name">spring.redis.pool.max-wait</span><span class="token punctuation">=</span><span class="token attr-value">-1</span><span class="token comment" spellcheck="true">#连接池中的最大空闲连接</span><span class="token attr-name">spring.redis.pool.max-idle</span><span class="token punctuation">=</span><span class="token attr-value">8</span><span class="token comment" spellcheck="true">#连接池中的最小空闲连接</span><span class="token attr-name">spring.redis.pool.min-idle</span><span class="token punctuation">=</span><span class="token attr-value">0</span><span class="token comment" spellcheck="true">#连接超时时间（毫秒）</span><span class="token attr-name">spring.redis.timeout</span><span class="token punctuation">=</span><span class="token attr-value">30000</span></code></pre><p>一样也是可以的没难度的</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424152043208.png" alt="image-20220424152043208"></p><h2 id="Redis企业级解决方案"><a href="#Redis企业级解决方案" class="headerlink" title="Redis企业级解决方案"></a>Redis企业级解决方案</h2><h3 id="Redis脑裂"><a href="#Redis脑裂" class="headerlink" title="Redis脑裂"></a>Redis脑裂</h3><p>出现在哨兵模式中</p><p>就是由于网络的原因，Master、Slave、Sentinel有延迟了</p><p>Sentinel问Master你还好吗，宕机没有，master不理，问了几次之后没理，就当你宕机，把slave重新升级成master，然后过一会网络好了，就有两个master，一山不容二虎，这就是redis脑裂问题，就是有两个master</p><h4 id="什么是Redis的集群脑裂"><a href="#什么是Redis的集群脑裂" class="headerlink" title="什么是Redis的集群脑裂"></a>什么是Redis的集群脑裂</h4><p>​        Redis的集群脑裂是指因为网络问题，导致Redis Master节点跟Redis slave节点和Sentinel集群处于不同 的网络分区，此时因为sentinel集群无法感知到master的存在，所以将slave节点提升为master节点。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424185227126.png" alt="image-20220424185227126"></p><h5 id="注意：-3"><a href="#注意：-3" class="headerlink" title="注意："></a>注意：</h5><p>此时存在两个不同的master节点，就像一个大脑分裂成了两个。集群脑裂问题中，如果客户端还 在基于原来的master节点继续写入数据，那么新的Master节点将无法同步这些数据，当网络问题 解决之后，sentinel集群将原先的Master节点降为slave节点，此时再从新的master中同步数据， 将会造成大量的数据丢失。</p><p>那客户端是连接新的master还是连接旧的？</p><p>出现脑裂现象会出现什么问题？</p><p>​        就是当Sentinel切换新master，新master就有写的功能，那有数据保存到新的master，原来的master是不是就会丢失一些数据</p><p>​    <strong>以后都可以这样理解，脑裂就是出现了两个主节点，解决方案不同技术不一样</strong></p><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>配置两个参数就可以</p><p>redis.conf配置参数：</p><pre class=" language-none"><code class="language-none">min-replicas-to-write 1min-replicas-max-lag 5</code></pre><h5 id="参数：-2"><a href="#参数：-2" class="headerlink" title="参数："></a>参数：</h5><p>第一个参数表示最少的slave节点为1个 </p><p>第二个参数表示数据复制和同步的延迟不能超过5秒</p><p><strong>配置了这两个参数：如果发生脑裂原Master会在客户端写入操作的时候拒绝请求。这样可以避免大量数据丢失。</strong></p><h3 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h3><h4 id="缓存冷启动"><a href="#缓存冷启动" class="headerlink" title="缓存冷启动"></a>缓存冷启动</h4><p>​        缓存中没有数据，由于缓存冷启动一点数据都没有，如果直接就对外提供服务了，那么并发量上来 Mysql就裸奔挂掉了。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424185419139.png" alt="image-20220424185419139"></p><p>缓存中没有数据，直接对外服务并发量上来数据库一下就挂掉</p><p>提前在redis放缓存就是缓存预热</p><h4 id="缓存冷启动场景"><a href="#缓存冷启动场景" class="headerlink" title="缓存冷启动场景"></a>缓存冷启动场景</h4><p>​        新启动的系统没有任何缓存数据，在缓存重建数据的过程中，系统性能和数据库负载都不太好，所以最 好是在系统上线之前就把要缓存的热点数据加载到缓存中，这种缓存预加载手段就是缓存预热</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424185449907.png" alt="image-20220424185449907"></p><h4 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h4><ul><li>提前给redis中灌入部分数据，再提供服务 </li><li>如果数据量非常大，<strong>就不可能将所有数据都写入redis</strong>，因为数据量太大了，第一是因为耗费的时间太长了，第二根本redis容纳不下所有的数据 </li><li>需要根据当天的具体访问情况，实时<strong>统计出访问频率较高的热数据</strong> </li><li>然后将访问频率较高的热数据写入redis中，肯定是热数据也比较多，我们也得多个服务并行读取数据去写，并行的分布式的缓存预热</li></ul><p><img src="/2022/04/25/redis-bi-ji/image-20220424185606718.png" alt="image-20220424185606718"></p><p>​        lua语言把Nginx日志直接发给消息中间件（只是一种解决方案），然后通过Storm（实时框架）统计访问次数,然后根据结果将热门的加到缓存中就好了</p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p><img src="/2022/04/25/redis-bi-ji/image-20220424185709595.png" alt="image-20220424185709595"></p><p>缓存穿透就是用户对不存在的数据发起请求</p><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>​        <strong>缓存穿透是指缓存和数据库中都没有的数据</strong>，而用户不断发起请求，如发起为id为“-1”的数据或id为特别 大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。</p><h6 id="解释："><a href="#解释：" class="headerlink" title="解释："></a>解释：</h6><p>​        缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查 询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。</p><h4 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h4><p><strong>1.对空值缓存：</strong>如果一个查询返回的数据为空（不管数据是否存在），我们仍然把这个空结果缓存， 设置空结果的过期时间会很短，最长不超过5分钟。</p><p><strong>2.布隆过滤器：</strong>如果想判断一个元素是不是在一个集合里，一般想到的是将集合中所有元素保存起来，然后通过比较确定。</p><h5 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h5><p>–byte数组实现</p><p>​        布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效 地插入和查询，可以用来告诉你 “某样东西一定不存在或者可能存在”。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424185908110.png" alt="image-20220424185908110"></p><p>​    比如先放了个西瓜和香蕉，苹果不存在，但是它的hash值和对上了</p><p>注意： 布隆说不存在一定不存在，布隆说存在你要小心了，它有可能不存在。</p><h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><p>引入hutool包  </p><pre class=" language-xml"><code class="language-xml">   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>cn.hutool<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hutool-all<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.7.17<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></code></pre><p>可以在项目启动的时候把所有商品的id查询出来放进去布隆过滤器里面</p><pre class=" language-JAVA"><code class="language-JAVA">@Testpublic void FilterTest()&#123;    //初始化    BitMapBloomFilter bitMapBloomFilter = new BitMapBloomFilter(10);    //添加元素    bitMapBloomFilter.add("abc");    bitMapBloomFilter.add("123");    bitMapBloomFilter.add("juejue");    bitMapBloomFilter.add("qwe");    System.out.println(bitMapBloomFilter.contains("789"));    System.out.println(bitMapBloomFilter.contains("abc"));&#125;</code></pre><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>缓存击穿是指缓存中没有但数据库中有的单条数据</p><h5 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h5><p>​        某一个热点 key，在缓存过期的一瞬间，同时有大量的请求打进来，由于此时缓存过期了，所以请求最 终都会走到数据库，造成瞬时数据库请求量大、压力骤增，甚至可能打垮数据库。</p><h4 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h4><p><strong>1.互斥锁：</strong></p><p>​    在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程 拿不到锁就阻塞等着，等到第一个线程将数据写入缓存后，其他线程直接查询缓存。 </p><p><strong>2.热点数据不过期：</strong></p><p>​    直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存。</p><h5 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h5><pre class=" language-JAVA"><code class="language-JAVA">/** * 互斥锁解决缓存击穿 * * @param key 商品key */@Testpublic String lock(String key) throws InterruptedException &#123;    //获取key的值    String value = jedis.get(key);    //判断缓存是否过期    if (value == null) &#123;        //设置3分钟的超时时间，只有key不存在时候才能创建        Long setnx = jedis.setnx(key + "_mutex", "6");        //设置过期时间        jedis.pexpire(key + "_mutex", 3 * 60);        //设置成功        if (setnx == 1) &#123;            //DB操作            value = "db";            //保存缓存            jedis.setex(key,3*60,value);            jedis.del(key + "_mutex");            return value;        &#125;else &#123;            // 这个时候代表同时操作的其他线程已经load db并设置缓存了。 需要重新重新获取缓存            Thread.sleep(5000);            //重试            return lock(key);        &#125;    &#125;else &#123;        return value;    &#125;&#125;</code></pre><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>​    缓存雪崩发生时说明缓存中大批量的数据过期，而查询量巨大，请求直接到达数据库，造成数据库压力倍增</p><h5 id="概念-2"><a href="#概念-2" class="headerlink" title="概念"></a>概念</h5><p>​        缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发 到DB，DB瞬时压力过重雪崩。</p><p>缓存正常从Redis中获取，示意图如下：</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424195855987.png" alt="image-20220424195855987"></p><p>缓存失效瞬间示意图如下：</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424195913256.png" alt="image-20220424195913256"></p><h5 id="解决方案-3"><a href="#解决方案-3" class="headerlink" title="解决方案"></a>解决方案</h5><ul><li><strong>过期时间打散：</strong>既然是大量缓存集中失效，那最容易想到就是让他们不集中生效。可以给缓存的过 期时间时加上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。 </li><li><strong>热点数据不过期：</strong>该方式和缓存击穿一样，也是要着重考虑刷新的时间间隔和数据异常如何处理的情况。</li><li><strong>加互斥锁:</strong> 该方式和缓存击穿一样，按 key 维度加锁，对于同一个 key，只允许一个线程去计算， 其他线程原地阻塞等待第一个线程的计算结果，然后直接走缓存即可。</li></ul><h6 id="加锁排队代码"><a href="#加锁排队代码" class="headerlink" title="加锁排队代码"></a>加锁排队代码</h6><pre class=" language-JAVA"><code class="language-JAVA">/** * 互斥锁解决缓存击穿 * * @param key 商品key */@Testpublic String lock(String key) throws InterruptedException &#123;    //获取key的值    String value = jedis.get(key);    //判断缓存是否过期    if (value == null) &#123;        //设置3分钟的超时时间，只有key不存在时候才能创建        Long setnx = jedis.setnx(key + "_mutex", "6");        //设置过期时间        jedis.pexpire(key + "_mutex", 3 * 60);        //设置成功        if (setnx == 1) &#123;            //DB操作            value = "db";            //保存缓存            jedis.setex(key,3*60,value);            jedis.del(key + "_mutex");            return value;        &#125;else &#123;            Thread.sleep(5000);            //重试            return lock(key);        &#125;    &#125;else &#123;        return value;    &#125;&#125;</code></pre><h3 id="Redis开发规范"><a href="#Redis开发规范" class="headerlink" title="Redis开发规范"></a>Redis开发规范</h3><h4 id="key设计技巧"><a href="#key设计技巧" class="headerlink" title="key设计技巧"></a>key设计技巧</h4><ul><li>1、把表名转换为key前缀，如 tag: </li><li>2、把第二段放置用于区分key的字段，对应msyql中主键的列名，如 user_id </li><li>3、第三段放置主键值，如 2,3,4 </li><li>4、第四段写存储的列名</li></ul><h5 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h5><pre><code># 表名 主键 主键值 存储列名字set user:user_id:1:name JueJueset user:user_id:1:age 20#查询这个用户keys user:user_id:9*</code></pre><p>冒号的方式你打开管理工具看缓存就有层级目录</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424170722693.png" alt="image-20220424170722693"></p><p><strong>要是有业务的话，在表名前面加一个业务名就可以</strong></p><h4 id="value设计"><a href="#value设计" class="headerlink" title="value设计"></a>value设计</h4><h5 id="拒绝bigkey"><a href="#拒绝bigkey" class="headerlink" title="拒绝bigkey"></a>拒绝bigkey</h5><p>​        防止网卡流量、慢查询，string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。</p><h4 id="命令使用"><a href="#命令使用" class="headerlink" title="命令使用"></a>命令使用</h4><h5 id="1、禁用命令"><a href="#1、禁用命令" class="headerlink" title="1、禁用命令"></a>1、禁用命令</h5><p>​        禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐 进式处理。 </p><h5 id="2、合理使用select"><a href="#2、合理使用select" class="headerlink" title="2、合理使用select"></a>2、合理使用select</h5><p>​        redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线 程处理，会有干扰。</p><h5 id="3、使用批量操作提高效率"><a href="#3、使用批量操作提高效率" class="headerlink" title="3、使用批量操作提高效率"></a>3、使用批量操作提高效率</h5><h6 id="原生命令："><a href="#原生命令：" class="headerlink" title="原生命令："></a>原生命令：</h6><p>​    例如mget、mset。 </p><h6 id="非原生命令："><a href="#非原生命令：" class="headerlink" title="非原生命令："></a>非原生命令：</h6><p>​    可以使用pipeline提高效率。pipeline方式，就很快</p><h6 id="注意：-4"><a href="#注意：-4" class="headerlink" title="注意："></a>注意：</h6><p>​    但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。</p><h5 id="4、不建议过多使用Redis事务功能"><a href="#4、不建议过多使用Redis事务功能" class="headerlink" title="4、不建议过多使用Redis事务功能"></a>4、不建议过多使用Redis事务功能</h5><p>​    Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot 上。</p><p>集群版本要求就是在一个槽上</p><h4 id="客户端使用"><a href="#客户端使用" class="headerlink" title="客户端使用"></a>客户端使用</h4><p>1.Jedis ：<a href="https://github.com/xetorthio/jedis">https://github.com/xetorthio/jedis</a> 重点推荐 </p><p>2.Spring Data redis ：<a href="https://github.com/spring-projects/spring-data-redis">https://github.com/spring-projects/spring-data-redis</a> 使用Spring框架时推荐 3.Redisson ：<a href="https://github.com/mrniko/redisson">https://github.com/mrniko/redisson</a> 分布式锁、阻塞队列的时重点推荐 </p><h6 id="1、避免多个应用使用一个Redis实例"><a href="#1、避免多个应用使用一个Redis实例" class="headerlink" title="1、避免多个应用使用一个Redis实例"></a>1、避免多个应用使用一个Redis实例</h6><p>​    不相干的业务拆分，公共数据做服务化。 </p><h6 id="2、使用连接池"><a href="#2、使用连接池" class="headerlink" title="2、使用连接池"></a>2、使用连接池</h6><p>​    可以有效控制连接，同时提高效率，标准使用方式:</p><pre class=" language-JAVA"><code class="language-JAVA">执行命令如下：Jedis jedis = null;try &#123;    jedis = jedisPool.getResource();//具体的命令    jedis.executeCommand()&#125; catch (Exception e) &#123;    logger.error("op key &#123;&#125; error: " + e.getMessage(), key, e);&#125; finally &#123;//注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。if (jedis != null)    jedis.close();&#125;</code></pre><h3 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h3><p><img src="/2022/04/25/redis-bi-ji/image-20220424202532521.png" alt="image-20220424202532521"></p><p>就是查缓存了查笔记本，然后同时又有请求去修改这个笔记本，所以这就数据不一致了</p><p>缓存说明： 从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。</p><p><strong>缓存不一致理论上来说是可以设置过期时间来保证一致性的；越短越能保证</strong></p><h4 id="三种更新策略"><a href="#三种更新策略" class="headerlink" title="三种更新策略"></a>三种更新策略</h4><ul><li>先更新数据库，再更新缓存 </li><li>先删除缓存，再更新数据库 </li><li>先更新数据库，再删除缓存</li></ul><p>我们还是得以数据库中的数据为准</p><h5 id="先更新数据库，再更新缓存"><a href="#先更新数据库，再更新缓存" class="headerlink" title="先更新数据库，再更新缓存"></a>先更新数据库，再更新缓存</h5><p>这套方案，大家是普遍反对的。为什么呢？ </p><h6 id="线程安全角度"><a href="#线程安全角度" class="headerlink" title="线程安全角度"></a>线程安全角度</h6><p>同时有请求A和请求B进行更新操作，那么会出现 </p><p>（1）线程A更新了数据库 </p><p>（2）线程B更新了数据库 </p><p>（3）线程B更新了缓存 </p><p>（4）线程A更新了缓存 这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。 这就导致了脏数据，因此不考虑。</p><h5 id="先删缓存，再更新数据库"><a href="#先删缓存，再更新数据库" class="headerlink" title="先删缓存，再更新数据库"></a>先删缓存，再更新数据库</h5><p>​    该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出 现如下情形: </p><p>（1）请求A进行写操作，删除缓存 </p><p>（2）请求B查询发现缓存不存在 </p><p>（3）请求B去数据库查询得到旧值 </p><p>（4）请求B将旧值写入缓存 </p><p>（5）请求A将新值写入数据库 </p><p>注意： </p><p>该数据永远都是脏数据。</p><h5 id="先更新数据库，再延时删缓存-正解"><a href="#先更新数据库，再延时删缓存-正解" class="headerlink" title="先更新数据库，再延时删缓存(正解)"></a>先更新数据库，再延时删缓存(正解)</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220424204451253.png" alt="image-20220424204451253"></p><p>这种情况存在并发问题吗？ </p><p>（1）缓存刚好失效 </p><p>（2）请求A查询数据库，得一个旧值 </p><p>（3）请求B将新值写入数据库 </p><p>（4）请求B删除缓存 </p><p>（5）请求A将查到的旧值写入缓存</p><p>发生这种情况的概率又有多少? </p><p>​        发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗 时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快 于写操作的，因此步骤（3）耗时比步骤（2）更短，这一情形很难出现</p><p>加过期时间</p><p>先更新数据库，在删除缓存，而且删除缓存是延时的删除缓存</p><p>就是缓存添加成功后等个1s再删掉</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FastDFS笔记</title>
      <link href="/2022/04/19/fastdfs-bi-ji/"/>
      <url>/2022/04/19/fastdfs-bi-ji/</url>
      
        <content type="html"><![CDATA[<hr><h1 id="FastDFS"><a href="#FastDFS" class="headerlink" title="FastDFS"></a>FastDFS</h1><p>分布式文件系统</p><h4 id="为什么要使用？"><a href="#为什么要使用？" class="headerlink" title="为什么要使用？"></a>为什么要使用？</h4><h5 id="单机时代"><a href="#单机时代" class="headerlink" title="单机时代"></a>单机时代</h5><p>​    我们通常直接在项目目录下建立静态资源文件夹，用于存放项目中的文件资源，然后还可以按不同类型建立不同子目录比如resource&#x2F;img、resource&#x2F;file</p><p>优点：方便</p><p>缺点：文件越多越混乱</p><h5 id="独立文件服务器"><a href="#独立文件服务器" class="headerlink" title="独立文件服务器"></a>独立文件服务器</h5><p>引入一个独立图片服务器</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419135816244.png" alt="image-20220419135816244"></p><p>流程： 项目上传文件时，首先通过ftp或者ssh将文件上传到图片服务器 的某个目录下，再通过Ngnix或者Apache来访问此目录下的文 件，返回一个独立域名的图片URL地址，前端使用文件时就通过 这个URL地址读取。</p><h5 id="分布式文件系统"><a href="#分布式文件系统" class="headerlink" title="分布式文件系统"></a>分布式文件系统</h5><p>​        业务发展，单台服务器存储和响应也很快到达了瓶颈，新的业 务需要文件访问具有高响应性、高可用性来支持系统。</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419135910310.png" alt="image-20220419135910310"></p><h6 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h6><ul><li>扩展能力: 毫无疑问，扩展能力是一个分布式文件系统最重要的特点； </li><li>高可用性: 在分布式文件系统中，高可用性包含两层，一是整个文件系统的可用性，二是数据 的完整和一致性； </li><li>弹性存储: 可以根据业务需要灵活地增加或缩减数据存储以及增删存储池中的资源，而不需要 中断系统运行。</li></ul><h6 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h6><p>​        系统复杂度稍高，需要更多服务器</p><p>独立文件服务器缺点：容灾、单点故障、垂直扩展稍差</p><p>分布式文件系统缺点：系统复杂度稍高</p><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>FastDFS是一个开源的轻量级分布式文件系统。它解决了大数据量 存储和负载均衡等问题。特别适合以中小文件（建议范围：4KB &lt; file_size &lt;500MB）为载体的在线服务，如相册网站、视频网站等等。</p><p>FastDFS特性： </p><ul><li>文件不分块存储，上传的文件和OS文件系统中的文件一一对应 </li><li>支持相同内容的文件只保存一份，节约磁盘空间 </li><li>下载文件支持HTTP协议，可以使用内置Web Server，也可以和其他Web Server配合使用 </li><li>支持在线扩容 </li><li>支持主从文件</li></ul><h4 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h4><p>FastDFS服务端有三个角色：跟踪服务器（&#x3D;&#x3D;tracker&#x3D;&#x3D;）、存储服务器 （storage）和客户端（client）。</p><h5 id="tracker"><a href="#tracker" class="headerlink" title="tracker"></a>tracker</h5><p>​        跟踪服务器，主要做调度工作，起负载均衡的作用。在内存中记录 集群中所有存储组和存储服务器的状态信息，是客户端和数据服务 器交互的枢纽。 </p><h5 id="storage"><a href="#storage" class="headerlink" title="storage"></a>storage</h5><p>​        存储服务器（又称：存储节点或数据服务器），文件和文件属性 （meta data）都保存到存储服务器上。Storage server直接利用 OS的文件系统调用管理文件。 </p><h5 id="client"><a href="#client" class="headerlink" title="client"></a>client</h5><p>​        客户端，作为业务请求的发起方，通过专有接口，使用TCP&#x2F;IP协议 与跟踪器服务器或存储节点进行数据交互。FastDFS向使用者提供 基本文件访问接口，比如upload、download、append、delete 等，以客户端库的方式提供给用户使用。 </p><h5 id="group"><a href="#group" class="headerlink" title="group"></a>group</h5><p>​        组， 也可称为卷。 同组内服务器上的文件是完全相同的 ，同一组 内的storage server之间是对等的， 文件上传、 删除等操作可以在 任意一台storage server上进行 。</p><h5 id="流程："><a href="#流程：" class="headerlink" title="流程："></a>流程：</h5><p>​        Tracker相当于FastDFS的大脑，不论是上传还是下载都是通过 tracker来分配资源；客户端一般可以使用Ngnix等静态服务器 来调用或者做一部分的缓存；存储服务器内部分为卷（或者叫 做组），卷于卷之间是平行的关系，可以根据资源的使用情况 随时增加，卷内服务器文件相互同步备份，以达到容灾的目的。</p><h4 id="上传机制"><a href="#上传机制" class="headerlink" title="上传机制"></a>上传机制</h4><p>​        首先客户端请求Tracker服务获取到存储服务器的ip地址和端口，然后客户端根据返回的IP地址和端口号请求上传文件，存储服务器接 收到请求后生产文件，并且将文件内容写入磁盘并返回给客户端 file_id、路径信息、文件名等信息，客户端保存相关信息上传完毕。</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419140919363.png" alt="image-20220419140919363"></p><p>内部机制如下 </p><h5 id="1、选择Tracker-server"><a href="#1、选择Tracker-server" class="headerlink" title="1、选择Tracker server"></a>1、选择Tracker server</h5><p>当集群中不止一个Tracker server时，由于Tracker之间是完全对等 的关系，客户端在upload文件时可以任意选择一个trakcer。 </p><h5 id="2、选择Storage-server"><a href="#2、选择Storage-server" class="headerlink" title="2、选择Storage server"></a>2、选择Storage server</h5><p>当选定Group后，Tracker会在Group内选择一个Storage Server给 客户端 </p><h5 id="3、选择Storage"><a href="#3、选择Storage" class="headerlink" title="3、选择Storage"></a>3、选择Storage</h5><p>path 当分配好Storage Server后，客户端将向Storage发送写文件请求， Storage将会为文件分配一个数据存储目录。</p><p>注意： &#x3D;&#x3D;剩余存储空间最多的优先。&#x3D;&#x3D;</p><h5 id="4、生成Fileid"><a href="#4、生成Fileid" class="headerlink" title="4、生成Fileid"></a>4、生成Fileid</h5><p>​        选定存储目录之后，Storage会为文件生一个Fileid，由Storage Server Ip、文件创建时间、文件大小、文件crc32和一个随机数拼接而成，然后将这个二进制串进行base64编码，转换为可打印的字符串。</p><h5 id="5、生成文件名"><a href="#5、生成文件名" class="headerlink" title="5、生成文件名"></a>5、生成文件名</h5><p>当文件存储到某个子目录后，即认为该文件存储成功，接下来会为 该文件生成一个文件名，文件名由group、存储目录、两级子目 录、fileid、文件后缀名（由客户端指定，主要用于区分文件类型） 拼接而成。</p><p>小总结：FastDFS上传文件成功后返回文件名由<strong>group、存储目录、两级子目录、fileid、文件后缀名</strong>组成</p><h4 id="下载机制"><a href="#下载机制" class="headerlink" title="下载机制"></a>下载机制</h4><p>​        客户端带上文件名信息请求Tracker服务获取到存储服务器的ip地址和端口，然后客户端根据返回的IP地址和端口号请求下载文件，存 储服务器接收到请求后返回文件给客户端。</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419141326561.png" alt="image-20220419141326561"></p><h6 id="内部机制如下"><a href="#内部机制如下" class="headerlink" title="内部机制如下"></a>内部机制如下</h6><p>1 client询问tracker下载文件的storage，参数为文件标识（组名和文件名） </p><p>2 tracker返回一台可用的storage </p><p> client直接和storage通讯完成文件下载</p><p>FastDFS分布式文件系统在下载文件的时候<strong>客户端带文件名请求</strong>&#x3D;&#x3D;Stroage&#x3D;&#x3D;</p><h3 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h3><p>准备安装在zk-03机器</p><p>下载安装GCC</p><pre class=" language-none"><code class="language-none">yum install gcc-c++ perl-devel pcre-devel openssl-devel zlib-devel wget</code></pre><p>传两文件过去</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418195342025.png" alt="image-20220418195342025"></p><p>V6是6.几的一个版本，V1是他的依赖包，都解压去&#x2F;usr&#x2F;local下</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418195755475.png" alt="image-20220418195755475"></p><p>然后也可以下载安装，我懒</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419141629434.png" alt="image-20220419141629434"></p><p>进去依赖包执行一下</p><pre class=" language-none"><code class="language-none">编译./make.sh安装./make.sh  install</code></pre><p>这样依赖就安装好了</p><p>然后去fastdfs目录下也重复编译安装步骤一次</p><p>复制配置文件</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418200724071.png" alt="image-20220418200724071"></p><h4 id="创建tracker服务"><a href="#创建tracker服务" class="headerlink" title="创建tracker服务"></a>创建tracker服务</h4><h5 id="创建tracker目录"><a href="#创建tracker目录" class="headerlink" title="创建tracker目录"></a>创建tracker目录</h5><p>mkdir -p &#x2F;data&#x2F;fastdfs&#x2F;tracker</p><h6 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h6><p>vim &#x2F;etc&#x2F;fdfs&#x2F;tracker.conf</p><p>搜索改目录并改端口</p><p>base_path&#x3D;&#x2F;data&#x2F;fastdfs&#x2F;tracker（需要预先创建）</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418201106850.png" alt="image-20220418201106850"></p><p>保存退出后</p><p>cd &#x2F;etc&#x2F;init.d&#x2F;</p><p>启动一下</p><p>.&#x2F;fdfs_trackerd start</p><p>检查tracker服务</p><p>netstat -lntup |grep fdfs</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418203414236.png" alt="image-20220418203414236"></p><h5 id="创建storage服务"><a href="#创建storage服务" class="headerlink" title="创建storage服务"></a>创建storage服务</h5><p>创建storage目录</p><pre class=" language-none"><code class="language-none">mkdir -p /data/fastdfs/storagemkdir -p /data/fastdfs/base</code></pre><p>修改配置文件</p><p>vim &#x2F;etc&#x2F;fdfs&#x2F;storage.conf</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418204336829.png" alt="image-20220418204336829"></p><p>然后搜serverport看一下是不是之前改的8888</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418204448189.png" alt="image-20220418204448189"></p><p>能看见两个角色就是启动成功</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418204647779.png" alt="image-20220418204647779"></p><p>还少一个客户端</p><p>修改Client配置文件</p><p>vim &#x2F;etc&#x2F;fdfs&#x2F;client.conf</p><p>然后也是改basepath和ip地址挤端口</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418204853250.png" alt="image-20220418204853250"></p><p>跟踪服务器要是有多台可以另一行</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418204840508.png" alt="image-20220418204840508"></p><p>创建目录</p><p>mkdir -p &#x2F;data&#x2F;fastdfs&#x2F;client</p><h3 id="FastDFS指令"><a href="#FastDFS指令" class="headerlink" title="FastDFS指令"></a>FastDFS指令</h3><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419142215345.png" alt="image-20220419142215345"></p><p>运维用的多    </p><h5 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h5><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419085819688.png" alt="image-20220419085819688"></p><h6 id="指令参数"><a href="#指令参数" class="headerlink" title="指令参数"></a>指令参数</h6><pre class=" language-none"><code class="language-none">fdfs_upload_file <config_file> <local_filename> [storage_ip:port][store_path_index]</code></pre><h6 id="参数含义："><a href="#参数含义：" class="headerlink" title="参数含义："></a>参数含义：</h6><p>1  <config_file>：配置文件路径 </config_file></p><p>2  <local_filename>：本地文件路径 </local_filename></p><p>3  [storage_ip:port] ：（可选参数）</p><p>4 [store_path_index] ：（可选参数）</p><p>注意： 上传文件后会返回文件在FastDFS中的唯一文件标识，即卷名 +文件名</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419090048051.png" alt="image-20220419090048051"></p><h5 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h5><h6 id="指令参数-1"><a href="#指令参数-1" class="headerlink" title="指令参数"></a>指令参数</h6><pre class=" language-none"><code class="language-none">fdfs_download_file <config_file> <file_id> [local_filename] [<download_offset><download_bytes>]</code></pre><h6 id="参数含义：-1"><a href="#参数含义：-1" class="headerlink" title="参数含义："></a>参数含义：</h6><p>1   <config_file>：配置文件路径 </config_file></p><p>2   <file_id>：文件在FastDFS中的唯一文件标识，即卷名+文件名 </file_id></p><p>3  [local_filename] ：文件下载地址</p><p>4  <download_offset>：（可选参数）文件下载开始时间 </download_offset></p><p>5  <download_bytes>：（可选参数）文件下载的字节数</download_bytes></p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419091454103.png" alt="image-20220419091454103"></p><h5 id="查看文件信息指令"><a href="#查看文件信息指令" class="headerlink" title="查看文件信息指令"></a>查看文件信息指令</h5><h6 id="指令参数-2"><a href="#指令参数-2" class="headerlink" title="指令参数"></a>指令参数</h6><pre class=" language-none"><code class="language-none">fdfs_file_info <config_file> <file_id></code></pre><p>参数含义： </p><p>1   <config_file>：配置文件路径 </config_file></p><p>2  <file_id>：文件在FastDFS中的唯一文件标识，即卷名+文件名</file_id></p><h5 id="删除指令"><a href="#删除指令" class="headerlink" title="删除指令"></a>删除指令</h5><pre class=" language-none"><code class="language-none">fdfs_delete_file <config_file> <file_id></code></pre><p>含义同上</p><h6 id="注意"><a href="#注意" class="headerlink" title="注意:"></a>注意:</h6><pre><code> 删除指令使用后，文件在该卷中的所有备份都会被删除，因为 卷内的存储节点会相互同步，故慎用。</code></pre><h2 id="SpringBoot操作FastDFS"><a href="#SpringBoot操作FastDFS" class="headerlink" title="SpringBoot操作FastDFS"></a>SpringBoot操作FastDFS</h2><p>由GitHub大牛tobato在原作者发布的客户端基础上进行大量重构而来</p><h5 id="主要特性"><a href="#主要特性" class="headerlink" title="主要特性"></a>主要特性</h5><ul><li>1 对关键部分代码加入了单元测试，便于理解与服务端的接口交易，提高接口质量 </li><li>2 将以前对byte硬解析风格重构为使用对象+注解的形式，尽量增强了代码的可读性 </li><li>3 支持对服务端的连接池管理 </li><li>4 支持上传图片时候检查图片格式，并且自动生成缩略图 </li><li>5 在SpringBoot当中自动导入依赖</li></ul><pre class=" language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!--引入fastdfs依赖--></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.github.tobato<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>fastdfs-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.26.5<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></code></pre><p>直接写在测试里的</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian;import com.github.tobato.fastdfs.domain.fdfs.StorePath;import com.github.tobato.fastdfs.domain.proto.storage.DownloadByteArray;import com.github.tobato.fastdfs.service.FastFileStorageClient;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import java.io.*;@SpringBootTestclass FastdfsDemoApplicationTests &#123;    //fastdfs存储节点的客户端对象    @Autowired    private FastFileStorageClient fastFileStorageClient;    /**     * 测试springboot下javaAPI对分布式文件系统上传文件操作     */    @Test    public void testUpload() throws FileNotFoundException &#123;        //1.读取本地文件        File file = new File("J:\\login.jpg");        //2.创建传输文件的输入流        FileInputStream fileInputStream = new FileInputStream(file);        //3.文件上传        /**         * 第一个参数：输入文件内容的输入流         * 文件大小         * 文件拓展名         * 描述文件的元数据         */        StorePath storePath = fastFileStorageClient.uploadFile(fileInputStream, file.length(), "jpg", null);        //4.将卷名和文件名一起打印        System.out.println(storePath.getFullPath());        //5.将卷名和文件名分开打印        System.out.println("------------------------");        System.out.println(storePath.getGroup());        System.out.println(storePath.getPath());        //group1/M00/00/00/wKgIEGJeEt-ALjUOAAqFA9rZsJU238.jpg        //------------------------        //group1        //M00/00/00/wKgIEGJeEt-ALjUOAAqFA9rZsJU238.jpg    &#125;    /**     * springboot环境下JavaApi对分布式文件系统的下载文件操作     */    @Test    public void testDownload() throws IOException &#123;        //1.下载文件        /**         * 第一个参数：文件处于存储节点卷名         * 文件名         * 下载回调函数         */        byte[] bytes = fastFileStorageClient.downloadFile("group1", "M00/00/00/wKgIEGJeEt-ALjUOAAqFA9rZsJU238.jpg", new DownloadByteArray());        //2.创建文件输出流        FileOutputStream fileOutputStream = new FileOutputStream("J:\\aaa.jpg");        //3.使用文件输出流将文件内容字节数组写出去        fileOutputStream.write(bytes);        //4.刷新一下输出流        fileOutputStream.flush();        //5.关闭流        fileOutputStream.close();    &#125;&#125;</code></pre><p>上传</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419094059528.png" alt="image-20220419094059528"></p><p>下载</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419100121712.png" alt="image-20220419100121712"></p><h3 id="文件上传-基于FastDFS实现"><a href="#文件上传-基于FastDFS实现" class="headerlink" title="文件上传-基于FastDFS实现"></a>文件上传-基于FastDFS实现</h3><p>就是上传到FastDFS里，而不是放在项目的某个目录下</p><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.springframework.boot<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spring-boot-starter-thymeleaf<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.springframework.boot<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spring-boot-starter-web<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></code></pre><p>写个index.html</p><pre class=" language-html"><code class="language-html"><span class="token doctype">&lt;!DOCTYPE html></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>html</span> <span class="token attr-name">lang</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>en<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>head</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">charset</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>UTF-8<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>title</span><span class="token punctuation">></span></span>LikeU.Admin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>title</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>icon<span class="token punctuation">"</span></span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>favicon.ico<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">charset</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>utf-8<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">http-equiv</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>X-UA-Compatible<span class="token punctuation">"</span></span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>IE<span class="token punctuation">=</span>edge<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>width<span class="token punctuation">=</span>device-width, initial-scale<span class="token punctuation">=</span>1, maximum-scale<span class="token punctuation">=</span>1, user-scalable<span class="token punctuation">=</span>no<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>viewport<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token comment" spellcheck="true">&lt;!--富文本编辑器wangEditor--></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>https://cdn.staticfile.org/wangEditor/10.0.13/wangEditor.min.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>https://cdn.staticfile.org/wangEditor/10.0.13/fonts/w-e-icon.woff<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>https://cdn.staticfile.org/wangEditor/10.0.13/wangEditor.min.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script language-javascript"></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>head</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>body</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>jumbotron<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>container<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>editor<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>欢迎使用富文本编辑器<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>btn btn-primary btn-lg<span class="token punctuation">"</span></span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>btnGenCode<span class="token punctuation">"</span></span> <span class="token attr-name">role</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>button<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>保存 »<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>body</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>text/javascript<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script language-javascript">    <span class="token keyword">var</span> E <span class="token operator">=</span> window<span class="token punctuation">.</span>wangEditor    <span class="token keyword">var</span> editor <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">E</span><span class="token punctuation">(</span><span class="token string">'#editor'</span><span class="token punctuation">)</span>       <span class="token comment" spellcheck="true">//配置服务端接口了</span>    editor<span class="token punctuation">.</span>customConfig<span class="token punctuation">.</span>uploadImgServer <span class="token operator">=</span><span class="token string">'/upload'</span>    <span class="token comment" spellcheck="true">//参数名字</span>    editor<span class="token punctuation">.</span>customConfig<span class="token punctuation">.</span>uploadFileName <span class="token operator">=</span><span class="token string">'file'</span>    <span class="token comment" spellcheck="true">//显示图片大小和类型</span>    editor<span class="token punctuation">.</span>customConfig<span class="token punctuation">.</span>uploadImgMaxSize <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token comment" spellcheck="true">//2M</span>    editor<span class="token punctuation">.</span>customConfig<span class="token punctuation">.</span>uploadImgAccept <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'jpg'</span><span class="token punctuation">,</span> <span class="token string">'jpeg'</span><span class="token punctuation">,</span> <span class="token string">'png'</span><span class="token punctuation">,</span> <span class="token string">'gif'</span><span class="token punctuation">,</span> <span class="token string">'bmp'</span><span class="token punctuation">,</span> <span class="token string">'webp'</span><span class="token punctuation">]</span>    editor<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//以下是博客别人的写法</span>    <span class="token comment" spellcheck="true">// 配置服务器端地址</span>    <span class="token comment" spellcheck="true">//  editor.customConfig.uploadImgServer = 'http://localhost:8080/upload/editor'</span>    <span class="token comment" spellcheck="true">//配置指定文件名</span>    <span class="token comment" spellcheck="true">// editor.customConfig.uploadFileName = 'file'</span>    <span class="token comment" spellcheck="true">//如果图片不大，可以用base64存储</span>    <span class="token comment" spellcheck="true">//editor.customConfig.uploadImgShowBase64 = true</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>html</span><span class="token punctuation">></span></span></code></pre><p>wangEditor富文本编辑器</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419111505928.png" alt="image-20220419111505928"></p><p>配置</p><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true">#############分布式文件系统的配置#########</span><span class="token key atrule">fdfs</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">#超时时间</span>  <span class="token key atrule">connect-timeout</span><span class="token punctuation">:</span> <span class="token number">600</span>  <span class="token comment" spellcheck="true">#连接时间</span>  <span class="token key atrule">so-timeout</span><span class="token punctuation">:</span> <span class="token number">1500</span>  <span class="token key atrule">tracker-list</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> 192.168.8.16<span class="token punctuation">:</span><span class="token number">22122</span></code></pre><h6 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h6><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.controller;import com.github.tobato.fastdfs.domain.fdfs.StorePath;import com.github.tobato.fastdfs.service.FastFileStorageClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.multipart.MultipartFile;import java.io.IOException;/** * 图片控制层 */@RestControllerpublic class UploadController &#123;    //fastdfs存储节点的客户端对象    @Autowired    private FastFileStorageClient fastFileStorageClient;    /**     * 图片上传     * @param file     */    @PostMapping("/upload")//图片上传，必须post请求    public void upload(MultipartFile file) throws IOException &#123;        //1.判断文件是否为空        if(file!=null)&#123;            //2.获取上传图片名字            String filename = file.getOriginalFilename();            //3.图片后缀名 jpg            String fileSuffix = filename.substring(filename.lastIndexOf("."));            //4.上传图片            StorePath storePath = fastFileStorageClient.uploadFile(file.getInputStream(), file.getSize(), fileSuffix, null);            //5.上传成功返回图片路径            System.out.println(storePath.getFullPath());            //TODO 保存到数据库  jdbc  mybatis plus        &#125;    &#125;&#125;</code></pre><p>然后一次性上传图片限制的话，控制器就得是数组接收了</p><p>然后上传成功得有返回值，这就不整了，运行项目，上传图片，进去断点</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419143733498.png" alt="image-20220419143733498"></p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419111257653.png" alt="image-20220419111257653"></p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419111351266.png" alt="image-20220419111351266"></p><h2 id="FastDFS集成Nginx"><a href="#FastDFS集成Nginx" class="headerlink" title="FastDFS集成Nginx"></a>FastDFS集成Nginx</h2><p>Nginx服务器是一个高性能的web服务器与反向代理服务器。</p><p>当只有静态资源的时候我们也可以使用Nginx来作为服务器</p><h4 id="FastDFS集成Nginx的2个原因"><a href="#FastDFS集成Nginx的2个原因" class="headerlink" title="FastDFS集成Nginx的2个原因"></a>FastDFS集成Nginx的2个原因</h4><h5 id="1-为分布式文件系统提供Http服务支持"><a href="#1-为分布式文件系统提供Http服务支持" class="headerlink" title="1 为分布式文件系统提供Http服务支持"></a>1 为分布式文件系统提供Http服务支持</h5><p>​        通过Nginx的web服务代理访问分布式文件系统的存储节点，从而实现通过http请求访问存储节点资源。</p><h5 id="2-解决复制延迟问题"><a href="#2-解决复制延迟问题" class="headerlink" title="2 解决复制延迟问题"></a>2 解决复制延迟问题</h5><p>​        由于FastDFS的同卷的存储节点之间需要同步，当文件尚未同步完 成时，访问请求到达改节点，获取的数据将是未同步完的不完整数 据，即为复制延迟问题。通过Nginx检测请求的存储节点的数据， 若该存储节点的数据尚未同步完成，则将请求转发至数据的原存储 节点，从而解决复制延迟问题。</p><h3 id="环境搭建-1"><a href="#环境搭建-1" class="headerlink" title="环境搭建"></a>环境搭建</h3><p>我就懒直接传进去安装包</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419112455553.png" alt="image-20220419112455553"></p><h5 id="下载方式"><a href="#下载方式" class="headerlink" title="下载方式"></a>下载方式</h5><p>下载Fast DFS的Nginx模块包</p><pre class=" language-none"><code class="language-none">wget https://github.com/happyfish100/fastdfs-nginx-module/archive/V1.22.tar.gz</code></pre><p>下载Nginx软件包</p><pre class=" language-none"><code class="language-none">wget https://nginx.org/download/nginx-1.19.2.tar.gz</code></pre><p>解压到local下</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419112701751.png" alt="image-20220419112701751"></p><p>安装nginx依赖</p><pre class=" language-none"><code class="language-none">yum install -y gcc gcc-c++ zlib zlib-devel openssl openssl-devel pcre pcre-devel gd-devel epel-release</code></pre><p>检查</p><p>.&#x2F;configure –add-module&#x3D;&#x2F;usr&#x2F;local&#x2F;fastdfs-nginx-module-1.22&#x2F;src</p><p>make</p><p>make install</p><p>然后在这个nginx就可以使用这个模块了</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419132532506.png" alt="image-20220419132532506"></p><p>​    进去</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419132613471.png" alt="image-20220419132613471"></p><p>拷贝文件</p><pre class=" language-none"><code class="language-none">cp mime.types /etc/fdfs/cp http.conf /etc/fdfs/然后去/usr/local/fastdfs-nginx-module-1.22/srccp mod_fastdfs.conf /etc/fdfs/切换到/etc/fdfs/vim mod_fastdfs.conf </code></pre><p>改这个</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419133019512.png" alt="image-20220419133019512"></p><p>还有这服务器地址</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419133104343.png" alt="image-20220419133104343"></p><p>文件url中是否有group的名字</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419133129909.png" alt="image-20220419133129909"></p><p>还有这个</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419133224807.png" alt="image-20220419133224807"></p><p>切换目录</p><p>&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf</p><p>vim nginx.conf</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419133833315.png" alt="image-20220419133833315"></p><p>启动一下</p><p>.&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419133959908.png" alt="image-20220419133959908"></p><p>安装一下lsof</p><p>yum install lsof</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419134134944.png" alt="image-20220419134134944"></p><h6 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h6><p>上传一张图片</p><p>先搞张图片放在opt下</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419134832345.png" alt="image-20220419134832345"></p><p>然后复制路径反手打开一个浏览器</p><p>然后就可以通过nginx+fastdfs访问网络上的图片资源</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419134948622.png" alt="image-20220419134948622"></p><h4 id><a href="#" class="headerlink" title></a></h4>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>springboot整合sawgger报错</title>
      <link href="/2022/04/13/springboot-zheng-he-sawgger-bao-cuo/"/>
      <url>/2022/04/13/springboot-zheng-he-sawgger-bao-cuo/</url>
      
        <content type="html"><![CDATA[<h4 id="报错内容"><a href="#报错内容" class="headerlink" title="报错内容"></a>报错内容</h4><p>Failed to start bean ‘documentationPluginsBootstrapper</p><p><strong>解决swagger空指针问题，或者springboot切换到2.6以下的版本</strong>，同样一模一样的代码，换了之后就可以</p><p><img src="/2022/04/13/springboot-zheng-he-sawgger-bao-cuo/image-20220307131609357.png" alt="image-20220307131609357"></p><p>​        一开始网上的各种解决方都试过了，比如依赖循环？？swagger依赖Google的guava，加一个最新版本的guava？编写swagger配置类？JDK问题？但是我用的是jdk1.8不会有问题的呀？？？</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>恢复VMware左侧目录</title>
      <link href="/2022/04/13/hui-fu-wu-guan-vmware-zuo-ce-xu-ni-ji-mu-lu/"/>
      <url>/2022/04/13/hui-fu-wu-guan-vmware-zuo-ce-xu-ni-ji-mu-lu/</url>
      
        <content type="html"><![CDATA[<h5 id="或者点这里"><a href="#或者点这里" class="headerlink" title="或者点这里"></a>或者点这里</h5><p><img src="/2022/04/13/hui-fu-wu-guan-vmware-zuo-ce-xu-ni-ji-mu-lu/image-20220413195134345.png" alt="image-20220413195134345"></p><h6 id><a href="#" class="headerlink" title></a></h6>]]></content>
      
      
      <categories>
          
          <category> other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小失误 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dubbo笔记</title>
      <link href="/2022/04/13/dubbo-bi-ji/"/>
      <url>/2022/04/13/dubbo-bi-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="二、-Dubbo-架构讲解"><a href="#二、-Dubbo-架构讲解" class="headerlink" title="二、 Dubbo 架构讲解"></a>二、 Dubbo 架构讲解</h2><h3 id="1-架构图"><a href="#1-架构图" class="headerlink" title="1.架构图"></a>1.架构图</h3><p>Provider在运行时是要依赖于IOC容器的</p><p>1.发布 2.订阅</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220228185855334.png" alt="image-20220228185855334"></p><p>先把Spring启动，而且Provider；最终会缓存到Spring的IOC容器当中。Provider启动好以后，第二步，就是去注册中心（Registry）中注册，也叫服务的注册与发布，接下来就是启动Consumer（服务的消费者，也就是谁调用我们的Provider），然后Consumer启动时，就完成了架构图中的第二步，也就是服务的订阅。因为Consumer要去调用Provider，它肯定得知道Provider的一些信息（IP，端口，暴露的服务等），而这些信息，Provider启动的时候都已经放到了注册中心当中了，那Consumer启动去链接注册中心，从注册中心去订阅这些信息，那Consumer不就拿到或者已知了Ip地址和服务的名字是什么等。</p><p>3就是通知，之前说过zookeeper是有观察者模式的，当Provider发生变化之后就会通知我们的Consumer，那在Dubbo当中我们就可以使用zookeeper作为注册中心。那下面，4，当我们把Provider和Consumer都启动好了，Consumer就可以调用Provider的服务了，也就是实现invoke，唯独只有这一条线是实线，因为它调用时基于同步的方式来调用的。</p><p>再来说说，还记得学java时候，方法的调用有两种，一种是并发的，一种是串行化的，比如没有涉及到多线程编程，那所有的方法就是串行化的（就比如A调用B，A要等B执行完了之后回到调用点再往下走），要是基于多线程的方式，那多线程就不叫调用方法了，叫启动方法，就是一个线程启动方法，启动完不管，继续往下走再启动再往下走，也就是异步的方法调用。所以我们要知道Consumer在调用Provider的时候是同步的，那就会有一个线程阻塞的情况出现，也就是只有Provider的代码执行完了，Consumer才会继续往下执行。</p><p>那剩下就还有一个Monitor，作用就是监控中心，每隔 2 分钟 Consumer 和 Provider 会把数据包发送给 Monitor，所以它就能实时的知道他们两的服务的压力或者像服务的基本信息等，然后来对这些信息做一个统计。</p><h3 id="2-架构说明"><a href="#2-架构说明" class="headerlink" title="2 架构说明"></a>2 架构说明</h3><h5 id="2-1虚线"><a href="#2-1虚线" class="headerlink" title="2.1虚线"></a>2.1虚线</h5><p>虚线表示异步，实线表示同步。异步不阻塞线程性能高，同步阻塞线程必须等待响应结果才能继续执行，相对性能低。 </p><h5 id="2-2Provider"><a href="#2-2Provider" class="headerlink" title="2.2Provider"></a>2.2Provider</h5><p>暴露服务的服务提供方。 </p><h5 id="2-3Container"><a href="#2-3Container" class="headerlink" title="2.3Container"></a>2.3Container</h5><p>服务运行容器。Dubbo 完全基于 Spring 实现的。 </p><h5 id="2-4Registry"><a href="#2-4Registry" class="headerlink" title="2.4Registry"></a>2.4Registry</h5><p>服务注册与发现的注册中心。注册中心，放置所有 Provider 对外提供的信息。包含 Provider 的 IP，访问端口，访问遵守的协议，对外提供的接口，接口中有哪些方法等相关信 息。 </p><h5 id="2-5Consumer"><a href="#2-5Consumer" class="headerlink" title="2.5Consumer"></a>2.5Consumer</h5><p>调用远程服务的服务消费方。 </p><h5 id="2-6Monitor"><a href="#2-6Monitor" class="headerlink" title="2.6Monitor"></a>2.6Monitor</h5><p>统计服务的调用次调和调用时间的监控中心。监控中心，监控 Provider 的压力情况等。 每隔 2 分钟 Consumer 和 Provider 会把调用次数发送给 Monitor，由 Monitor 进行统计。 </p><h3 id="3-执行流程"><a href="#3-执行流程" class="headerlink" title="3 执行流程"></a>3 执行流程</h3><ol start="0"><li><p>start：启动 Spring 容器时会把 Provider 启动。 </p></li><li><p>register：把 Provider 相关信息注册到 Registry 里 </p></li><li><p>subscribe：Consumer 从 Registry 中订阅 Provider 的信息 </p></li><li><p>notify：通知给 Consumer </p></li><li><p>invoke：Consumer 根据 Registry 通知的信息进行调用 Provider 中方法。</p></li><li><p>count:Consumer 和 Provider 把调用次数信息异步发送给 Monitor 进行统计</p></li></ol><h2 id="三、-Dubbo-支持的协议"><a href="#三、-Dubbo-支持的协议" class="headerlink" title="三、 Dubbo 支持的协议"></a>三、 Dubbo 支持的协议</h2><h3 id="1-Dubbo-协议-官方推荐协议"><a href="#1-Dubbo-协议-官方推荐协议" class="headerlink" title="1 Dubbo 协议(官方推荐协议)"></a>1 Dubbo 协议(官方推荐协议)</h3><p>优点： </p><p>​    采用 NIO 复用单一长连接，并使用线程池并发处理请求，减少握手和加大并发效率， 性能较好（推荐使用） </p><p>缺点： </p><p>​    大文件上传时,可能出现问题(不使用 Dubbo 文件上传) </p><p>同步的调用方式，在做文件上传时，由于文件上传的容量比较大，就会导致调用的过程是非常耗时的，如果链接的时间很长，就可能会涉及到超时的一些问题，所以一般我们都不使用Dubbo来做文件上传，在Consumer就去做了，我们用Dubbo要做的是就是把上传的文件名保存到我们的数据库当中</p><h3 id="2-RMI-Remote-Method-Invocation-协议"><a href="#2-RMI-Remote-Method-Invocation-协议" class="headerlink" title="2 RMI(Remote Method Invocation)协议"></a>2 RMI(Remote Method Invocation)协议</h3><p>优点: </p><p>​    JDK 自带的能力。 </p><p>缺点: </p><p>​    偶尔连接失败. </p><h3 id="3-Hessian-协议"><a href="#3-Hessian-协议" class="headerlink" title="3 Hessian 协议"></a>3 Hessian 协议</h3><p>优点: </p><p>​    可与原生 Hessian 互操作，基于 HTTP 协议 </p><p>缺点:</p><p>​     需 hessian.jar 支持，http短链接的开销很大</p><p>Hessian，基于Http，就是A请求B，相应了，完事了，一会再请求，还得在再建立一次链接。那我们在使用Dubbo的时候使用哪种协议，就是使用官方推荐的Dubbo协议，来完成远程服务的一个调用</p><h2 id="四、-Dubbo-支持的注册中心"><a href="#四、-Dubbo-支持的注册中心" class="headerlink" title="四、 Dubbo 支持的注册中心"></a>四、 Dubbo 支持的注册中心</h2><h4 id="1-Zookeeper-官方推荐"><a href="#1-Zookeeper-官方推荐" class="headerlink" title="1 Zookeeper(官方推荐)"></a>1 Zookeeper(官方推荐)</h4><p>优点: 支持分布式.很多周边产品. </p><p>缺点: 受限于 Zookeeper 软件的稳定性。Zookeeper 是一款专门为分布式架构提供辅助型处 理的软件，稳定较优。 </p><h4 id="2-Multicast"><a href="#2-Multicast" class="headerlink" title="2 Multicast"></a>2 Multicast</h4><ol><li>优点: 去中心化,不需要单独安装软件. </li><li>缺点: Provider 和 Consumer 和 Registry 不能跨机房(路由)</li></ol><h4 id="3-Redis"><a href="#3-Redis" class="headerlink" title="3.Redis"></a>3.Redis</h4><ol><li>优点: 支持集群,性能高 </li><li>缺点: 要求服务器时间同步.否则可能出现集群失败问题.</li></ol><h4 id="4-Simple"><a href="#4-Simple" class="headerlink" title="4.Simple"></a>4.Simple</h4><ol><li>优点: 标准 RPC 服务.没有兼容问题 </li><li>缺点: 不支持集群</li></ol><h1 id="Dubbo概念-核心组件"><a href="#Dubbo概念-核心组件" class="headerlink" title="Dubbo概念_核心组件"></a>Dubbo概念_核心组件</h1><h4 id="注册中心Registry"><a href="#注册中心Registry" class="headerlink" title="注册中心Registry"></a>注册中心Registry</h4><p>Dubbo微服务体系中，注册中心是其核心组件之一。Dubbo通过 注册中心实现了分布式环境中各服务之间的注册与发现，是各个分 布式节点之间的纽带。</p><h5 id="其主要作用如下"><a href="#其主要作用如下" class="headerlink" title="其主要作用如下:"></a>其主要作用如下:</h5><p>动态加入：一个服务提供者通过注册中心可以动态地把自己暴露给其他消费者，无须消费者逐个去更新配置文件。 </p><p>动态发现：一个消费者可以动态地感知新的配置、路由规则和新的服务提供者，无须重启服务使之生效。 </p><p>动态调整：注册中心支持参数的动态调整，新参数自动更新到所有相关服务节点。 </p><p>统一配置：避免了本地配置导致每个服务的配置不一致问题。</p><p>常见的注册中心有zookeeper 、eureka、consul、etcd。</p><h4 id="服务提供者Provider"><a href="#服务提供者Provider" class="headerlink" title="服务提供者Provider"></a>服务提供者Provider</h4><p>服务的提供方 </p><h4 id="服务消费者Consumer"><a href="#服务消费者Consumer" class="headerlink" title="服务消费者Consumer"></a>服务消费者Consumer</h4><p>调用远程服务的服务消费方</p><h4 id="监控中心Monitor"><a href="#监控中心Monitor" class="headerlink" title="监控中心Monitor"></a>监控中心Monitor</h4><p>主要负责监控统计调用次数和调用时间等。</p><h3 id="配置开发环境-Zookeeper注册中心"><a href="#配置开发环境-Zookeeper注册中心" class="headerlink" title="配置开发环境_Zookeeper注册中心"></a>配置开发环境_Zookeeper注册中心</h3><p>这里就是在docker安装一个zookeeper了</p><p>docker拉去镜像</p><pre class=" language-none"><code class="language-none">docker pull zookeeper</code></pre><p>启动运行容器</p><p>docker run –name zk -d -p 2181:2181 zookeeper            </p><p>进入容器</p><p>docker exec -it zk &#x2F;bin&#x2F;bash</p><p>exec：在运行的容器厚葬执行命令</p><p>-it：交互式</p><p>然后进去bin一下客户端</p><p>.&#x2F;zkCli.sh 连接</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220411152821009.png" alt="image-20220411152821009">然后就可以Ctrl+c退出和exit退出容器了</p><h3 id="配置开发环境-管理控制台"><a href="#配置开发环境-管理控制台" class="headerlink" title="配置开发环境_管理控制台"></a>配置开发环境_管理控制台</h3><h5 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h5><p>Dubbo-admin管理平台，图形化的服务管理页面，安装时需要指定 注册中心地址，即可从注册中心中获取到所有的提供者&#x2F;消费者进行 配置管理。</p><p>还是使用docker来安装</p><h5 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h5><pre class=" language-bash"><code class="language-bash">docker pull docker.io/apache/dubbo-admin</code></pre><p>启动运行容器</p><pre class=" language-bash"><code class="language-bash">docker run -d \-p 9600:8080 -e admin.registry.address<span class="token operator">=</span>zookeeper://192.168.8.11:2181 -e admin.config-center<span class="token operator">=</span>zookeeper://192.168.8.11:2181 -e admin.metadata-report.address<span class="token operator">=</span>zookeeper://192.168.8.11:2181 --restart<span class="token operator">=</span>always docker.io/apache/dubbo-admin</code></pre><h5 id="参数："><a href="#参数：" class="headerlink" title="参数："></a>参数：</h5><p>–restart：always 容器退出时总是重启 </p><p>admin.registry.address：注册中心 </p><p>admin.config-center：配置中心 </p><p>admin.metadata-report.address：元数据中心</p><p>不是docker的话就特别复杂，通过docker就可以一键启动</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220411154623785.png" alt="image-20220411154623785"></p><h5 id="可视化界面"><a href="#可视化界面" class="headerlink" title="可视化界面"></a>可视化界面</h5><p><img src="/2022/04/13/dubbo-bi-ji/image-20220411154734327.png" alt="image-20220411154734327"></p><p>账号密码都是root</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220411155422661.png" alt="image-20220411155422661"></p><p>当然，服务现在还是没有的，因为dubbo还没开发服务</p><h2 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a>高级特性</h2><h3 id="地址缓存"><a href="#地址缓存" class="headerlink" title="地址缓存"></a>地址缓存</h3><p><strong>服务生产者地址会缓存</strong></p><p>面试的时候可能会问的</p><p>就是Dubbo注册中心挂了，服务是否可以正常访问？？</p><p>答：因为dubbo服务消费者在第一次调用时 ， 会将服务提供方地址缓存到本地 ，以后在调用则不会访问注册中心。服务提供者地址发生变化时，注册中心会通服务消费者。</p><p>可以手动去docker里面关掉zookeeper，会发现两个案例还是可以访问的</p><h3 id="超时时间域配置覆盖关系"><a href="#超时时间域配置覆盖关系" class="headerlink" title="超时时间域配置覆盖关系"></a>超时时间域配置覆盖关系</h3><p>超时机制也是保护服务的一种手段</p><p>就是调用去查，然后耗时很久，又没有拿到数据，那不就是一直在等</p><p>那高并发情景下，很多用户都要访问这个服务，都去请求生产者，线程堆积，<strong>服务雪崩</strong></p><p>问题： </p><ul><li>服务消费者在调用服务提供者的时候发生了阻塞、等待的情形，这个时候，服务消费者会一 直等待下去。 </li><li>在某个峰值时刻，大呈的请求都在同时请求服务消费者，会造成线程的大呈堆积，势必会造 成雪崩。 </li><li>dubbo利用超时机制来解决这个问题，设置一个超时时间，在这个时间段内，无法完成服务访问，则自动断开连接。</li></ul><h4 id="配置超时时间"><a href="#配置超时时间" class="headerlink" title="配置超时时间"></a>配置超时时间</h4><p>就可以在两个dubbo注解中加timeout属性</p><h5 id="生产端"><a href="#生产端" class="headerlink" title="生产端"></a>生产端</h5><p>使用timeout属性配置超时时间，默认值1000，单位毫秒。</p><p>服务生产者配3000就是：3s数据库没返回就断开</p><h5 id="消费端"><a href="#消费端" class="headerlink" title="消费端"></a>消费端</h5><p>服务消费者配2000就是：2s服务生产者返回就断开</p><h4 id="超时时间优先级"><a href="#超时时间优先级" class="headerlink" title="超时时间优先级"></a>超时时间优先级</h4><p>上面有提到dubbo支持多种场景下设置超时时间，也说过超时是针 对消费端的。那么既然超时是针对消费端，为什么服务端也可以设置超时呢？</p><p><strong>总结：</strong></p><p>​        这其实是一种策略，其实服务端的超时配置是消费端的缺省配 置，即如果服务端设置了超时，任务消费端可以不设置超时时间，简化了配置。另外针对控制的粒度，Dubbo支持了接口级 别也支持方法级别，可以根据不同的实际情况精确控制每个方 法的超时时间。</p><p>然后就是在企业中不建议把超时时间配置在Reference里面</p><p>为什么？？</p><p>一般来说就是谁开发的接口，谁去Service里定义，就是测试的时候测出来多少秒，然后写的时间稍微大一些</p><p><strong>Reference的优先级比较高，所以说就是Reference的超时时间会覆盖掉Service的</strong></p><h3 id="重试机制"><a href="#重试机制" class="headerlink" title="重试机制"></a>重试机制</h3><p>超时问题： </p><p>如果出现网络抖动，则会出现请求失败。</p><p>如何解决 ：</p><p>Dubbo提供重试机制来避免类似问题的发生。</p><h5 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h5><p>Service里面加一个retries &#x3D; 次数</p><p><strong>Dubbo在调用服务不成功时，默认会重试两次。</strong></p><p>就是超时机制和重试都是有默认的，就是你不配置也有这个功能</p><p><strong>如果消费者配置了重试次数，提供者也配置了重试次数，则以消费者为准</strong></p><h3 id="多版本"><a href="#多版本" class="headerlink" title="多版本"></a>多版本</h3><p>Dubbo提供多版本的配置，方便我们做服务的灰度发布，或者是解决不兼容的问题。</p><h5 id="灰度发布-金丝雀发布-："><a href="#灰度发布-金丝雀发布-：" class="headerlink" title="灰度发布(金丝雀发布)："></a>灰度发布(金丝雀发布)：</h5><p>当出现新功能时，会让一部分用户先使用新功能，用户反馈没 问题时，再将所有用户迁移到新功能。</p><h5 id="版本迁移步骤"><a href="#版本迁移步骤" class="headerlink" title="版本迁移步骤"></a>版本迁移步骤</h5><p>1 在低压力时间段，先升级一半提供者为新版本 </p><p>2 再将所有消费者升级为新版本 </p><p>3 然后将剩下的一半提供者升级为新版本</p><p>就是Service里一个version属性，<strong>Reference里面一个version属性，决定服务提供者的版本</strong></p><p>如果不需要区分版本：</p><p>配个”*”</p><p>按道理来说就是不同的版本要部署在不同的服务器上</p><p>这里就是老版本运行，然后直接修改版本和设置的数据，再改一下dubbo的端口（因为我们所有都在一个机器）</p><p>复制后改名就行</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220412131232185.png" alt="image-20220412131232185"></p><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>Dubbo是一个分布式服务框架，能避免单点故障和支持服务的横向扩容。一个服务通常会部署多个实例。</p><h5 id="Dubbo内置负载均衡策略"><a href="#Dubbo内置负载均衡策略" class="headerlink" title="Dubbo内置负载均衡策略"></a>Dubbo内置负载均衡策略</h5><p>1 RandomLoadBalance：随机负载均衡，随机的选择一个，默认负载均衡。 </p><p>2 RoundRobinLoadBalance：轮询负载均衡。 </p><p>3 LeastActiveLoadBalance：最少活跃调用数，相同活跃数的随机。</p><p>4 ConsistentHashLoadBalance：一致性哈希负载均衡，相同参数的请求总是落在同一台机器上。</p><h5 id="负载均衡策略配置"><a href="#负载均衡策略配置" class="headerlink" title="负载均衡策略配置"></a>负载均衡策略配置</h5><p>如果不指定负载均衡，默认使用随机负载均衡。我们也可以根据自己的需要，显式指定一个负载均衡。</p><p>生产方消费方都可以配置</p><p>就是去掉版本，然后改端口，再复制服务改名启动就行</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220412141552680.png" alt="image-20220412141552680"></p><p>然后点开管理面板查看服务提供者就会看见你启动的多个了</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220412142036873.png" alt="image-20220412142036873"></p><p>不记得配置的名字就可以直接两下shirt搜balance，去dubbo的AbstractLoadBalance，然后进去他实现类第一行就是一个他对应的配置的名字</p><p><strong>就是出现订单生产者集群之后才需要选择负载均衡的策略</strong></p><h3 id="集群容错"><a href="#集群容错" class="headerlink" title="集群容错"></a>集群容错</h3><p>Dubbo框架为服务集群容错提供了一系列好的解决方案，在此称为 dubbo服务集群容错模式。</p><h4 id="容错模式"><a href="#容错模式" class="headerlink" title="容错模式"></a>容错模式</h4><ul><li>Failover Cluster：失败重试。默认值。当出现失败，重试其它服务器，默认重试2次，使用 retries配置。一般用于读操作 </li><li>Failfast Cluster : 快速失败，只发起一次调用，失败立即报错。通常用于写操作。 </li><li>Failsafe Cluster : 失败安全，出现异常时，直接忽略。返回一个空结果。日志不重要操作。 </li><li>Failback Cluster : 失败自动恢复，后台记录失败请求，定时重发。非常重要的操作。 </li><li>Forking Cluster：并行调用多个服务器，只要有一个成功即返回。 </li><li>Broadcast Cluster：广播调用所有提供者，逐个调用，任意一台报错则报错。 同步要求高的可以 使用这个模式。</li></ul><p>接口幂等性：</p><p>就是不管前端这块卡了还是咋样，用户肯定会点点点，但是最终数据库都只有一条，就是幂等性</p><p>所以快速失败就是解决幂等性问题</p><p>海枯石烂发到成功–Failback</p><h4 id="集群容错配置"><a href="#集群容错配置" class="headerlink" title="集群容错配置"></a>集群容错配置</h4><p>就是Reference配置一个cluster就行</p><h3 id="服务降级"><a href="#服务降级" class="headerlink" title="服务降级"></a>服务降级</h3><p>​    服务降级，当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心 任务的正常运行。</p><p>两种场景： </p><ul><li>当下游的服务因为某种原因响应过慢，下游服务主动停掉一些不太重要的业务，释放出服务 器资源，增加响应速度！ </li><li>当下游的服务因为某种原因不可用，上游主动调用本地的一些降级逻辑，避免卡顿，迅速返回给用户！</li></ul><h5 id="为什么需要降级"><a href="#为什么需要降级" class="headerlink" title="为什么需要降级"></a>为什么需要降级</h5><p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心 服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即 使是有损服务。</p><p>就比如订单都快运行不了了，还要你的日志服务干嘛。</p><h5 id="服务降级方式"><a href="#服务降级方式" class="headerlink" title="服务降级方式"></a>服务降级方式</h5><p>也是在消费方</p><h6 id="第一种"><a href="#第一种" class="headerlink" title="第一种"></a>第一种</h6><pre class=" language-none"><code class="language-none">mock="force:return null"</code></pre><p><strong>含义：</strong></p><p>​        表示消费方对该服务的方法调用都直接返回null值，不发起远程 调用。用来屏蔽不重要服务不可用时对调用方的影响。</p><h6 id="第二种"><a href="#第二种" class="headerlink" title="第二种"></a>第二种</h6><pre class=" language-none"><code class="language-none">mock="fail:return null"</code></pre><p><strong>含义</strong>：</p><p> 表示消费方对该服务的方法调用在失败后，再返回null值，不抛 异常。用来容忍不重要服务不稳定时对调用方的影响。</p><p> Dubbo技术中服务降级解决___保证核心服务可用___问题</p><h3 id="服务限流原理"><a href="#服务限流原理" class="headerlink" title="服务限流原理"></a>服务限流原理</h3><h4 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h4><h5 id="漏桶算法"><a href="#漏桶算法" class="headerlink" title="漏桶算法"></a>漏桶算法</h5><p><img src="/2022/04/13/dubbo-bi-ji/image-20220413184111583.png" alt="image-20220413184111583"></p><p><strong>原理</strong>： </p><p>​        漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一 定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶 算法能强行限制数据的传输速率。</p><h5 id="令牌桶算法"><a href="#令牌桶算法" class="headerlink" title="令牌桶算法"></a>令牌桶算法</h5><p><img src="/2022/04/13/dubbo-bi-ji/image-20220413184148175.png" alt="image-20220413184148175"></p><p>原理: </p><p>​        令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令 牌，而如果请求需要被处理，则需要先从桶里获取一个令牌， 当桶里没有令牌可取时，则拒绝服务。</p><h5 id="漏桶-vs-令牌桶的区别"><a href="#漏桶-vs-令牌桶的区别" class="headerlink" title="漏桶 vs 令牌桶的区别"></a>漏桶 vs 令牌桶的区别</h5><p>漏桶的天然特性决定了它不会发生突发流量，就算每秒1000个请求 到来，那么它对后台服务输出的访问速率永远恒定。而令牌桶则不 同，其特性可以“预存”一定量的令牌，因此在应对突发流量的时候 可以在短时间消耗所有令牌，其突发流量处理效率会比漏桶高，但 是导向后台系统的压力也会相应增多。</p><p>限流技术主要解决___保护系统___问题?</p><p>限流算法中___令牌桶算法___算法具有应对突发性的流量?</p><h3 id="服务限流实现"><a href="#服务限流实现" class="headerlink" title="服务限流实现"></a>服务限流实现</h3><p>​        为了防止某个消费者的QPS或是所有消费者的QPS总和突然飙升而 导致的重要服务的失效，系统可以对访问流量进行控制，这种对集 群的保护措施称为服务限流。</p><h5 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h5><pre class=" language-none"><code class="language-none">@Service(executes = 10)</code></pre><p>注意： 服务端并发执行（或占用线程池线程数）不能超过10个</p><h5 id="连接控制"><a href="#连接控制" class="headerlink" title="连接控制"></a>连接控制</h5><pre class=" language-none"><code class="language-none"> @Service(actives= 10)</code></pre><p>注意： 占用连接的请求的数不能超过10个。</p><h3 id="结果缓存"><a href="#结果缓存" class="headerlink" title="结果缓存"></a>结果缓存</h3><p>就是Reference里的cache属性</p><p>通过原子类的方式实现自增的效果<br><img src="/2022/04/13/dubbo-bi-ji/image-20220412163942544.png" alt="image-20220412163942544"></p><p>这个方法会进入一个无限循环体内，就不断自增赋值给自己，如果失败了就说明别的线程已经获取设置了，然后又继续循环自增    </p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220412164659080.png" alt="image-20220412164659080"></p><p>刷新就会一直往后自增，说明服务的消费者一直在消费用户生产者，一直远程调用</p><p>然后去Reference加一个cache&#x3D;”lru”</p><p>加了之后就会把我们的结果缓存起来，就不会一直去发生远程调用，这就是结果缓存</p><p>刷新刷来刷去都是0和12</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220412164915129.png" alt="image-20220412164915129"></p><p>这里就是服务消费者加缓存了</p><p>那要是想服务生产者加缓存怎么办？？</p><p>​    就直接引入一个redis就可以，或者将缓存加到java的内存中都是可以的</p><p>主要解决问题，响应慢</p><h2 id="项目打包"><a href="#项目打包" class="headerlink" title="项目打包"></a>项目打包</h2><h3 id="1-基于-SpringBoot-整合-Dubbo-的打包方式"><a href="#1-基于-SpringBoot-整合-Dubbo-的打包方式" class="headerlink" title="1 基于 SpringBoot 整合 Dubbo 的打包方式"></a>1 基于 SpringBoot 整合 Dubbo 的打包方式</h3><p>通过 SpringBoot 打包插件打包项目</p><p>一定要注意的就是，一定要包含打包插件。</p><p>笔记里面的是没有版本的，然后显示artifactId not found，搜到的解决方案就是加版本就好了，确实也是添加版本之后就没有问题了</p><p>打包consumer的时候一直报错没有找到服务接口api的jar，想了一想，然后去把api项目先install了一下，这样就有api的jar了，之后发现确实是这样子，但是然后又报错There are test failures.，，就是鬼知道在test里添加了什么代码，只要点一下一排按钮的那个闪电按钮，就是不测试直接打包就可以了，但是我的lifeCycle里的install好像打包完也没有看见有jar呀，原来我把显示关了，怪不得看不见。</p><p>然后就可以移动出去这个jar包了，接着在命令行使用java命令运行就ok，provider的打包方式和这个也是一样的</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220303205137614.png" alt="image-20220303205137614"></p><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.springframework.boot<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spring-boot-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.2.2.RELEASE<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span></code></pre><h3 id="2-基于-Assembly-插件打包"><a href="#2-基于-Assembly-插件打包" class="headerlink" title="2 基于 Assembly 插件打包"></a>2 基于 Assembly 插件打包</h3><p>我就不去打包了，到时候有需要的时候，再回过头来看就可以了。</p><h4 id="2-1Assembly-插件"><a href="#2-1Assembly-插件" class="headerlink" title="2.1Assembly 插件"></a>2.1Assembly 插件</h4><p>Assembly是Mave的打包插件，他的作用是可以帮助我们对<strong>jar项目做打包处理</strong>。在Spring 整合 dubbo 的项目中，需要使Assembly 打包插件来对项目做打包处理。</p><p>在这种情况下，因为consumer是一个war项目，启动就会生成war包了，就是不需要使用这个插件来打包，所以我们就是需要依赖这插件对provider进行打包处理</p><h4 id="2-2使用步骤"><a href="#2-2使用步骤" class="headerlink" title="2.2使用步骤"></a>2.2使用步骤</h4><ol><li>需要在项目根下创建一个目录，名称为 assembly </li><li>将示例中 bin,conf 目录拷贝到 assembly 的根目录中 </li><li>删除 conf 目录中 dubbo.properties 配置文件中的内容 </li><li>修改项目的 POM 文件添加 assembly 的打包插件 </li><li>在 assembly 目录下添加 assembly.xml 配置文件</li><li>运行打包插件，对项目进行打包处理。可以使用 maven 的 install 命令，也可以使用 插件的命令</li><li>修改 start.sh 或 start.bat 中配置信息，将启动类修改为当前 dubbo 版本的启动类</li></ol><pre class=" language-bash"><code class="language-bash"><span class="token function">nohup</span> java <span class="token variable">$JAVA_OPTS</span> <span class="token variable">$JAVA_MEM_OPTS</span> <span class="token variable">$JAVA_DEBUG_OPTS</span> <span class="token variable">$JAVA_JMX_OPTS</span>-classpath <span class="token variable">$CONF_DIR</span><span class="token keyword">:</span><span class="token variable">$LIB_JARS</span> org.apache.dubbo.container.Main <span class="token operator">></span><span class="token variable">$STDOUT_FILE</span> 2<span class="token operator">></span><span class="token operator">&amp;</span>1 <span class="token operator">&amp;</span></code></pre><h2 id="Dubbo-监控与管理"><a href="#Dubbo-监控与管理" class="headerlink" title="Dubbo 监控与管理"></a>Dubbo 监控与管理</h2><h3 id="1-监控平台-dubbo-monitor"><a href="#1-监控平台-dubbo-monitor" class="headerlink" title="1 监控平台: dubbo-monitor"></a>1 监控平台: dubbo-monitor</h3><h4 id="1-1Dubbo-Monitor-简介"><a href="#1-1Dubbo-Monitor-简介" class="headerlink" title="1.1Dubbo Monitor 简介"></a>1.1Dubbo Monitor 简介</h4><p>主要用来统计服务的调用次数和调用时间，服务消费者和提供者，在内存中累计调用次 数和调用时间，定时每分钟发送一次统计数据到监控中心，监控中心则使用数据绘制图表来显示。</p><h4 id="1-2Dubbo-Monitor-的使用"><a href="#1-2Dubbo-Monitor-的使用" class="headerlink" title="1.2Dubbo Monitor 的使用"></a>1.2Dubbo Monitor 的使用</h4><p>修改Monitor的配置文件，就是改一下你注册中心的ip</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220302130749227.png" alt="image-20220302130749227"></p><p>然后启动就是直接去bin下bat就可，Linux下就是.sh</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220302132031678.png" alt="image-20220302132031678"></p><p>然后就可以打开浏览器，输入本机ip和端口，主页如下</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220302132131419.png" alt="image-20220302132131419"></p><p>比如主页就是对上面菜单的介绍</p><p>主页</p><p>应用的依赖</p><p>注册的服务（不包括Consumer，注册的就是provider），consumer不是服务的注册（不记得就看架构图）</p><p>Host  当前provider和consumer的主机</p><p>注册中心的地址</p><p>服务器地址</p><p>状态</p><p>日志</p><p>系统环境的信息</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ为什么使用信道而不直接使用TCP连接通信？</title>
      <link href="/2022/04/08/rabbitmq-wei-shi-me-shi-yong-xin-dao-er-bu-zhi-jie-shi-yong-tcp-lian-jie-tong-xin/"/>
      <url>/2022/04/08/rabbitmq-wei-shi-me-shi-yong-xin-dao-er-bu-zhi-jie-shi-yong-tcp-lian-jie-tong-xin/</url>
      
        <content type="html"><![CDATA[<p>TCP连接的创建和销毁开销特别大。</p><p>创建需要3次握手，销毁需要4次分手。高峰时每秒成千上万条TCP连接的创建会造成资源巨大的浪费。而且操作系统每秒处理TCP连接数也是有限制的， 会造成性能瓶颈。</p><p>而如果一条线程使用一条信道，一条TCP链接可以容纳无限的信道，即使每秒成千上万的请求也不会成为性 能的瓶颈。</p><p><img src="/2022/04/08/rabbitmq-wei-shi-me-shi-yong-xin-dao-er-bu-zhi-jie-shi-yong-tcp-lian-jie-tong-xin/1562800613510.jpeg" alt="1562800613510"></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ笔记</title>
      <link href="/2022/04/08/rabbitmq-bi-ji/"/>
      <url>/2022/04/08/rabbitmq-bi-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h1><h4 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h4><p> MQ全称Message Queue（消息队列），是在消息的传输过程中保存消息的容器。多用于系统之间的异步通信。</p><h4 id="MQ的优势"><a href="#MQ的优势" class="headerlink" title="MQ的优势"></a>MQ的优势</h4><h5 id="应用解耦"><a href="#应用解耦" class="headerlink" title="应用解耦"></a>应用解耦</h5><p>在电商平台中，用户下订单需要调用订单系统，此时订单系统还需 要调用库存系统、支付系统、物流系统完成业务。此时会产生两个问题：</p><p>1 如果库存系统出现故障，会造成整个订单系统崩溃。 </p><p>2 如果需求修改，新增了一个X系统，此时必须修改订单系统的代码。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408103539142.png" alt="image-20220408103539142"></p><p>如果在系统中引入MQ，即订单系统将消息先发送到MQ中，MQ再转发到其他系统，则会解决以下问题：</p><p>1 由于订单系统只发消息给MQ，不直接对接其他系统，如果库存系统出现故障，不影响整个订单。</p><p>2 如果需求修改，新增了一个X系统，此时无需修改订单系统的代码，只需修改MQ将消息发送给X系统即可。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408103642727.png" alt="image-20220408103642727"></p><h5 id="异步提速"><a href="#异步提速" class="headerlink" title="异步提速"></a>异步提速</h5><p>如果订单系统同步访问每个系统，则用户下单等待时长如下：</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408103357196.png" alt="image-20220408103357196"></p><p>如果引入MQ，则用户下单等待时长如下：</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408103413238.png" alt="image-20220408103413238"></p><h5 id="削峰填谷"><a href="#削峰填谷" class="headerlink" title="削峰填谷"></a>削峰填谷</h5><p>假设我们的系统每秒只能承载1000请求，如果请求瞬间增多到每秒 5000，则会造成系统崩溃。此时引入mq即可解决该问题</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408103429479.png" alt="image-20220408103429479"></p><p>使用了MQ之后，限制消费消息的速度为1000，这样一来，高峰期 产生的数据势必会被积压在MQ中，高峰就被“削”掉了，但是因为消 息积压，在高峰期过后的一段时间内，消费消息的速度还是会维持在1000，直到消费完积压的消息，这就叫做“填谷”。</p><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><h5 id="短时间内需要处理大量请求"><a href="#短时间内需要处理大量请求" class="headerlink" title="短时间内需要处理大量请求"></a>短时间内需要处理大量请求</h5><p>如果直接连接系统处理业务，会耗费大量资源，有可能造成系统瘫痪。</p><p>如：秒杀，抢红包，抢火车票</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408104625502.png" alt="image-20220408104625502"></p><p>而使用MQ后，可以先让用户将请求发送到MQ中，MQ会先保存 请求消息，不会占用系统资源，且MQ会进行消息排序，先请求 的秒杀成功，后请求的秒杀失败。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408104612270.png" alt="image-20220408104612270"></p><h5 id="消息分发"><a href="#消息分发" class="headerlink" title="消息分发"></a>消息分发</h5><p>如电商网站要推送促销信息，该业务耗费时间较多，但对时效性 要求不高，可以使用MQ做消息分发。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408104655872.png" alt="image-20220408104655872"></p><h5 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h5><p>假如我们需要将数据保存到数据库之外，还需要一段时间将数据同步到缓存（如Redis）、搜索引擎（如Elasticsearch）中。此 时可以将数据库的数据作为消息发送到MQ中，并同步到缓存、 搜索引擎中。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408104712580.png" alt="image-20220408104712580"></p><h5 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h5><p>在电商系统中，订单完成后，需要及时的通知子系统（进销存系 统发货，用户服务积分，发送短信）进行下一步操作。为了保证 订单系统的高性能，应该直接返回订单结果，之后让MQ通知子 系统做其他非实时的业务操作。这样能保证核心业务的高效及时。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408104744539.png" alt="image-20220408104744539"></p><h5 id="离线处理"><a href="#离线处理" class="headerlink" title="离线处理"></a>离线处理</h5><p>在银行系统中，如果要查询近十年的历史账单，这是非常耗时的操作。如果发送同步请求，则会花费大量时间等待响应。此时使用MQ发送异步请求，等到查询出结果后获取结果即可。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408104814969.png" alt="image-20220408104814969"></p><h4 id="AMQP"><a href="#AMQP" class="headerlink" title="AMQP"></a>AMQP</h4><p>高级消息队列协议</p><p>RabbitMQ是由Erlang语言编写的基于AMQP的MQ产品。</p><p>MQ的标准非常简单</p><p>就是放一个容器，容器中可以存一个单向队列，FIFO策略，接着就是一个发送者，把消息发送到队列里，不管使用什么办法。</p><p>另外一端就是consumer消费者，拿消息，运行之后不管主动还是被动的从队列中把消息拿出来。处理掉就可以</p><p>就是保证这三个角色传递消息了，他就是MQ标准</p><p>AMQP中多了一个<strong>交换器</strong>，对于发送消息的人来说，它不需要知道队列是什么，知道交换器就可以，就是发消息发到交换器</p><p>那对于consumer来说就只需要知道自己的队列就行</p><p>其实真正的开发过程中，consumer还是要指定一下交换器的位置的</p><p>基于erlang，这个语言开发出来的产品，有几个特性，特别适合处理<strong>高并发</strong>，</p><p>处理高并发的时候服务器的<strong>吞吐量</strong>也是特别大的</p><p>然后就是对于<strong>多线程</strong>的处理也是特别好,这就是erlang这个语种开发的特点。</p><h5 id="AMQP工作过程"><a href="#AMQP工作过程" class="headerlink" title="AMQP工作过程"></a>AMQP工作过程</h5><p>生产者(Publisher)将消息发布到交换机(Exchange)，交换机根据规 则将消息分发给交换机绑定的队列(Queue)，队列再将消息投递给 订阅了此队列的消费者。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408105734730.png" alt="image-20220408105734730"></p><h4 id="RabbitMQ工作原理"><a href="#RabbitMQ工作原理" class="headerlink" title="RabbitMQ工作原理"></a>RabbitMQ工作原理</h4><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408105836497.png" alt="image-20220408105836497"></p><h5 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h5><p>消息的生产者。也是一个向交换机发布消息的客户端应用程序。 </p><h5 id="Connection"><a href="#Connection" class="headerlink" title="Connection"></a>Connection</h5><p>连接。生产者&#x2F;消费者和RabbitMQ服务器之间建立的TCP连接。 </p><h5 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h5><p>信道。是TCP里面的虚拟连接。例如：Connection相当于电缆， Channel相当于独立光纤束，一条TCP连接中可以创建多条信 道，增加连接效率。无论是发布消息、接收消息、订阅队列都是通过信道完成的。 </p><h5 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h5><p>消息队列服务器实体。即RabbitMQ服务器 </p><h5 id="Virtual-host"><a href="#Virtual-host" class="headerlink" title="Virtual host"></a>Virtual host</h5><p>虚拟主机。出于多租户和安全因素设计的，把AMQP的基本组件 划分到一个虚拟的分组中。每个vhost本质上就是一个mini版的 RabbitMQ服务器，拥有自己的队列、交换机、绑定和权限机 制。当多个不同的用户使用同一个RabbitMQ服务器时，可以划分出多个虚拟主机。RabbitMQ默认的虚拟主机路径是 &#x2F; </p><h5 id="Exchange"><a href="#Exchange" class="headerlink" title="Exchange"></a>Exchange</h5><p>交换机。用来接收生产者发送的消息，并根据分发规则，将这些消息分发给服务器中的队列中。不同的交换机有不同的分发规 则。 </p><h5 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h5><p>消息队列。用来保存消息直到发送给消费者。它是消息的容器， 也是消息的终点。消息一直在队列里面，等待消费者链接到这个 队列将其取走。 </p><h5 id="Binding"><a href="#Binding" class="headerlink" title="Binding"></a>Binding</h5><p>消息队列和交换机之间的虚拟连接，绑定中包含路由规则，绑定信息保存到交换机的路由表中，作为消息的分发依据。 </p><h5 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h5><p>消息的消费者。表示一个从消息队列中取得消息的客户端应用程序。</p><h4 id="安装Erlang"><a href="#安装Erlang" class="headerlink" title="安装Erlang"></a>安装Erlang</h4><p>1.安装<em><strong>epel</strong></em>源</p><pre class=" language-none"><code class="language-none">yum install -y epel-release</code></pre><p>2.添加存储库条目</p><pre class=" language-bash"><code class="language-bash"><span class="token function">wget</span> https://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpmrpm -Uvh erlang-solutions-1.0-1.noarch.rpm//报错-bash: wget: 未找到命令然后去安装一下wgetyum <span class="token function">install</span> -y <span class="token function">wget</span>再走一遍</code></pre><p>3.安装erlang</p><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> -y erlang</code></pre><p>4.验证安装是否成功</p><p><strong>erl -version</strong></p><h4 id="安装RabbitMQ–解压安装"><a href="#安装RabbitMQ–解压安装" class="headerlink" title="安装RabbitMQ–解压安装"></a>安装RabbitMQ–解压安装</h4><p>1.为了外部能够正常访问RabbitMQ服务，先关闭防火墙</p><h5 id><a href="#" class="headerlink" title></a></h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 关闭运行的防火墙</span>systemctl stop firewalld.service<span class="token comment" spellcheck="true"># 禁止防火墙自启动</span>systemctl disable firewalld.service</code></pre><h5 id="2-RabbitMQ是通过主机名进行访问的，必须给服务器添加主机名"><a href="#2-RabbitMQ是通过主机名进行访问的，必须给服务器添加主机名" class="headerlink" title="2.RabbitMQ是通过主机名进行访问的，必须给服务器添加主机名"></a>2.RabbitMQ是通过主机名进行访问的，必须给服务器添加主机名</h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 修改文件</span>vim /etc/sysconfig/network<span class="token comment" spellcheck="true"># 添加如下内容</span>NETWORKING<span class="token operator">=</span>yesHOSTNAME<span class="token operator">=</span>juejue<span class="token comment" spellcheck="true"># 修改文件</span>vim /etc/hosts<span class="token comment" spellcheck="true"># 添加如下内容</span>服务器ip juejue</code></pre><h5 id="3-使用rz命令上传RabbitMQ压缩文件"><a href="#3-使用rz命令上传RabbitMQ压缩文件" class="headerlink" title="3 使用rz命令上传RabbitMQ压缩文件"></a>3 使用rz命令上传RabbitMQ压缩文件</h5><h5 id="4-安装RabbitMQ"><a href="#4-安装RabbitMQ" class="headerlink" title="4 安装RabbitMQ"></a>4 安装RabbitMQ</h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 解压RabbitMQ</span><span class="token function">tar</span> xf rabbitmq-server-generic-unix-3.9.13.tar.xz<span class="token comment" spellcheck="true"># 重命名：</span><span class="token function">mv</span> rabbitmq_server-3.9.13 rabbitmq<span class="token comment" spellcheck="true"># 移动文件夹：</span><span class="token function">mv</span> rabbitmq /usr/local/</code></pre><h5 id="5-配置环境变量"><a href="#5-配置环境变量" class="headerlink" title="5  配置环境变量"></a>5  配置环境变量</h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 编辑/etc/profile文件</span>vim /etc/profile<span class="token comment" spellcheck="true">#添加如下内容</span><span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span>:/usr/local/rabbitmq/sbin<span class="token comment" spellcheck="true"># 运行文件，让修改内容生效</span><span class="token function">source</span> /etc/profile</code></pre><h5 id="6-开启管控台插件"><a href="#6-开启管控台插件" class="headerlink" title="6 开启管控台插件"></a>6 开启管控台插件</h5><pre class=" language-bash"><code class="language-bash">rabbitmq-plugins <span class="token function">enable</span> rabbitmq_management</code></pre><p>就是rabbitMQ自带的一个控制台插件，我们可以通过浏览器访问控制台，通过控制台来管理队列、消息、交换机等等</p><h5 id="7-后台运行"><a href="#7-后台运行" class="headerlink" title="7 后台运行"></a>7 后台运行</h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#启动rabbitmq</span>rabbitmq-server -detached<span class="token comment" spellcheck="true">#停止rabbitmq</span>rabbitmqctl stop    </code></pre><h5 id="8-通过管控台访问RabbitMQ"><a href="#8-通过管控台访问RabbitMQ" class="headerlink" title="8 通过管控台访问RabbitMQ"></a>8 通过管控台访问RabbitMQ</h5><p>路径： <a href="http://ip地址:15672/">http://ip地址:15672</a> ，用户名： guest ，密码： guest</p><p>rabbitMQ默认占用的端口号是5672，但是不是直接访问，而是访问它的管控台插件，管控台插件占用的是15672</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408130202366.png" alt="image-20220408130202366"></p><p>但是你会发现登录不了，因为这个现在是远程访问，默认不让远程使用管理员访问</p><p>就有两种解决办法，一是让管理员可以远程访问，二是再创建一个用户</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408130215521.png" alt="image-20220408130215521"></p><p>配置允许使用 guest远程访问</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 创建配置文件夹</span><span class="token function">mkdir</span> -p /usr/local/rabbitmq/etc/rabbitmq<span class="token comment" spellcheck="true"># 创建配置文件</span>vim /usr/local/rabbitmq/etc/rabbitmq/rabbitmq.conf<span class="token comment" spellcheck="true"># 添加如下内容</span>loopback_users<span class="token operator">=</span>none<span class="token comment" spellcheck="true"># 重启RabbitMQ</span>rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl start_app//对应停止。重新加载配置，启动</code></pre><p> 然后就可以使用guest用户来访问了</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408130327271.png" alt="image-20220408130327271"></p><h4 id="账户管理"><a href="#账户管理" class="headerlink" title="账户管理"></a>账户管理</h4><p>因为RabbitMQ并不推荐我们远程使用guest用户访问，因为会变的不安全，因为不修改账户名和密码那他们都是guest</p><p>guest账户默认只允许本地使用，我们可以创建新账户远程访问 RabbitMQ    </p><h5 id="1-创建账户"><a href="#1-创建账户" class="headerlink" title="1 创建账户"></a>1 创建账户</h5><h5 id="-1"><a href="#-1" class="headerlink" title></a></h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 创建账户</span>rabbitmqctl add_user 用户名 密码</code></pre><h5 id="2-给用户授予管理员角色"><a href="#2-给用户授予管理员角色" class="headerlink" title="2 给用户授予管理员角色"></a>2 给用户授予管理员角色</h5><pre class=" language-bash"><code class="language-bash">rabbitmqctl set_user_tags 用户名 administrator</code></pre><h5 id="3-给用户授权"><a href="#3-给用户授权" class="headerlink" title="3 给用户授权"></a>3 给用户授权</h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># "/"表示虚拟机</span><span class="token comment" spellcheck="true"># juejue表示用户名</span><span class="token comment" spellcheck="true"># ".*" ".*" ".*" 表示完整权限</span>rabbitmqctl set_permissions -p <span class="token string">"/"</span> juejue <span class="token string">".*"</span> <span class="token string">".*"</span> <span class="token string">".*"</span></code></pre><h5 id="4-通过管控台访问rabbitmq"><a href="#4-通过管控台访问rabbitmq" class="headerlink" title="4 通过管控台访问rabbitmq"></a>4 通过管控台访问rabbitmq</h5><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408130546799.png" alt="image-20220408130546799"></p><p>推荐自己创建交换机</p><h4 id="docker安装"><a href="#docker安装" class="headerlink" title="docker安装"></a>docker安装</h4><pre class=" language-bash"><code class="language-bash">curl -fsSL https://get.docker.com <span class="token operator">|</span> <span class="token function">bash</span> -s docker --mirror Aliyun<span class="token comment" spellcheck="true"># 启动docker</span>systemctl start docker</code></pre><p>安装好之后拉一下镜像</p><pre class=" language-bash"><code class="language-bash">docker pull rabbitmq</code></pre><p>启动RabbitMQ容器</p><pre class=" language-none"><code class="language-none">docker run -d --hostname juejue --name rabbit -p 15672:15672 -p 5672:5672 rabbitmq</code></pre><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220405150415806.png" alt="image-20220405150415806"></p><p>开启管控台插件</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 查询rabbitmq容器ID</span>docker <span class="token function">ps</span>  <span class="token comment" spellcheck="true"># 进入容器</span>docker <span class="token function">exec</span> -it 容器ID /bin/bash<span class="token comment" spellcheck="true"># 开启管控台插件</span>rabbitmq-plugins <span class="token function">enable</span> rabbitmq_management<span class="token comment" spellcheck="true"># 退出容器</span>ctrl+p+q</code></pre><p>然后容器的rabbitMQ是可以直接使用guest用户登陆的</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220405151331098.png" alt="image-20220405151331098"></p><p>不理解，，难道我重新启动rabbitmq，之前创建的juejue用户就没了？整的我要重新创建一遍</p><h4 id="简单模式"><a href="#简单模式" class="headerlink" title="简单模式"></a>简单模式</h4><p>RabbitMQ共有六种工作模式：简单模式（Simple）、工作队列模式（Work Queue）、发布订阅模式（Publish&#x2F;Subscribe）、路由 模式（Routing）、通配符模式（Topics）、远程调用模式（RPC， 不常用，这里不说)</p><p>就是简单使用Java原生API去实现，这里不过多展示</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408134152170.png" alt="image-20220408134152170"></p><h6 id="特点："><a href="#特点：" class="headerlink" title="特点："></a>特点：</h6><p>1 一个生产者对应一个消费者，通过队列进行消息传递。 </p><p>2 该模式使用direct交换机，direct交换机是RabbitMQ默认交换机。运行代码就可以看见发送的消息了</p><p>（JavaMessage Service）——–JMS</p><p>JMS是JavaEE规范中的一种，类比JDBC。很多 MQ产品都实现了JMS规范，例如ActiveMQ。RabbitMQ官方并没 有实现JMS规范，但是开源社区有JMS的实现包。</p><h4 id="工作队列模式"><a href="#工作队列模式" class="headerlink" title="工作队列模式"></a>工作队列模式</h4><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408134220045.png" alt="image-20220408134220045"></p><p>与简单模式相比，工作队列模式(Work Queue)多了一些消费者，该 模式也使用direct交换机，应用于处理消息较多的情况。</p><p>特点如下： </p><p>1 一个队列对应多个消费者。 </p><p>2 一条消息只会被一个消费者消费。 </p><p>3 消息队列默认采用轮询的方式将消息平均发送给消费者。</p><h4 id="发布订阅模式"><a href="#发布订阅模式" class="headerlink" title="发布订阅模式"></a>发布订阅模式</h4><p>前两个模式当中，同一条消息只会被发送到一个队列当中，并且只会被一个消费者消费一次，</p><p>但实际上有些消息是要被多次消费的</p><p>有点不一样的就是，之前两个是直接往队列里面发消息</p><p>但是现在这里会先发消息给交换机，由交换机再分发到队列当中</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406105628569.png" alt="image-20220406105628569"></p><p>在开发过程中，有一些消息需要不同消费者进行不同的处理，如电 商网站的同一条促销信息需要短信发送、邮件发送、站内信发送 等。此时可以使用发布订阅模式(Publish&#x2F;Subscribe) </p><p>特点： </p><p>1 生产者将消息发送给交换机，交换机将消息转发到绑定此交换机的每个队列中。</p><p>2 工作队列模式的交换机只能将消息发送给一个队列，发布订阅模式的交换机能将消息发送给多个队列。发布订阅模式使用fanout交换机。</p><p>然后工作模式和发布订阅是可以一起使用的，也就是可以使用多个消费者去监听同一个队列，他们轮询分配消息。</p><h4 id="路由模式"><a href="#路由模式" class="headerlink" title="路由模式"></a>路由模式</h4><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406105957506.png" alt="image-20220406105957506"></p><p>使用发布订阅模式时，所有消息都会发送到绑定的队列中，但很多 时候，不是所有消息都无差别的发布到所有队列中。比如电商网站 的促销活动，双十一大促可能会发布到所有队列；而一些小的促销 活动为了节约成本，只发布到站内信队列。此时需要使用路由模式 (Routing)完成这一需求。</p><p>特点： </p><p>1 每个队列绑定路由关键字RoutingKey   </p><p>2 生产者将带有RoutingKey的消息发送给交换机，交换机根据RoutingKey转发到指定队列。路由模式使用direct交换机。</p><p>然后交换机还是自己创建，不使用默认的</p><p>然后每个队列是可以添加多个路由关键字的</p><p>就是在交换机绑定队列的时候添加关键字，发送消息的时候也添加关键字。</p><h4 id="通配符模式"><a href="#通配符模式" class="headerlink" title="通配符模式"></a>通配符模式</h4><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408134734549.png" alt="image-20220408134734549"></p><p>其实就相当于路由模式的进阶版，比路由模式更加的灵活</p><p>生产者和路由模式中的区别就是绑定路由关键字的时候关键字里面带有通配符</p><p>其实通配符模式也叫主题模式topic</p><p>消费者就和也是直接拿路由模式的修改一下监听的队列就行，最终效果和路由模式的效果一样</p><h3 id="Springboot整合RabbtMQ"><a href="#Springboot整合RabbtMQ" class="headerlink" title="Springboot整合RabbtMQ"></a>Springboot整合RabbtMQ</h3><p>之前都是原生Java操作RabbitMQ，真正开发的时候更多都是用框架来简化RabbitMQ的操作；</p><p>配置文件</p><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># 配置RabbitMQ</span><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">rabbitmq</span><span class="token punctuation">:</span>    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.8.14    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">5672</span>    <span class="token key atrule">username</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">password</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">virtual-host</span><span class="token punctuation">:</span> /<span class="token comment" spellcheck="true">#日志格式</span><span class="token key atrule">logging</span><span class="token punctuation">:</span>  <span class="token key atrule">pattern</span><span class="token punctuation">:</span>    <span class="token key atrule">console</span><span class="token punctuation">:</span> '%d&amp;<span class="token comment" spellcheck="true">#123;HH:mm:ss.SSS&amp;#125;%clr(%-5level) ---[%-15thread]%cyan(%-50logger&amp;#123;50&amp;#125;):%msg%n'</span></code></pre><p>SpringBoot整合RabbitMQ时，需要在配置类创建队列和交换机</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.rabbitmqspringboot;import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RabbitConfig &#123;    private final String EXCHANGE_NAME = "boot_topic_exchange";    private final String QUEUE_NAME = "boot_queue";    // 创建交换机    @Bean("bootExchange")    public Exchange getExchange() &#123;        return ExchangeBuilder                .topicExchange(EXCHANGE_NAME) // 交换机类型                .durable(true) // 是否持久化                .build();    &#125;    // 创建队列    @Bean("bootQueue")    public Queue getMessageQueue() &#123;        return new Queue(QUEUE_NAME); // 队列名    &#125;    // 交换机绑定队列    @Bean//参数的交换机和队列都是从spring容器中拿的    public Binding bindMessageQueue(@Qualifier("bootExchange") Exchange exchange, @Qualifier("bootQueue") Queue queue) &#123;        return BindingBuilder                .bind(queue)                .to(exchange)                .with("#.message.#")                .noargs();    &#125;&#125;</code></pre><p>SpringBoot整合RabbitMQ时，提供了工具类RabbitTemplate发送 消息，编写生产者时只需要注入RabbitTemplate即可发送消息。</p><pre class=" language-JAVA"><code class="language-JAVA">@SpringBootTestpublic class TestProducer &#123;    // 注入RabbitTemplate工具类    @Autowired    private RabbitTemplate rabbitTemplate;    @Test    public void testSendMessage()&#123;        /*         * 发送消息         * 参数1：交换机         * 参数2：路由key         * 参数3：要发送的消息         */        rabbitTemplate.convertAndSend("boot_topic_exchange","message","双十一开始了！");    &#125;&#125;</code></pre><p>然后另一个项目编写消费者，为什么？？因为如果是同一个项目的话，直接调用就可以，不需要通过MQ去通信</p><pre class=" language-JAVA"><code class="language-JAVA">//消费者@Componentpublic class Consumer &#123;    //监听队列    @RabbitListener(queues = "boot_queue")    public void listenMessage(String message)&#123;        System.out.println("接收消息："+message);    &#125;&#125;</code></pre><p>然后消费者就不要写测试方法了，直接写普通方法，这样启动之后他就会一直监听队列</p><p>直接拿过来字符串类型的消息就可以用，框架会帮我们去做那个byte的转换</p><p>这个消费者是随着项目的启动而启动的</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406164530529.png" alt="image-20220406164530529"></p><h3 id="消息的可靠性投递"><a href="#消息的可靠性投递" class="headerlink" title="消息的可靠性投递"></a>消息的可靠性投递</h3><p>RabbitMQ消息投递的路径为： 生产者 —&gt; 交换机 —&gt; 队列 —&gt; 消费者</p><ul><li>确认模式（confirm）可以监听消息是否从生产者成功传递到交换机  。 </li><li>退回模式（return）可以监听消息是否从交换机成功传递到队列。 </li><li>消费者消息确认（Consumer Ack）可以监听消费者是否成功处理消息。</li></ul><h4 id="确认模式"><a href="#确认模式" class="headerlink" title="确认模式"></a>确认模式</h4><p>确认模式（confirm）可以监听消息是否从生产者成功传递到交换机。 退回模式（return）可以监听消息是否从交换机成功传递到队列。 消费者消息确认（Consumer Ack）可以监听消费者是否成功处理消息。</p><p>确认模式：在生产者中配置之后才会有作用</p><p>故意写错一个发送消息的交换器名字之后，运行发现交换机和队列都创建出来了，但是，队列里面没有消息，而且控制台也不报错，这就是不加确认模式的一个效果</p><h5 id="1-生产者配置文件开启确认模式"><a href="#1-生产者配置文件开启确认模式" class="headerlink" title="1 生产者配置文件开启确认模式"></a>1 生产者配置文件开启确认模式</h5><p>加了之后</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406174100375.png" alt="image-20220406174100375"></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">rabbitmq</span><span class="token punctuation">:</span>    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.8.14    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">5672</span>    <span class="token key atrule">username</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">password</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">virtual-host</span><span class="token punctuation">:</span> /    <span class="token comment" spellcheck="true"># 开启确认模式</span>    <span class="token key atrule">publisher-confirm-type</span><span class="token punctuation">:</span> correlated</code></pre><h5 id="2-生产者定义确认模式的回调方法"><a href="#2-生产者定义确认模式的回调方法" class="headerlink" title="2 生产者定义确认模式的回调方法"></a>2 生产者定义确认模式的回调方法</h5><pre class=" language-JAVA"><code class="language-JAVA">@Testpublic void sendMessage()&#123;    //定义确认模式的回调方法，消息交换机发送后会调用confirm方法    rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback()&#123;        /**         * 被调用的回调方法         * @param correlationData 相关配置信息         * @param ack 交换机是否成功收到消息         * @param cause 失败原因         */        @Override        public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123;        if (ack)&#123;            System.out.println("confirm接收成功");        &#125;else &#123;            System.out.println("接收失败，原因为："+cause);            //做一些处理，让消息再次发送            &#125;        &#125;    &#125;);    //故意写一个错的交换机    rabbitTemplate.convertAndSend("my_topic_exchange","my_routing","Send Message...");&#125;</code></pre><h4 id="退回模式"><a href="#退回模式" class="headerlink" title="退回模式"></a>退回模式</h4><p>退回模式：可以监听消息是否从交换机成功传递到队列</p><h5 id="1-生产者配置文件开启退回模式"><a href="#1-生产者配置文件开启退回模式" class="headerlink" title="1 生产者配置文件开启退回模式"></a>1 生产者配置文件开启退回模式</h5><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># 配置RabbitMQ</span><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">rabbitmq</span><span class="token punctuation">:</span>    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.8.14    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">5672</span>    <span class="token key atrule">username</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">password</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">virtual-host</span><span class="token punctuation">:</span> /    <span class="token comment" spellcheck="true"># 开启确认模式</span>    <span class="token key atrule">publisher-confirm-type</span><span class="token punctuation">:</span> correlated      <span class="token comment" spellcheck="true"># 开启回退模式</span>    <span class="token key atrule">publisher-returns</span><span class="token punctuation">:</span> <span class="token boolean important">true</span></code></pre><h5 id="2-生产者定义退回模式的回调方法"><a href="#2-生产者定义退回模式的回调方法" class="headerlink" title="2 生产者定义退回模式的回调方法"></a>2 生产者定义退回模式的回调方法</h5><pre class=" language-JAVA"><code class="language-JAVA">@Testpublic void testReturn()&#123;    //定义退回模式的回调方法。交换机发送到队列失败后才会执行returnedMessage方法    rabbitTemplate.setReturnsCallback(new RabbitTemplate.ReturnsCallback()&#123;        /**         * @param returnedMessage 失败后将失败信息封装到参数中         */        @Override        public void returnedMessage(ReturnedMessage returnedMessage) &#123;            System.out.println("消息对象："+returnedMessage.getMessage());            System.out.println("错误码："+returnedMessage.getReplyCode());            System.out.println("错误信息："+returnedMessage.getReplyText());            System.out.println("交换机："+returnedMessage.getExchange());            System.out.println("路由键："+returnedMessage.getRoutingKey());            //处理消息。。。。        &#125;    &#125;);    rabbitTemplate.convertAndSend("my_topic_exchange","my_routing1","Send Message...");&#125;</code></pre><p>这里故意把routingKey写错，也是发送不到队列还没有报错</p><p>写错之后的发送</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406183631452.png" alt="image-20220406183631452"></p><h4 id="Ack"><a href="#Ack" class="headerlink" title="Ack"></a>Ack</h4><p>在RabbitMQ中，消费者接收到消息后会向队列发送确认签收的消 息，只有确认签收的消息才会被移除队列。这种机制称为消费者消 息确认（Consumer Acknowledge，简称Ack）。类似快递员派送 快递也需要我们签收，否则一直存在于快递公司的系统中。 消息分为自动确认和手动确认。自动确认指消息只要被消费者接收 到，无论是否成功处理消息，则自动签收，并将消息从队列中移 除。但是在实际开发中，收到消息后可能业务处理出现异常，那么 消息就会丢失。此时需要设置手动签收，即在业务处理成功再通知 签收消息，如果出现异常，则拒签消息，让消息依然保留在队列当中。</p><p>自动确认：spring.rabbitmq.listener.simple.acknowledge&#x3D;”none” </p><p>手动确认：spring.rabbitmq.listener.simple.acknowledge&#x3D;”manual”</p><h5 id="-2"><a href="#-2" class="headerlink" title></a></h5><p>然后就是消费者故意人为的制造一个bug&#x2F;0，控制台直接报错，但是队列中的消息还是被消费完了</p><p>然后再发一次，还是没有成功处理掉，就相当于说消息丢失了，所以在开发的时候更多使用的是手动签收消息</p><h5 id="1-消费者配置开启手动签收"><a href="#1-消费者配置开启手动签收" class="headerlink" title="1 消费者配置开启手动签收"></a>1 消费者配置开启手动签收</h5><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># 配置RabbitMQ</span><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">rabbitmq</span><span class="token punctuation">:</span>    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.8.14    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">5672</span>    <span class="token key atrule">username</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">password</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">virtual-host</span><span class="token punctuation">:</span> /    <span class="token comment" spellcheck="true"># 手动签收</span>    <span class="token key atrule">listener</span><span class="token punctuation">:</span>      <span class="token key atrule">simple</span><span class="token punctuation">:</span>        <span class="token key atrule">acknowledge-mode</span><span class="token punctuation">:</span> manual</code></pre><h5 id="2-消费者处理消息时定义手动签收和拒绝签收的情况"><a href="#2-消费者处理消息时定义手动签收和拒绝签收的情况" class="headerlink" title="2 消费者处理消息时定义手动签收和拒绝签收的情况"></a>2 消费者处理消息时定义手动签收和拒绝签收的情况</h5><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myconsumer1;import com.rabbitmq.client.Channel;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;import java.io.IOException;@Componentpublic class AckConsumer &#123;    //监听队列    @RabbitListener(queues = "my_queue")    public void listenMessage(Message message, Channel channel) throws IOException &#123;        //需要使用信道来完成消息的手动签收        //消息投递序号，消息每次投递该值都会+1        long deliveryTag = message.getMessageProperties().getDeliveryTag();        try &#123;            int i = 1 / 0;//模拟处理消息出现bug            System.out.println("成功接收消息：" + message);            //签收消息            /**             * 参数1：消息投递序号             * 参数2：是否一次可以签收多条消息             */            channel.basicAck(deliveryTag, true);        &#125; catch (Exception e) &#123;            //拒签消息            /**             * 参数1：消息投递序号             * 参数2：是否一次可以拒签多条消息             * 参数3：消息是否可以重回队列             */            channel.basicNack(deliveryTag,true,true);        &#125;    &#125;&#125;</code></pre><p>写好之后重启消费方，并再次发送一条消息，就会一直显示消息消费失败，因为回退了又发过来，就会一直报</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406191805803.png" alt="image-20220406191805803"></p><p>消息是一直在队列中的，处于一个未签收的状态，消息并不会丢失掉</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406192133446.png" alt="image-20220406192133446"></p><p><strong>为了避免大量消息把消费者冲击奔溃，就是暂时存在MQ中</strong></p><p>来看看没有开启限流的一个效果，就会一下全部丢给消费者，测试数据少，要是十万条一下丢呢？？</p><p>不就会内存溢出？内存泄漏？</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406194441454.png" alt="image-20220406194441454"></p><h3 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a>高级特性</h3><h4 id="消费端限流"><a href="#消费端限流" class="headerlink" title="消费端限流"></a>消费端限流</h4><p>MQ可以对请求进行“削峰填谷”，即通过消费端限流的 方式限制消息的拉取速度，达到保护消费端的目的。</p><p>1 生产者批量发送消息</p><p>就是搞个for循环</p><pre class=" language-JAVA"><code class="language-JAVA">@Testpublic void testSendBatch()&#123;    for (int i = 0; i < 20; i++) &#123;        rabbitTemplate.convertAndSend("my_topic_exchange","my_routing","Send Message..."+i);    &#125;&#125;</code></pre><p>2 消费端配置限流机制</p><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># 配置RabbitMQ</span><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">rabbitmq</span><span class="token punctuation">:</span>    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.8.14    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">5672</span>    <span class="token key atrule">username</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">password</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">virtual-host</span><span class="token punctuation">:</span> /    <span class="token key atrule">listener</span><span class="token punctuation">:</span>      <span class="token key atrule">simple</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 限流机制必须开启手动签收</span>        <span class="token key atrule">acknowledge-mode</span><span class="token punctuation">:</span> manual        <span class="token comment" spellcheck="true"># 消费端最多拉去5条消息消费，签收后不满5条才会继续拉去消息</span>        <span class="token key atrule">prefetch</span><span class="token punctuation">:</span> <span class="token number">5</span></code></pre><p>3 消费者监听队列</p><p>新写一个消费方，把之前的消费方的注解注释掉不让它监听了</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myconsumer1;import com.rabbitmq.client.Channel;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;import java.io.IOException;@Componentpublic class OosConsumer &#123;//Oos就是限流的意思    //监听队列    @RabbitListener(queues = "my_queue")    public void listenMessage(Message message, Channel channel) throws IOException, InterruptedException &#123;       //获取消息        System.out.println(new String(message.getBody()));        //2.模拟业务处理        Thread.sleep(3000);        //3.签收消息        channel.basicAck(message.getMessageProperties().getDeliveryTag(), true);    &#125;&#125;</code></pre><p>发个20条的</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406195014144.png" alt="image-20220406195014144"></p><p>看看公平分发因为处理时间不同的效果</p><p>但是第一次是全让消费者1消费了，应该是先把消费者1启动起来了，再发消息看看</p><p>然后就会看见，消费者1很快就处理完了，就是等着消费者2处理</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406204258726.png" alt="image-20220406204258726"></p><p>这就是公平分发的一个效果，所以说公平分发就会造成消费者资源的浪费</p><p>接下来是不公平分发，就是谁处理的快让谁处理的多</p><h4 id="利用限流实现不公平分发"><a href="#利用限流实现不公平分发" class="headerlink" title="利用限流实现不公平分发"></a>利用限流实现不公平分发</h4><p>在RabbitMQ中，多个消费者监听同一条队列，则队列默认采用的 轮询分发。但是在某种场景下这种策略并不是很好，例如消费者1处 理任务的速度非常快，而其他消费者处理速度却很慢。此时如果采 用公平分发，则消费者1有很大一部分时间处于空闲状态。此时可以 采用不公平分发，即谁处理的快，谁处理的消息多。</p><p>1 生产者批量发送消息</p><p>2 消费端配置不公平分发</p><p>然后先把消费端的限流最多拉取5注释掉,也就是把限流给他去掉，弄成1</p><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># 配置RabbitMQ</span><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">rabbitmq</span><span class="token punctuation">:</span>    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.8.14    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">5672</span>    <span class="token key atrule">username</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">password</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">virtual-host</span><span class="token punctuation">:</span> /    <span class="token key atrule">listener</span><span class="token punctuation">:</span>      <span class="token key atrule">simple</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 限流机制必须开启手动签收</span>        <span class="token key atrule">acknowledge-mode</span><span class="token punctuation">:</span> manual        <span class="token comment" spellcheck="true"># 消费端最多拉去5条消息消费，签收后不满5条才会继续拉去消息</span><span class="token comment" spellcheck="true">#        prefetch: 5</span>        <span class="token comment" spellcheck="true"># 消费者最多拉去一条消息进行消费，这样谁处理快谁拉取下一条消息</span>        <span class="token key atrule">prefetch</span><span class="token punctuation">:</span> <span class="token number">1</span></code></pre><p>3 编写两个消费者</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myconsumer1;import com.rabbitmq.client.Channel;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;import java.io.IOException;@Componentpublic class UnfairConsumer &#123;    //消费者1    @RabbitListener(queues = "my_queue")    public void listenMessage1(Message message, Channel channel) throws IOException, InterruptedException &#123;       //获取消息        System.out.println("消费者1："+new String(message.getBody()));        //2.模拟业务处理        Thread.sleep(500);        //3.签收消息        channel.basicAck(message.getMessageProperties().getDeliveryTag(), true);    &#125;    //消费者1    @RabbitListener(queues = "my_queue")    public void listenMessage2(Message message, Channel channel) throws IOException, InterruptedException &#123;        //获取消息        System.out.println("消费者2："+new String(message.getBody()));        //2.模拟业务处理        Thread.sleep(3000);        //3.签收消息        channel.basicAck(message.getMessageProperties().getDeliveryTag(), true);    &#125;&#125;</code></pre><p>真的是，只要配置文件的缩进有一个空格的区别，都会直接报错，运行都运行不了</p><p>来看看，这样就造成了性能的节约，这就是利用限流机制实现不公平分发</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406212028303.png" alt="image-20220406212028303"></p><h4 id="消息存活时间"><a href="#消息存活时间" class="headerlink" title="消息存活时间"></a>消息存活时间</h4><p>RabbitMQ可以设置消息的存活时间（Time To Live，简称TTL）， 当消息到达存活时间后还没有被消费，会被移出队列。RabbitMQ 可以对队列的所有消息设置存活时间，也可以对某条消息设置存活时间。</p><p><strong>对队列消息设置存活时间，要在创建队列的时候设置</strong></p><p><strong>对某条消息设置存活时间，要在发送消息的时候设置</strong></p><p>注释掉原来生产者（myproducer1）的配置类，复制过来一份</p><p>设置队列消息存活时间</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407092358460.png" alt="image-20220407092358460"></p><p>单条消息设置存活时间</p><pre class=" language-JAVA"><code class="language-JAVA">//发送消息，设置消息的存活时间    @Test    public void testSendMessage()&#123;        //1.创建消息属性        MessageProperties messageProperties = new MessageProperties();        //2.设置存活时间        messageProperties.setExpiration("10000");        //3.创建消息对象        Message message = new Message("send Message,...".getBytes(),messageProperties);        //4.发送消息        rabbitTemplate.convertAndSend("my_topic_exchange","my_routing",message);    &#125;</code></pre><p>接下里注意两个事情</p><h5 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h5><p>1 如果设置了单条消息的存活时间，也设置了队列的存活时 间，以时间短的为准。</p><p>2 消息过期后，并不会马上移除消息，只有<strong>消息消费到队列顶端</strong>时，才会移除该消息。</p><h4 id="优先级队列"><a href="#优先级队列" class="headerlink" title="优先级队列"></a>优先级队列</h4><p>假设在电商系统中有一个订单催付的场景，即客户在一段时间内未 付款会给用户推送一条短信提醒，但是系统中分为大型商家和小型商家。比如像苹果，小米这样大商家一年能给我们创造很大的利润，所以在订单量大时，他们的订单必须得到优先处理，此时就需 要为不同的消息设置不同的优先级，此时我们要使用优先级队列。    优先级数值越大，越先被消费</p><p>1 创建队列和交换机</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myproducer1;import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;//@Configurationpublic class RabbitConfig3 &#123;    private final String EXCHANGE_NAME = "priority_exchange";    private final String QUEUE_NAME = "priority_queue";    // 创建交换机    @Bean(EXCHANGE_NAME)    public Exchange getExchange() &#123;        return ExchangeBuilder                .topicExchange(EXCHANGE_NAME) // 交换机类型                .durable(true) // 是否持久化                .build();    &#125;    // 创建队列    @Bean(QUEUE_NAME)    public Queue getMessageQueue() &#123;        return QueueBuilder                .durable(QUEUE_NAME)//队列持久化                .maxPriority(10)//设置队列的最大优先级，最大可以到255，官网推荐不超过10，太高比较浪费资源                .build();    &#125;    // 交换机绑定队列    @Bean//参数的交换机和队列都是从spring容器中拿的    public Binding bindMessageQueue(@Qualifier(EXCHANGE_NAME) Exchange exchange, @Qualifier(QUEUE_NAME) Queue queue) &#123;        return BindingBuilder                .bind(queue)                .to(exchange)                .with("my_routing").noargs();    &#125;&#125;</code></pre><p>2 编写生产者</p><pre class=" language-JAVA"><code class="language-JAVA">@Testpublic void testPriority()&#123;    for (int i = 0; i < 10; i++) &#123;        if (i==5)&#123;//i为5时优先级较高            //1.创建消息属性            MessageProperties messageProperties = new MessageProperties();            //2.设置优先级            messageProperties.setPriority(9);            //3.创建消息对象            Message message = new Message(("send Message,..."+i).getBytes(),messageProperties);            //4.发送消息            rabbitTemplate.convertAndSend("priority_exchange","my_routing",message);        &#125;else &#123;            rabbitTemplate.convertAndSend("priority_exchange","my_routing","send Message");        &#125;    &#125;&#125;</code></pre><p>3 编写消费者</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myconsumer1;import com.rabbitmq.client.Channel;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;import java.io.IOException;@Componentpublic class PriorityConsumer &#123;//    @RabbitListener(queues = "priority_queue")    public void listenMessage(Message message, Channel channel) throws IOException &#123;        //获取消息        System.out.println(new String(message.getBody()));        //签收消息        channel.basicAck(message.getMessageProperties().getDeliveryTag(), true);    &#125;&#125;</code></pre><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407101710237.png" alt="image-20220407101710237"></p><h4 id="死信队列"><a href="#死信队列" class="headerlink" title="死信队列"></a>死信队列</h4><p>在MQ中，当消息成为死信（Dead message）后，消息中间件可以 将其从当前队列发送到另一个队列中，这个队列就是死信队列。而 在RabbitMQ中，由于有交换机的概念，实际是将死信发送给了死信交换机（Dead Letter Exchange，简称DLX）。死信交换机和死信队列和普通的没有区别。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407182948566.png" alt="image-20220407182948566"></p><p>消息成为死信的情况： </p><p>1 队列消息长度到达限制。 </p><p>2 消费者拒签消息，并且不把消息重新放入原队列。 </p><p>3 消息到达存活时间未被消费。</p><h5 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h5><p>创建死信队列</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myproducer1;import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RabbitConfig4 &#123;    private final String DEAD_EXCHANGE = "dead_exchange";    private final String DEAD_QUEUE = "dead_queue";    private final String NORMAL_EXCHANGE = "normal_exchange";    private final String NORMAL_QUEUE = "normal_queue";    // 死信交换机    @Bean(DEAD_EXCHANGE)    public Exchange deadExchange() &#123;        return ExchangeBuilder                .topicExchange(DEAD_EXCHANGE) // 交换机类型                .durable(true) // 是否持久化                .build();    &#125;    // 死信队列    @Bean(DEAD_QUEUE)    public Queue deadQueue() &#123;        return QueueBuilder                .durable(DEAD_QUEUE)                .build();    &#125;    // 死信交换机绑定死信队列    @Bean    public Binding bindDeadQueue(@Qualifier(DEAD_EXCHANGE) Exchange exchange, @Qualifier(DEAD_QUEUE) Queue queue) &#123;        return BindingBuilder                .bind(queue)                .to(exchange)                .with("dead_routing").noargs();    &#125;    //普通交换机    @Bean(NORMAL_EXCHANGE)    public Exchange normalExchange() &#123;        return ExchangeBuilder                .topicExchange(NORMAL_EXCHANGE) // 交换机类型                .durable(true) // 是否持久化                .build();    &#125;    // 普通队列    @Bean(NORMAL_QUEUE)    public Queue normalQueue() &#123;        return QueueBuilder                .durable(NORMAL_QUEUE)                .deadLetterExchange(DEAD_EXCHANGE)//绑定死信交换机                .deadLetterRoutingKey("dead_routing")//死信队列路由关键字                .ttl(10000)//消息存活10秒                .maxLength(10)//队列最大长度为10                .build();    &#125;    // 普通交换机绑定普通队列    @Bean    public Binding bindMessageQueue(@Qualifier(NORMAL_EXCHANGE) Exchange exchange, @Qualifier(NORMAL_QUEUE) Queue queue) &#123;        return BindingBuilder                .bind(queue)                .to(exchange)                .with("my_routing").noargs();    &#125;&#125;</code></pre><h6 id="注意：-1"><a href="#注意：-1" class="headerlink" title="注意："></a>注意：</h6><p><strong>普通队列绑定死信队列时，需要绑定死信交换机和死信队列的路由关键字</strong></p><h5 id="测试死信队列"><a href="#测试死信队列" class="headerlink" title="测试死信队列"></a>测试死信队列</h5><p>1 生产者发送消息</p><pre class=" language-JAVA"><code class="language-JAVA">  @Test    public void testDlx()&#123;        //存活时间过期后变成死信//        rabbitTemplate.convertAndSend("normal_exchange","my_routing","测试死信！");        //超过队列长度后变成死信//        for (int i = 0; i < 20; i++) &#123;//            rabbitTemplate.convertAndSend("normal_exchange","my_routing","测试死信！");//        &#125;        //消息拒签但不返回原队列后变成死信        rabbitTemplate.convertAndSend("normal_exchange","my_routing","测试死信！");    &#125;</code></pre><p>存活时间过期</p><p>消息超时放到死信队列中</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407135305003.png" alt="image-20220407135305003"></p><p>超出长度后放到死信队列当中</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407135748948.png" alt="image-20220407135748948"></p><p>拒签</p><p>因为忘记开消费者，所以之前发的一条消息超时放进去变24，然后先开启拒签消费者再发送</p><p>然后消费方开不起来，一看，消费方没加@Component</p><p>一发完就直接拒签进死信，完全不放原来队列</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407140653964.png" alt="image-20220407140653964"></p><h4 id="延迟队列"><a href="#延迟队列" class="headerlink" title="延迟队列"></a>延迟队列</h4><p>延迟队列，即消息进入队列后不会立即被消费，只有到达指定时间 后，才会被消费。 例如：用户下单后，30分钟后查询订单状态，未支付则会取消订单。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407184303377.png" alt="image-20220407184303377"></p><p>但RabbitMQ中并未提供延迟队列功能，我们可以使用死信队列实现延迟队列的效果。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407184325497.png" alt="image-20220407184325497"></p><h5 id="死信队列实现"><a href="#死信队列实现" class="headerlink" title="死信队列实现"></a>死信队列实现</h5><h5 id="插件实现"><a href="#插件实现" class="headerlink" title="插件实现"></a>插件实现</h5><p>在使用死信队列实现延迟队列时，会遇到一个问题：RabbitMQ只 会移除队列顶端的过期消息，如果第一个消息的存活时长较长，而 第二个消息的存活时长较短，则第二个消息并不会及时执行。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407194715665.png" alt="image-20220407194715665"></p><p>RabbitMQ虽然本身不能使用延迟队列，但官方提供了延迟队列插 件，安装后可直接使用延迟队列。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407194730806.png" alt="image-20220407194730806"></p><h6 id="安装延迟队列插件"><a href="#安装延迟队列插件" class="headerlink" title="安装延迟队列插件"></a>安装延迟队列插件</h6><p>1 上传至&#x2F;usr&#x2F;local&#x2F;rabbitmq&#x2F;plugins&#x2F;下</p><p>2 启用插件</p><pre class=" language-bash"><code class="language-bash">rabbitmq-plugins <span class="token function">enable</span> rabbitmq_delayed_message_exchange</code></pre><p>3 重启RabbitMQ服务</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#停止rabbitmq</span>rabbitmqctl stop<span class="token comment" spellcheck="true">#启动rabbitmq</span>rabbitmq-server restart -detached</code></pre><p>这样就把延队列的一个插件安装成功了，此时登录管控台可以看到交换机类型多了延迟消息</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407185450590.png" alt="image-20220407185450590"></p><h6 id="使用延迟队列"><a href="#使用延迟队列" class="headerlink" title="使用延迟队列"></a>使用延迟队列</h6><p>1 创建延迟交换机和延迟队列</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myorder;import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.HashMap;import java.util.Map;@Configurationpublic class RabbitConfig2 &#123;    public final String DELAYED_EXCHANGE = "delayed_exchange";    public final String DELAYED_QUEUE = "delayed_queue";    //1.延迟交换机    @Bean(DELAYED_EXCHANGE)    public Exchange delayedExchange() &#123;        // 创建自定义交换机        Map<String, Object> args = new HashMap<>();        //就是延迟交换机也是有实际类型的        args.put("x-delayed-type","topic"); // topic类型的延迟交换机        //参数：交换机名字，类型，是否持久化，是否自动删除        return new CustomExchange(DELAYED_EXCHANGE, "x-delayed-message", true, false, args);    &#125;    //2.延迟队列    @Bean(DELAYED_QUEUE)    public Queue delayedQueue() &#123;        return QueueBuilder                .durable(DELAYED_QUEUE)                .build();    &#125;    // 3.绑定    @Bean    public Binding    bindingDelayedQueue(@Qualifier(DELAYED_QUEUE) Queue queue, @Qualifier(DELAYED_EXCHANGE) Exchange exchange) &#123;        return BindingBuilder                .bind(queue)                .to(exchange)                .with("order_routing").noargs();    &#125;&#125;</code></pre><p>就不能使用ExchangeBuilder去创建交换机了，因为没有</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407185932617.png" alt="image-20220407185932617"></p><p>需要注意的一点就是我们创建延迟队列的时候没有办法去设置消息的延迟时间，只有在发送消息的时候才能去设置一个延迟时间</p><p>2 编写下单的控制器方法</p><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">//插件下单</span><span class="token annotation punctuation">@GetMapping</span><span class="token punctuation">(</span><span class="token string">"/place2/&amp;#123;orderId&amp;#125;"</span><span class="token punctuation">)</span><span class="token keyword">public</span> String <span class="token function">placeOrders</span><span class="token punctuation">(</span><span class="token annotation punctuation">@PathVariable</span> String orderId<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"处理订单数据---插件实现延迟队列？"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//设置延迟时间10s</span>    MessagePostProcessor messagePostProcessor <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">MessagePostProcessor</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> Message <span class="token function">postProcessMessage</span><span class="token punctuation">(</span>Message message<span class="token punctuation">)</span> <span class="token keyword">throws</span> AmqpException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            message<span class="token punctuation">.</span><span class="token function">getMessageProperties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setDelay</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> message<span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//将订单id发送到订单队列</span>    rabbitTemplate<span class="token punctuation">.</span><span class="token function">convertAndSend</span><span class="token punctuation">(</span><span class="token string">"delayed_exchange"</span><span class="token punctuation">,</span><span class="token string">"order_routing"</span><span class="token punctuation">,</span>orderId<span class="token punctuation">,</span>messagePostProcessor<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token string">"下单成功，修改库存--插件"</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p>3 编写延迟队列的消费者</p><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">//监听过期订单的队列，普通订单队列是不需要监听的</span><span class="token annotation punctuation">@RabbitListener</span><span class="token punctuation">(</span>queues <span class="token operator">=</span> <span class="token string">"delayed_queue"</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listenMessage2</span><span class="token punctuation">(</span>String orderId<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"查询"</span><span class="token operator">+</span>orderId<span class="token operator">+</span><span class="token string">"号订单的状态，如果已支付无需处理，如果未支付则回退库存"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p>访问测试</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407194248473.png" alt="image-20220407194248473"></p><p>然后发消息之后，队列中也是没有显示的，直接就给消费者了。然后消费者等了10s之后才去消费</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407194429308.png" alt="image-20220407194429308"></p><p>然后就是使用插件比较方便一些，就没有必要去创建那么多的交换机和队列</p><h4 id="搭建集群"><a href="#搭建集群" class="headerlink" title="搭建集群"></a>搭建集群</h4><p>就是单台MQ无法满足消息的吞吐量以及安全性要求的时候，就比如无法满足消息的吞吐量：RabbitMQ每秒能接收1万条消息，但是系统能生产5万</p><p>安全性：单台宕机</p><p>这里就一个机器设置两个RabbitMQ服务了</p><p>1 设置两个RabbitMQ服务</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 关闭RabbitMQ服务</span>rabbitmqctl stop<span class="token comment" spellcheck="true"># 设置服务一</span>RABBITMQ_NODE_PORT<span class="token operator">=</span>5673 RABBITMQ_NODENAME<span class="token operator">=</span>rabbit1 rabbitmq-server start -detached<span class="token comment" spellcheck="true"># 设置服务二</span>RABBITMQ_NODE_PORT<span class="token operator">=</span>5674 RABBITMQ_SERVER_START_ARGS<span class="token operator">=</span><span class="token string">"-rabbitmq_management listener [&amp;#123;port,15674&amp;#125;]"</span> RABBITMQ_NODENAME<span class="token operator">=</span>rabbit2 rabbitmq-server start -detached这里只是启动了两个服务，不是在一个集群里，然后启动后之前创建的数据都会丢失，包括创建的页面</code></pre><p>2 将两个服务设置到同一集群中</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 关闭服务2</span>rabbitmqctl -n rabbit2 stop_app    <span class="token comment" spellcheck="true"># 重新设置服务2</span>rabbitmqctl -n rabbit2 reset<span class="token comment" spellcheck="true"># 将服务2加入服务1中</span>rabbitmqctl -n rabbit2 join_cluster rabbit1@localhost<span class="token comment" spellcheck="true"># 启动服务2</span>rabbitmqctl -n rabbit2 start_app</code></pre><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407203916178.png" alt="image-20220407203916178"></p><p>5672希望留给负载均衡服务器用</p><p>将服务2加入服务1中,网上看的都是装在windows的cookie不一致</p><p>然后我去分别看了一下</p><p>&#x2F;root&#x2F;.erlang.cookie         ~&#x2F;.erlang.cookie </p><p>里面的cookie是一样的</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407211558045.png" alt="image-20220407211558045"></p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407210329849.png" alt="image-20220407210329849"></p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407211610431.png" alt="image-20220407211610431"></p><p>我就是加不进去啊！！就先放着吧，也不知道啥问题</p><h4 id="镜像队列"><a href="#镜像队列" class="headerlink" title="镜像队列"></a>镜像队列</h4><p>搭建了集群后，虽然多个节点可以互相通信，但队列只保存在了一 个节点中，如果该节点故障，则整个集群都将丢失消息。</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 关闭服务1</span>rabbitmqctl -n rabbit1 stop_app</code></pre><p>2就访问不到了废了</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407213037708.png" alt="image-20220407213037708"></p><p>此时我们需要引入镜像队列机制，它可以将队列消息复制到集群中的其他节点上。如果一个节点失效了，另一个节点上的镜像可以保证服务的可用性。</p><p>在管控台点击 Admin —&gt; Policies 设置镜像队列</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407213059056.png" alt="image-20220407213059056"></p><p>此时某个节点故障则不会影响整个集群。</p><h4 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h4><p>无论是生产者还是消费者，只能连接一个RabbitMQ节点，而在我 们使用RabbitMQ集群时，如果只连接一个RabbitMQ节点，会造成 该节点的压力过大。我们需要平均的向每个RabbitMQ节点发送请 求，此时需要一个负载均衡工具帮助我们分发请求，接下来使用 Haproxy做负载均衡：</p><p>1 安装Haproxy</p><pre class=" language-bash"><code class="language-bash">yum -y <span class="token function">install</span> haproxy</code></pre><p>2 配置Haproxy</p><pre class=" language-bash"><code class="language-bash">vim /etc/haproxy/haproxy.cfg</code></pre><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 以下为修改内容</span>defaults <span class="token comment" spellcheck="true"># 修改为tcp</span> mode tcp<span class="token comment" spellcheck="true"># 以下为添加内容</span>listen rabbitmq_cluster <span class="token comment" spellcheck="true"># 对外暴露端口</span>       bind 0.0.0.0:5672       mode tcp       balance roundrobin       <span class="token comment" spellcheck="true"># 代理RabbitMQ的端口</span>       server node1 127.0.0.1:5673 check inter 5000 rise 2 fall 2       server node2 127.0.0.1:5674 check inter 5000 rise 2 fall 2listen stats <span class="token comment" spellcheck="true"># Haproxy控制台路径</span>       bind 192.168.0.162:8100       mode http       option httplog       stats <span class="token function">enable</span>       stats uri /rabbitmq-stats       stats refresh 5s</code></pre><p>3 启动Haproxy    </p><pre class=" language-bash"><code class="language-bash">haproxy -f /etc/haproxy/haproxy.cfg    </code></pre><p>4 访问Haproxy控制台：<a href="http://192.168.0.162:8100/rabbitmq-stats">http://192.168.0.162:8100/rabbitmq-stats</a></p><p>5 生产者连接Haproxy发送消息</p><pre class=" language-JAVA"><code class="language-JAVA">// 生产者public class Producer &#123;    public static void main(String[] args)throws IOException, TimeoutException &#123;        ConnectionFactory connectionFactory = newConnectionFactory();              connectionFactory.setHost("192.168.0.162");        connectionFactory.setPort(5672);              connectionFactory.setUsername("guest");              connectionFactory.setPassword("guest");              connectionFactory.setVirtualHost("/");        Connection conn = connectionFactory.newConnection();        Channel channel = conn.createChannel();              channel.queueDeclare("simple_queue",false, false, false, null);        channel.basicPublish("","simple_queue", null,"hello!rabbitmq!".getBytes());        channel.close();        conn.close();   &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper笔记2</title>
      <link href="/2022/04/01/zookeeper-bi-ji-2/"/>
      <url>/2022/04/01/zookeeper-bi-ji-2/</url>
      
        <content type="html"><![CDATA[<hr><h3 id="集中式到分布式"><a href="#集中式到分布式" class="headerlink" title="集中式到分布式"></a>集中式到分布式</h3><p>集群：多个人在一起做同样的事</p><p>分布式：多个人在一起做不同的事情</p><h4 id="单机架构"><a href="#单机架构" class="headerlink" title="单机架构"></a>单机架构</h4><p>一个系统业务量很小的时候所有的代码都放在一个项目中就好了， 然后这个项目部署在一台服务器上，整个项目所有的服务都由这台 服务器提供。</p><h5 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h5><ul><li>服务性能存在瓶颈 </li><li>不可伸缩性 </li><li>代码量庞大，系统臃肿，牵一发动全身 </li><li>单点故障问题</li></ul><h4 id="集群架构"><a href="#集群架构" class="headerlink" title="集群架构"></a>集群架构</h4><p>单机处理到达瓶颈的时候，你就把单机复制几份，这样就构成了一个集群。</p><h5 id="集群存在的问题"><a href="#集群存在的问题" class="headerlink" title="集群存在的问题:"></a>集群存在的问题:</h5><p>当你的业务发展到一定程度的时候，你会发现一个问题无论怎 么增加节点，貌似整个集群性能的提升效果并不明显了。这时 候，你就需要使用分布式架构了。</p><h4 id="什么是分布式"><a href="#什么是分布式" class="headerlink" title="什么是分布式"></a>什么是分布式</h4><p>分布式架构就是将一个完整的系统，按照业务功能，拆分成一个个 独立的子系统，在分布式结构中，每个子系统就被称为“服务”。这 些子系统能够独立运行在web容器中，它们之间通过RPC方式通信。</p><h5 id="分布式的优势"><a href="#分布式的优势" class="headerlink" title="分布式的优势:"></a>分布式的优势:</h5><ul><li>系统之间的耦合度大大降低，可以独立开发、独立部署、独立测试，系统与系统之间的边界 非常明确，排错也变得相当容易，开发效率大大提升。</li></ul><ul><li><p>系统之间的耦合度降低，从而系统更易于扩展。我们可以针对性地扩展某些服务。 </p></li><li><p>服务的复用性更高。比如，当我们将用户系统作为单独的服务后，该公司所有的产品都可以 使用该系统作为用户系统，无需重复开发。</p></li></ul><h4 id="三者区别"><a href="#三者区别" class="headerlink" title="三者区别"></a>三者区别</h4><p>我的理解就是，首先我们有一个小饭店，有洗菜、炒菜、切菜、上菜、备料、收银等操作</p><h5 id="单机："><a href="#单机：" class="headerlink" title="单机："></a>单机：</h5><p>一个厨师全干！</p><h5 id="集群："><a href="#集群：" class="headerlink" title="集群："></a>集群：</h5><p>好多个厨师一起做这些活。</p><h5 id="分布式："><a href="#分布式：" class="headerlink" title="分布式："></a>分布式：</h5><p>就有点像大酒店一样，会计，服务员，出事，配菜的人，专门洗菜的人，专门炒菜的厨师。</p><h5 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h5><p>将一套系统拆分成不同子系统部署在不同服务器上（这叫分布 式），然后部署多个相同的子系统在不同的服务器上（这叫集群）。</p><h3 id="CAP定理"><a href="#CAP定理" class="headerlink" title="CAP定理"></a>CAP定理</h3><p>分布式系统的最大难点，就是各个节点的状态如何同步。CAP 定理是这 方面的基本定理，也是理解分布式系统的起点。</p><ul><li>Consistency（一致性） </li><li>Availability （可用性） </li><li>Partition tolerance （分区容错性）</li></ul><p>这三个指标不可能同时做到。这个结论就叫做 CAP 定理。</p><h5 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h5><p>分区容错性是无法避免的，因此可以认为 CAP的 P总是成立。CAP 定 理告诉我们，剩下的 C 和 A 无法同时做到。</p><h5 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h5><p>就是老板和一个服务员A说这个菜价变了，然后别人问另一个服务员B的时候，B只能告诉顾客，菜价还在商定。</p><h5 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h5><p>只要收到用户的请求，服务器就必须给出回应。</p><p>就是不管价格变V0还是V1，只要问了，就必须告诉他</p><h4 id="一致性和可用性如何选择"><a href="#一致性和可用性如何选择" class="headerlink" title="一致性和可用性如何选择"></a>一致性和可用性如何选择</h4><ul><li><h6 id="一致性-1"><a href="#一致性-1" class="headerlink" title="一致性"></a>一致性</h6><p>特别是涉及到重要的数据，就比如钱，商品数量，商品价格。 </p></li><li><h6 id="可用性-1"><a href="#可用性-1" class="headerlink" title="可用性"></a>可用性</h6></li></ul><p>​        网页的更新不是特别强调一致性，短时期内，一些用户拿到老版 本，另一些用户拿到新版本，问题不会特别大。</p><p>外部系统</p><p>分布式服务平台–统一接入管理</p><p>公共服务平台、核心交易平台、信息服务平台、交易后处理平台</p><h5 id="多个节点协同问题"><a href="#多个节点协同问题" class="headerlink" title="多个节点协同问题"></a>多个节点协同问题</h5><p>1.每天的定时任务由哪个节点来执行</p><p>2.RPC调用时的服务发现</p><p>3.如何保证并发请求的幂等</p><p>这些问题可以统一归纳为多节点协调问题，如果靠节点自身进 行协调这是非常不可靠的，性能上也不可取。必须由一个独立 的服务做协调工作，它必须可靠，而且保证性能。</p><p>所以zookeeper就出现发挥作用了</p><h3 id="Zookeeper介绍"><a href="#Zookeeper介绍" class="headerlink" title="Zookeeper介绍"></a>Zookeeper介绍</h3><p>zookeeper是什么，一句话概括，就是文件系统+监听机制     </p><p>ZooKeeper是一个开放源代码的分布式协调服务。ZooKeeper的设 计目标是将那些复杂且容易出错的分布式一致性服务封装起来,构成 一个高效可靠的原语集,并以一系列简单易用的接口提供给用户使用。</p><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>数据发布订阅、负载均衡、命名服务、分布式协调通知</p><h4 id="数据发布-x2F-订阅"><a href="#数据发布-x2F-订阅" class="headerlink" title="数据发布&#x2F;订阅"></a>数据发布&#x2F;订阅</h4><p>数据发布&#x2F;订阅的一个常见的场景是配置中心，发布者把数据发布到 ZooKeeper 的一个或一系列的节点上，供订阅者进行数据订阅，达 到动态获取数据的目的。</p><p>ZooKeeper 采用的是推拉结合的方式。 </p><p>1 推: 服务端会推给注册了监控节点的客户端 Wathcer 事件通知 </p><p>2 拉: 客户端获得通知后，然后主动到服务端拉取最新的数据</p><h4 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h4><p>负载均衡是一种手段，用来把对某种资源的访问分摊给不同的设 备，从而<strong>减轻单点</strong>的压力。</p><h4 id="命名服务"><a href="#命名服务" class="headerlink" title="命名服务"></a>命名服务</h4><p>命名服务就是提供名称的服务。ZooKeeper 的命名服务有两个应用方面。</p><h5 id="功能："><a href="#功能：" class="headerlink" title="功能："></a>功能：</h5><p>1 提供类 JNDI 功能，可以把系统中各种服务的名称、地址以及目录信息存放在 ZooKeeper， 需要的时候去 ZooKeeper 中读取  </p><p>2 制作分布式的序列号生成器 </p><h4 id="分布式协调-x2F-通知"><a href="#分布式协调-x2F-通知" class="headerlink" title="分布式协调&#x2F;通知"></a>分布式协调&#x2F;通知</h4><p>分布式协调&#x2F;通知服务是分布式系统中不可缺少的一个环节,是将不同 的分布式组件有机结合起来的关键所在。对于一个在多台机器上部 署运行的应用而言，通常需要一个协调者(Coordinator）来控制整 个系统的运行流程。</p><h3 id="为什么选择Zookeeper"><a href="#为什么选择Zookeeper" class="headerlink" title="为什么选择Zookeeper"></a>为什么选择Zookeeper</h3><p>分布式架构的出现，越来越多的分布式应用会面临数据一致性 问题。很遗憾的是，在解决分布式数据一致性上，除了ZooKeeper 之外，目前还没有一个成熟稳定且被大规模应用的解决方案。</p><p>ZooKeeper无论从易用性还是稳定性上来说，都已经达到了一 个工业级产品的标准。</p><p>还是免费的。</p><h5 id="广泛应用"><a href="#广泛应用" class="headerlink" title="广泛应用"></a>广泛应用</h5><p>最后，ZooKeeper已经得到了广泛的应用。诸如Hadoop、 HBase、Storm、kafka等越来越多的大型分布式项目都将 Zookeeper作为核心组件。</p><h4 id="集群角色"><a href="#集群角色" class="headerlink" title="集群角色"></a>集群角色</h4><p>通常在分布式系统中，构成一个集群的每一台机器都有自己的角 色，最典型的集群模式就是Master&#x2F;Slave模式（主备模式)。在这种 模式中，我们把能够处理所有写操作的机器称为Master机器，把所 有通过异步复制方式获取最新数据，并提供读服务的机器称为Slave 机器。</p><h5 id="概念颠覆："><a href="#概念颠覆：" class="headerlink" title="概念颠覆："></a>概念颠覆：</h5><p>而在ZooKeeper中，这些概念被颠覆了。它没有沿用传统的 MasterlSlave概念，而是引入了Leader、Follower和 Observer 三种角色。</p><h5 id="数据节点Znode"><a href="#数据节点Znode" class="headerlink" title="数据节点Znode"></a>数据节点Znode</h5><p>ZooKeeper将所有数据存储在内存中，数据模型是一棵树。</p><h4 id="Watcher监听机制"><a href="#Watcher监听机制" class="headerlink" title="Watcher监听机制"></a>Watcher监听机制</h4><p> Watcher(事件监听器)，是ZooKeeper 中的一个很重要的特性。</p><p>ZooKeeper 允许用户在指定节点上注册一些Watcher，并且在 一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到 感兴趣的客户端上去，该机制是ZooKeeper实现分布式协调服务的重要特性。</p><p>比较普通的为数据修改和节点修改（包括删除）</p><h4 id="ACL权限控制"><a href="#ACL权限控制" class="headerlink" title="ACL权限控制"></a>ACL权限控制</h4><p>ZooKeeper 采用ACL (Access Control Lists）策略来进行权限控 制，类似于UNIX文件系统的权限控制。ZooKeeper定义了如下5种 权限。</p><p>CREATE:创建子节点的权限 </p><p>READ:获取节点数据和子节点列表的权限 </p><p>WRITE:更新节点数据的权限 </p><p>DELETE:删除子节点的权限 </p><p>ADMIN:设置节点ACL的权限</p><p>注：create和delete这两种权限都是针对子节点的权限控制。</p><h3 id="集群安装"><a href="#集群安装" class="headerlink" title="集群安装"></a>集群安装</h3><p>创建三台机器，因为配置好了电脑和Vmware的网络，还是dhcp，所以他们的ip就分别为192.168.8.14    192.168.8.15   192.168.8.16</p><p>设置开机激活网卡</p><p>设置关闭防火墙</p><p>这样才能使用Xshell远程连接上</p><p>搭建好第一台机器的zookeeper之后，别的集群机器就不用再重复一样的操作了</p><p>直接传jdk过去</p><p>新版本的搭建zookeeper伪集群</p><p>$PATH相当于是获取计算机之前的环境变量，然后通过冒号再拼接一个刚刚编写的环境变量</p><p>但是再windows里面是%获取</p><pre class=" language-none"><code class="language-none">#  $# 启动脚本携带的参数个数#  -ne 不等于</code></pre><h4 id><a href="#" class="headerlink" title></a></h4><p>服务器与服务器之间可以通过scp这个命令去传</p><pre class=" language-none"><code class="language-none">scp -r jdk/ 198.168.xx.xx:$PWD递归传        就是这台机器什么目录就传给那台机器什么目录 也可以写死:/usr/local/xx</code></pre><p>回车之后就要输入yes和密码</p><p>传zookeeper也是同样的传法</p><p>然后就是和第一台机器一样配置一下环境变量 和让他重新生效一下</p><p>然后三台机器都再配置文件上加上，几台就配几个</p><pre class=" language-none"><code class="language-none">server.1=192.168.8.14:2888:3888server.2=192.168.8.15:2888:3888server.3=192.168.8.16:2888:3888</code></pre><p>然后配置好之后把这个配置文件直接发送给别的机器就行</p><p>然后三台机器的配置文件都是一摸一样的，就得有一个机器的标识</p><p>然后用重定向echo写一下</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191549565.png" alt="image-20220403191549565"></p><p>我就直接配置好一台然后虚拟机拷贝s修改了。。。</p><p>创建数据持久化目录</p><pre class=" language-none"><code class="language-none">mkdir /usr/local/zookeeper/zkdatamkdir /usr/local/zookeeper/zklogs</code></pre><p>配置JDK环境</p><p>vim &#x2F;etc&#x2F;profile  最后这两个</p><pre class=" language-none"><code class="language-none">export JAVA_HOME=/usr/local/jdkexport PATH=$PATH:$JAVA_HOME/bin</code></pre><p>生效环境变量</p><pre class=" language-none"><code class="language-none">source /etc/profile</code></pre><p>然后可以java -version 看一下</p><h5 id="设置一键启动-x2F-一键停止脚本"><a href="#设置一键启动-x2F-一键停止脚本" class="headerlink" title="设置一键启动&#x2F;一键停止脚本"></a><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403190515065.png" alt="image-20220403190515065">设置一键启动&#x2F;一键停止脚本</h5><pre class=" language-sh"><code class="language-sh">if [ $# -ne 1 ];then   echo "无效参数，用法为: $1 &#123;start|stop|restart|status&#125;"   exitfi#遍历所有节点for host in 192.168.8.14 192.168.8.15 192.168.8.16do   echo "========== $host 正在 $1 ========="   #发送命令给目标机器   ssh $host "source /etc/profile; /usr/local/zookeeper/bin/zkServer.sh $1"done</code></pre><p>然后就是给权限</p><p>chmod  777 文件名</p><p>然后启动一下</p><pre class=" language-none"><code class="language-none">./zkStart-all.sh start</code></pre><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191349175.png" alt="image-20220403191349175"></p><p>查看状态</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191355180.png" alt="image-20220330161453551"></p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191359971.png" alt="image-20220403191359971">一个leader (zk-02)两个follower</p><p>节点类型也就还是那四种，持久化，临时；有序无序；看需求2选一组合</p><h3 id="节点特性"><a href="#节点特性" class="headerlink" title="节点特性"></a>节点特性</h3><h4 id="持久节点"><a href="#持久节点" class="headerlink" title="持久节点"></a>持久节点</h4><p>持久节点是zookeeper中最常见的一种节点类型。所谓持久节点， 是指改数据节点被创建后，就会一直存在与zookeeper服务器上， 直到有删除操作来主动清除这个节点。</p><h4 id="持久顺序节点"><a href="#持久顺序节点" class="headerlink" title="持久顺序节点"></a>持久顺序节点</h4><p>这类节点的基本特性和上面的节点类型是一致的。额外的特性是， 在ZK中，每个父节点会为他的第一级子节点维护一份时序，会记录 每个子节点创建的先后顺序。</p><h4 id="临时节点"><a href="#临时节点" class="headerlink" title="临时节点"></a>临时节点</h4><p>区别： 和持久节点不同的是，临时节点的生命周期和客户端会话绑定。也就是说，如果客户端会话失效，那么这个节点就会自动被清除掉。注意，这里提到的是会话失效，而非连接断开。另 外，在临时节点下面不能创建子节点。</p><h4 id="临时顺序节点"><a href="#临时顺序节点" class="headerlink" title="临时顺序节点"></a>临时顺序节点</h4><p>临时顺序节点的基本特性和临时节点是一致的，同样是在临时节点 的基础上，添加了顺序的特性。</p><h3 id="客户端命令行"><a href="#客户端命令行" class="headerlink" title="客户端命令行"></a>客户端命令行</h3><p>create [-s] [-e] path data acl</p><p>参数：</p><p>-s：顺序节点 </p><p>-e：临时节点 </p><p>默认情况下，不添加-s或者-e参数的，创建的是持久节点。</p><p>ls &#x2F;路径   </p><p>读取节点信息</p><p>set &#x2F;路径 data</p><p>更新节点数据</p><p>get &#x2F;路径 </p><p>获取zookeeper指定节点的数据内容和属性信息。</p><p>delete path [version]</p><p>删除指定节点，有子节点就报错</p><h4 id="节点信息"><a href="#节点信息" class="headerlink" title="节点信息"></a>节点信息</h4><p>上一篇笔记有，不过这里有图</p><h3 id="Watcher监听机制-1"><a href="#Watcher监听机制-1" class="headerlink" title="Watcher监听机制"></a><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191407815.png" alt="image-20220403191407815">Watcher监听机制</h3><p>监听节点变化</p><pre class=" language-none"><code class="language-none">ls -w path</code></pre><p>监听节点的值的变化</p><pre class=" language-none"><code class="language-none">get -w path</code></pre><h5 id="Watcher-特性总结"><a href="#Watcher-特性总结" class="headerlink" title="Watcher 特性总结"></a>Watcher 特性总结</h5><h6 id="一次性"><a href="#一次性" class="headerlink" title="一次性"></a>一次性</h6><p>无论是服务端还是客户端，一旦一个 Watcher 被触发，ZooKeeper 都会将其从相应的存储中移除。因此，在 Watcher 的使用上，需要 反复注册。这样的设计有效地减轻了服务端的压力。</p><h5 id="客户端串行执行"><a href="#客户端串行执行" class="headerlink" title="客户端串行执行"></a>客户端串行执行</h5><p>客户端 Watcher 回调的过程是一个<strong>串行同步</strong>的过程，这为我们保证了顺序，同时，需要注意的一点是，一定不能因为一个 Watcher 的处理逻辑影响了整个客户端的 Watcher 回调。</p><p>轻量 WatcherEvent 是 ZooKeeper 整个 Watcher 通知机制的最小通知 单元，这个数据结构中只包含三部分内容：通知状态、事件类型和 节点路径。</p><h3 id="权限控制-ACL"><a href="#权限控制-ACL" class="headerlink" title="权限控制 ACL"></a>权限控制 ACL</h3><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191416175.png" alt="image-20220403191416175">)</p><p>在ZooKeeper的实际使用中，我们的做法往往是搭建一个共用的 ZooKeeper集群，统一为若干个应用提供服务。在这种情况下，不 同的应用之间往往是不会存在共享数据的使用场景的，因此需要解 决不同应用之间的权限问题。</p><p>参数： </p><p>1 ZooKeeper的权限控制是基于每个znode节点的，需要对每个节点设置权限 </p><p>2 每个znode支持设置多种权限控制方案和多个权限 </p><p>3 子节点不会继承父节点的权限，客户端无权访问某节点，但可能可以访问它的子节点</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/Users/jianjian/blog/source/_posts/Zookeeper%E7%AC%94%E8%AE%B02/image-20220403182150011.png" alt="image-20220403182150011"></p><h5 id="schema"><a href="#schema" class="headerlink" title="schema"></a>schema</h5><p>ZooKeeper内置了一些权限控制方案，可以用以下方案为每个节点设置权限：</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191422575.png" alt="image-20220403191422575"></p><p><img src="/2022/04/01/zookeeper-bi-ji-2/Users/jianjian/blog/source/_posts/Zookeeper%E7%AC%94%E8%AE%B02/image-20220403182623463.png" alt="image-20220403182623463"></p><h5 id="id"><a href="#id" class="headerlink" title="id"></a>id</h5><p>授权对象ID是指，权限赋予的用户或者一个实体，例如：IP 地址或 者机器。授权模式 schema 与 授权对象 ID 之间关系：</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191427673.png" alt="image-20220403191427673">)</p><h5 id="权限permission"><a href="#权限permission" class="headerlink" title="权限permission"></a>权限permission</h5><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191431927.png" alt="image-20220403191431927"></p><h5 id="权限相关命令"><a href="#权限相关命令" class="headerlink" title="权限相关命令"></a>权限相关命令</h5><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191436188.png" alt="image-20220403191436188"></p><h6 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h6><p>默认创建一个节点就是world方案，就是任何人都拥有所有权限</p><h6 id="ip"><a href="#ip" class="headerlink" title="ip"></a>ip</h6><pre class=" language-none"><code class="language-none">setAcl /node2 ip:192.168.100.1:cdrwa </code></pre><h6 id="Auth方案"><a href="#Auth方案" class="headerlink" title="Auth方案"></a>Auth方案</h6><p>语法格式：</p><pre class=" language-none"><code class="language-none">setAcl <path> auth:<user>:<acl></code></pre><p>添加认证用户</p><pre class=" language-none"><code class="language-none">addauth digest <user>:<password></code></pre><p>注：断开会话重连需要重 新addauth添加认证用户</p><h4 id="原生API操作Zookeeper"><a href="#原生API操作Zookeeper" class="headerlink" title="原生API操作Zookeeper"></a>原生API操作Zookeeper</h4><pre class=" language-Java"><code class="language-Java">/** * zookeeper原生API操作 */public class ZKMain &#123;    public static void main(String[] args) throws IOException, InterruptedException, KeeperException &#123;        //1.创建会话        /**         * 参数解释：         *  param 1 - Zookeeper 的实例 ip ，此处是一个集群，所以配置了多个 ip，用逗号隔开         *  param 2 - session 过期时间，单位秒(1000),会话超时时间         *  param 3 - 监视者，用于获取监听事件，监听机制         */        ZooKeeper zk = new ZooKeeper("192.168.8.14,192.168.8.15," +                "192.168.8.16",4000,null);        //查看链接状态        System.out.println(zk.getState());        /**         * 创建节点         * 第一个参数：节点名字         * 节点数据         * ACL策略  OpenAcl:完全开放，任何属性都能操作，还有就是创建者，可读...         * 节点类型         *///        zk.create("/node1","123".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);//        System.out.println("========创建成功============");        //判断节点是否存在//        Stat node1 = zk.exists("/node1", null);//        System.out.println(node1.toString());        //删除节点   -1全匹配全部版本号        zk.delete("/node1",-1);        //修改节点        zk.setData("/node1","fuckkkk".getBytes(),-1);        //获取节点数据        byte[] data = zk.getData("/node1", null, null);        System.out.println(new String(data));        //获取节点        List<String> children = zk.getChildren("/node1", null);        for (String child: children             ) &#123;            System.out.println(child);        &#125;    &#125;&#125;</code></pre><p>下来就是看如何实现监听的机制</p><p>针对于节点的监听</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191451855.png" alt="image-20220403191451855"></p><p>监听节点数据</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191456045.png" alt="image-20220403191456045"></p><p>监听节点，监听数据</p><p>使用原生AP操作的话，他的监听就是只有一次的，要想多次监听，就还得重新注册，这就是一个坏处</p><p>具体怎么一个监听一次呢，就是你一直运行着这个项目，然后直接去改节点数据，一改完就可以看见监听成功的回调，然后你清空控制台，再去修改一次节点数据，然后回去看控制台什么反应都没有的</p><h4 id="ZkClient操作Zookeeper"><a href="#ZkClient操作Zookeeper" class="headerlink" title="ZkClient操作Zookeeper"></a>ZkClient操作Zookeeper</h4><pre class=" language-Java"><code class="language-Java">package com.jian.zookeepernewdemo;import org.I0Itec.zkclient.IZkChildListener;import org.I0Itec.zkclient.IZkDataListener;import org.I0Itec.zkclient.ZkClient;import org.apache.zookeeper.CreateMode;import java.util.List;public class ZKClientMain &#123;    public static void main(String[] args) throws InterruptedException &#123;        //1.创建会话        ZkClient zk = new ZkClient("192.168.8.14,192.168.8.15,192.168.8.16");        //2.获取子节点//        List<String> children = zk.getChildren("/node");//        children.forEach(f ->&#123;//            System.out.println(f);//        &#125;);                //3.创建节点//        zk.create("/node3","666", CreateMode.PERSISTENT);//        System.out.println("创建节点成功");        //4.修改节点数据//        zk.writeData("/node3","fuckkk");        //5.获取数据//        String o = zk.readData("/node3");//        System.out.println(o);        //6.删除数据//        zk.delete("/node3");        //7.注册节点监听事件//        zk.subscribeChildChanges("/node", new IZkChildListener() &#123;//            @Override//            public void handleChildChange(String s, List<String> list) throws Exception &#123;////                System.out.println("数据发生改变");//                list.forEach(f ->&#123;//                    System.out.println(f);//                &#125;);//            &#125;//        &#125;);        //8.注册节点数据监听事件            zk.subscribeDataChanges("/node2", new IZkDataListener() &#123;                @Override                public void handleDataChange(String s, Object o) throws Exception &#123;                &#125;                @Override                public void handleDataDeleted(String s) throws Exception &#123;                    System.out.println("数据被删除了");                &#125;            &#125;);            Thread.sleep(Long.MAX_VALUE);    &#125;&#125;</code></pre><h4 id="Curator"><a href="#Curator" class="headerlink" title="Curator"></a>Curator</h4><p>然后Curator也是一个zookeeper的客户端框架，和ZkClient一样，但是他是全世界范围内使用最广泛的Zookeeper客户端之一，目前已经成为了Apache的顶级项目</p><p>然后有三个版本，直接引入最高级的版本，他是肯定包含低级版本的</p><pre class=" language-Java"><code class="language-Java">package com.jian.zookeepernewdemo;import org.apache.curator.framework.CuratorFramework;import org.apache.curator.framework.CuratorFrameworkFactory;import org.apache.curator.framework.recipes.cache.NodeCache;import org.apache.curator.retry.ExponentialBackoffRetry;import org.apache.zookeeper.CreateMode;import java.util.List;/** * curator的方式操作zookeeper */public class CuratorMain &#123;    public static void main(String[] args) throws Exception &#123;        //1.创建会话        String connStr = "192.168.8.14,192.168.8.15,192.168.8.16";        //工厂模式创建会话        CuratorFramework cur = CuratorFrameworkFactory.builder()                .connectString(connStr)                .sessionTimeoutMs(5000)//超时时间                .retryPolicy(new ExponentialBackoffRetry(1000, 3))//断开重试机制                .build();        //连接        cur.start();        //2.创建节点//        cur.create()//里面不能写东西，也是通过.调用//        .withMode(CreateMode.PERSISTENT).forPath("/node4","666".getBytes());        //3.获取数据//        byte[] bytes = cur.getData()//                .forPath("/node4");//        System.out.println(new String(bytes));        //4.删除一个节点，这种方式不能删除有子节点的//        cur.delete().forPath("/node4");        //5.删除节点但是这个节点里面有子节点  递归删除//        cur.delete().deletingChildrenIfNeeded().forPath("/node3");        //6.修改节点//        cur.setData().forPath("/node","666".getBytes());        //7.获取某个节点的所有子节点//        List<String> list = cur.getChildren().forPath("/node");//        for (String s:list//             ) &#123;//            System.out.println(s);//        &#125;        //8.监听机制 --永久的        NodeCache nodeCache = new NodeCache(cur,"/node");        nodeCache.getListenable().addListener(() ->&#123;            System.out.println("被修改了.........");        &#125;);        nodeCache.start();//运行跑起来        Thread.sleep(Long.MAX_VALUE);    &#125;&#125;</code></pre><h4 id="四字命令"><a href="#四字命令" class="headerlink" title="四字命令"></a>四字命令</h4><p>这里不多解释</p><p>ruok有点问题，就是他说没问题，他有可能是服务出现问题，所以在工作中不要用ruok来判断zookeeper运行没运行</p><p>用的比较多的就是conf、cons、stat</p><h4 id="选举机制"><a href="#选举机制" class="headerlink" title="选举机制"></a>选举机制</h4><p>采用半数选举的方式</p><h5 id="核心选举原则"><a href="#核心选举原则" class="headerlink" title="核心选举原则"></a>核心选举原则</h5><ul><li><p>Zookeeper集群中只有超过半数以上的服务器启动，集群才能正常工作； </p></li><li><p>在集群正常工作之前，myid小的服务器给myid大的服务器投票，直到集群正常工作，选出 Leader； </p></li><li><p>半数机制；</p><h4 id="选举机制流程"><a href="#选举机制流程" class="headerlink" title="选举机制流程"></a>选举机制流程</h4></li><li><p>服务器1启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息， 服务器1的状态一直属于Looking(选举状态)。 </p></li><li><p>服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的编号大所以服务 器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。 </p></li><li><p>服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的编号最大所以 服务器3胜出，此时投票数正好大于半数，所以服务器3成为领导者，服务器1,2成为小弟。 </p></li><li><p>服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的编号大，但 之前服务器3已经胜出，所以服务器4只能成为小弟。 </p></li><li><p>服务器5启动，后面的逻辑同服务器4成为小弟。</p></li></ul><h5 id="选择机制中的概念"><a href="#选择机制中的概念" class="headerlink" title="选择机制中的概念"></a>选择机制中的概念</h5><h6 id="Serverid：服务器ID"><a href="#Serverid：服务器ID" class="headerlink" title="Serverid：服务器ID"></a>Serverid：服务器ID</h6><p>比如有三台服务器，编号分别是1,2,3。</p><p><strong>编号越大在选择算法中的权重越大。</strong></p><h6 id="Zxid：数据ID"><a href="#Zxid：数据ID" class="headerlink" title="Zxid：数据ID"></a>Zxid：数据ID</h6><p>服务器中存放的最大数据ID.</p><p><strong>值越大说明数据越新，在选举算法中数据越新权重越大。</strong></p><h6 id="Epoch：逻辑时钟"><a href="#Epoch：逻辑时钟" class="headerlink" title="Epoch：逻辑时钟"></a>Epoch：逻辑时钟</h6><p>或者叫投票的次数，同一轮投票过程中的逻辑时钟值是相同的。每 投完一次票这个数据就会增加，然后与接收到的其它服务器返回的 投票信息中的数值相比，根据不同的值做出不同的判断。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper笔记1</title>
      <link href="/2022/03/29/zookeeper-bi-ji-1/"/>
      <url>/2022/03/29/zookeeper-bi-ji-1/</url>
      
        <content type="html"><![CDATA[<hr><hr><h5 id="注："><a href="#注：" class="headerlink" title="注："></a>注：</h5><p>笔记为技术入门学习，到时候再写一篇书籍《Zookeeper分布式过程协同技术详解的笔记》</p><h3 id="一、-Zookeeper-简介"><a href="#一、-Zookeeper-简介" class="headerlink" title="一、 Zookeeper 简介"></a>一、 Zookeeper 简介</h3><h4 id="1-什么是-Zookeeper"><a href="#1-什么是-Zookeeper" class="headerlink" title="1 什么是 Zookeeper"></a>1 什么是 Zookeeper</h4><p>Zookeeper 是 Apache 的一个分布式服务框架，是 Apache Hadoop 的一个子项目。官方 文档上这么解释 Zookeeper，它主要是用来解决分布式应用中经常遇到的一些数据管理问题， 如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。 </p><p><strong>简单来说 zookeeper&#x3D;文件系统+监听通知机制</strong></p><h3 id="二、-Zookeeper-存储结构"><a href="#二、-Zookeeper-存储结构" class="headerlink" title="二、 Zookeeper 存储结构"></a>二、 Zookeeper 存储结构</h3><h4 id="1-Znode"><a href="#1-Znode" class="headerlink" title="1 Znode"></a><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329120753191.png" alt="image-20220329120753191">1 Znode</h4><p>在 Zookeeper 中，znode 是一个跟 Unix 文件系统路径相似的节点，可以向节点存储数据或者获取数据。 </p><p>Zookeeper 底层是一套数据结构。这个存储结构是一个树形结构，其上的每一个节点， 我们称之为“znode” </p><p>Zookeeper 中的数据是按照“树”结构进行存储的。而且 znode 节点还分为 4 中不同的类型。 </p><p>每一个 znode 默认能够存储 1MB 的数据（对于记录状态性质的数据来说，够了） </p><p>可以使用 zkCli 命令，登录到 Zookeeper 上，并通过 ls、create、delete、get、set 等命令操作这些 znode 节点</p><h4 id="2-Znode-节点类型"><a href="#2-Znode-节点类型" class="headerlink" title="2 Znode 节点类型"></a>2 Znode 节点类型</h4><h5 id="2-1-PERSISTENT-持久化目录节点"><a href="#2-1-PERSISTENT-持久化目录节点" class="headerlink" title="2.1 PERSISTENT-持久化目录节点"></a>2.1 PERSISTENT-持久化目录节点</h5><p>客户端与 zookeeper 断开连接后，该节点依旧存在。 </p><h5 id="2-2-PERSISTENT-SEQUENTIAL-持久化顺序编号目录节点"><a href="#2-2-PERSISTENT-SEQUENTIAL-持久化顺序编号目录节点" class="headerlink" title="2.2 PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点"></a>2.2 PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点</h5><p>客户端与 zookeeper 断开连接后，该节点依旧存在，只是 Zookeeper 给该节点名称进行顺序编号。 </p><h5 id="2-3-EPHEMERAL-临时目录节点"><a href="#2-3-EPHEMERAL-临时目录节点" class="headerlink" title="2.3 EPHEMERAL-临时目录节点"></a>2.3 EPHEMERAL-临时目录节点</h5><p>客户端与 zookeeper 断开连接后，该节点被删除。 </p><h5 id="2-4-EPHEMERAL-SEQUENTIAL-临时顺序编号目录节点"><a href="#2-4-EPHEMERAL-SEQUENTIAL-临时顺序编号目录节点" class="headerlink" title="2.4 EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点"></a>2.4 EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点</h5><p>客户端与 zookeeper 断开连接后，该节点被删除，只是 Zookeeper 给该节点名称进行顺序编号。</p><h3 id="三、-监听通知机制"><a href="#三、-监听通知机制" class="headerlink" title="三、 监听通知机制"></a>三、 监听通知机制</h3><p>Zookeeper 是使用观察者设计模式来设计的。当客户端注册监听它关心的目录节点时， 当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，Zookeeper 会通知客户端。</p><h3 id="四、-安装-zookeeper"><a href="#四、-安装-zookeeper" class="headerlink" title="四、 安装 zookeeper"></a>四、 安装 zookeeper</h3><h4 id="1-安装单机版"><a href="#1-安装单机版" class="headerlink" title="1.安装单机版"></a>1.安装单机版</h4><p>首先先去创建一台虚拟机，然后安装一下JDK以及配置一个环境变量</p><p>接着就是上传和解压zookeeper的压缩包</p><h4 id="2-Zookeeper-目录结构"><a href="#2-Zookeeper-目录结构" class="headerlink" title="2.Zookeeper 目录结构"></a>2.Zookeeper 目录结构</h4><pre class=" language-none"><code class="language-none">1. bin：放置运行脚本和工具脚本，2. conf：zookeeper 默认读取配置的目录，里面会有默认的配置文件3. docs：zookeeper 相关的文档4. lib：zookeeper 核心的 jar5. logs：zookeeper 日志</code></pre><h4 id="3-配置zookeeper"><a href="#3-配置zookeeper" class="headerlink" title="3.配置zookeeper"></a>3.配置zookeeper</h4><p>Zookeeper 在启动时默认的去 conf 目录下查找一个名称为 zoo.cfg 的配置文件。 在 zookeeper 应用目录中有子目录 conf。其中有配置文件模板：zoo_sample.cfg cp zoo_sample.cfg zoo.cfg。zookeeper 应用中的配置文件为 conf&#x2F;zoo.cfg。</p><p>修改配置文件 zoo.cfg - 设置数据缓存路径</p><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329124124371.png" alt="image-20220329124124371"></p><h4 id="4-启动-Zookeeper"><a href="#4-启动-Zookeeper" class="headerlink" title="4.启动 Zookeeper"></a>4.启动 Zookeeper</h4><p>默认加载配置文件：.&#x2F;zkServer.sh start：默认的会去 conf 目录下加载 zoo.cfg 配置文件。 </p><p>指定加载配置文件：.&#x2F;zkServer.sh start <strong>配置文件的路径。</strong></p><h4 id="5-停止zookeeper"><a href="#5-停止zookeeper" class="headerlink" title="5.停止zookeeper"></a>5.停止zookeeper</h4><pre class=" language-none"><code class="language-none">./zkServer.sh stop</code></pre><h4 id="6-查看-Zookeeper-状态"><a href="#6-查看-Zookeeper-状态" class="headerlink" title="6.查看 Zookeeper 状态"></a>6.查看 Zookeeper 状态</h4><pre class=" language-none"><code class="language-none">./zkServer.sh status</code></pre><h4 id="7-使用客户端连接单机版-Zookeepe"><a href="#7-使用客户端连接单机版-Zookeepe" class="headerlink" title="7.使用客户端连接单机版 Zookeepe"></a>7.使用客户端连接单机版 Zookeepe</h4><h5 id="7-1连接方式一"><a href="#7-1连接方式一" class="headerlink" title="7.1连接方式一"></a>7.1连接方式一</h5><p>bin&#x2F;zkCli.sh 默认连接地址为本机地址，默认连接端口为 2181</p><h5 id="7-2连接方式二"><a href="#7-2连接方式二" class="headerlink" title="7.2连接方式二"></a>7.2连接方式二</h5><p>bin&#x2F;zkCli.sh -server ip:port 连接指定 IP 地址与端口</p><h4 id="8-安装集群版"><a href="#8-安装集群版" class="headerlink" title="8.安装集群版"></a>8.安装集群版</h4><h5 id="8-1-Zookeeper-集群中的角色"><a href="#8-1-Zookeeper-集群中的角色" class="headerlink" title="8.1 Zookeeper 集群中的角色"></a>8.1 Zookeeper 集群中的角色</h5><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329124655830.png" alt="image-20220329124655830"></p><p>学习阶段在这里就搭建伪集群了</p><p>应用部署位置是：192.168.233.130。客户端 监听端口分别为：2181、2182、2183。投票选举端口分别为 2881&#x2F;3881、2882&#x2F;3882、2883&#x2F;3883。 tar -zxf zookeeper-3.6.0.tar.gz </p><p>将解压后的 Zookeeper 应用目录重命名，便于管理 mv zookeeper-3.6.0 zookeeper01</p><h5 id="8-2提供数据缓存目录"><a href="#8-2提供数据缓存目录" class="headerlink" title="8.2提供数据缓存目录"></a>8.2提供数据缓存目录</h5><p>在 zookeeper01 应用目录中，创建 data 目录，用于缓存应用运行数据 cd zookeeper01 mkdir data</p><h5 id="8-3复制应用"><a href="#8-3复制应用" class="headerlink" title="8.3复制应用"></a>8.3复制应用</h5><p>复制两份 Zookeeper 应用。用于模拟集群中的 3 个节点。 </p><p>cp -r zookeeper01 zookeeper02 </p><p>cp -r zookeeper01 zookeeper03</p><h5 id="8-4-提供配置文件、设置数据缓存路径"><a href="#8-4-提供配置文件、设置数据缓存路径" class="headerlink" title="8.4 提供配置文件、设置数据缓存路径"></a>8.4 提供配置文件、设置数据缓存路径</h5><p>这个上面有，做相关修改就行</p><h5 id="8-5提供应用唯一标识"><a href="#8-5提供应用唯一标识" class="headerlink" title="8.5提供应用唯一标识"></a>8.5提供应用唯一标识</h5><p>在 Zookeeper 集群中，每个节点需要一个唯一标识。这个唯一标识要求是自然数。且唯 一标识保存位置是：数据缓存目录(dataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;data)的 myid 文件中。其中“数据缓存目录”为配置文件 zoo.cfg 中的配置参数 </p><p>在 data 目录中创建文件 myid ： touch myid </p><p>为应用提供唯一标识。本环境中使用 1、2、3 作为每个节点的唯一标识。 </p><p>vi myid </p><p>简化方式为： echo [唯一标识] &gt;&gt; myid。 echo 命令为回声命令，系统会将命令发送的 数据返回。 ‘&gt;&gt;’为定位，代表系统回声数据指定发送到什么位置。 此命令代表系统回声数 据发送到 myid 文件中。 如果没有文件创建文件</p><h5 id="8-6修改配置文件"><a href="#8-6修改配置文件" class="headerlink" title="8.6修改配置文件"></a>8.6修改配置文件</h5><p>vim zoo.cfg</p><p>就是根据应用做对应的端口修改</p><p>都设置好之后，查看状态，02leader，其他都是follower</p><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220122204938380.png" alt="image-20220122204938380"></p><h5 id="8-7编写一个启动，关闭集群脚本"><a href="#8-7编写一个启动，关闭集群脚本" class="headerlink" title="8.7编写一个启动，关闭集群脚本"></a>8.7编写一个启动，关闭集群脚本</h5><p>chmod 777 文件名  </p><p>分配可读可写可执行权限</p><p>启动</p><pre class=" language-none"><code class="language-none">zookeeper01/bin/zkServer.sh startzookeeper02/bin/zkServer.sh startzookeeper03/bin/zkServer.sh start</code></pre><p>关闭</p><pre class=" language-none"><code class="language-none">zookeeper01/bin/zkServer.sh stopzookeeper02/bin/zkServer.sh stopzookeeper03/bin/zkServer.sh stop</code></pre><h5 id="8-8连接集群"><a href="#8-8连接集群" class="headerlink" title="8.8连接集群"></a>8.8连接集群</h5><p>可以使用任何节点中的客户端工具连接集群中的任何节点。 .&#x2F;zkCli.sh -server 192.168.233.130:2183</p><h3 id="五、-Zookeeper-常用命令"><a href="#五、-Zookeeper-常用命令" class="headerlink" title="五、 Zookeeper 常用命令"></a>五、 Zookeeper 常用命令</h3><h4 id="1-ls"><a href="#1-ls" class="headerlink" title="1 ls"></a>1 ls</h4><p>ls &#x2F;path 使用 ls 命令查看 zookeeper 中的内容。在 ZooKeeper 控制台客户端中，没有默认列表功 能，必须指定要列表资源的位置。 如： ls &#x2F; 或者 ls  &#x2F;path</p><h4 id="2-create"><a href="#2-create" class="headerlink" title="2 create"></a>2 create</h4><p>create [-e] [-s] &#x2F;path [data]</p><p>使用 create 命令创建一个新的 Znode。</p><p>如： create &#x2F;test 123 创建一个&#x2F;test 节点，节点携带数据信息 123。 create -e &#x2F;test 123 创建一个临时节 点&#x2F;test，携带数据为 123，临时节点只在当前会话生命周期中有效，会话结束节点自动删除。</p><p>create -s &#x2F;test 123 创建一个顺序节点&#x2F;test，携带数据 123，创建的顺序节点由 ZooKeeper 自 动为节点增加后缀信息，如-&#x2F;test00000001 等。-e 和-s 参数可以联合使用</p><h4 id="3-get"><a href="#3-get" class="headerlink" title="3 get"></a>3 get</h4><p>get [-s] &#x2F;path</p><p>get 命令获取 Znode 中的数据。</p><p><strong>-s 查看 Znode 详细信息</strong></p><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329133741788.png" alt="image-20220329133741788"></p><p>oldlu:存放的数据 </p><p>cZxid:创建时 zxid(znode 每次改变时递增的事务 id) </p><p>ctime:创建时间戳 </p><p>mZxid:最近一次更近的 zxid </p><p>mtime:最近一次更新的时间戳 </p><p>pZxid:子节点的 zxid </p><p>cversion:子节点更新次数 </p><p>dataversion:节点数据更新次数 </p><p>aclVersion:节点 ACL(授权信息)的更新次数 </p><p>ephemeralOwner:如果该节点为 ephemeral 节点(临时，生命周期与 session 一样), ephemeralOwner 值表示与该节点绑定的 session id. 如果该节点不是 ephemeral 节点, ephemeralOwner 值为 0.</p><p>dataLength:节点数据字节数 </p><p>numChildren:子节点数量</p><h4 id="4-set"><a href="#4-set" class="headerlink" title="4 set"></a>4 set</h4><p>set &#x2F;path [data] </p><p>添加或修改 Znode 中的值</p><h4 id="5-delete"><a href="#5-delete" class="headerlink" title="5 delete"></a>5 delete</h4><p>delete &#x2F;path </p><p>删除 Znode。</p><h3 id="六、-使用-Java-API-操作-Zooke"><a href="#六、-使用-Java-API-操作-Zooke" class="headerlink" title="六、 使用 Java API 操作 Zooke"></a>六、 使用 Java API 操作 Zooke</h3><p>创建项目，添加zookeeper依赖</p><h4 id="1-创建Znode并添加数据"><a href="#1-创建Znode并添加数据" class="headerlink" title="1.创建Znode并添加数据"></a>1.创建Znode并添加数据</h4><pre class=" language-Java"><code class="language-Java">/** * 操作Zookeeper的Znode */public class ZnodeDemo implements Watcher &#123;    public static void main(String[] args) throws InterruptedException, KeeperException, IOException &#123;        //创建连接Zookeeper对象,这里用的三个参数构造方法        //第一个，连接的结点和端口，多个之间逗号隔开，        // sessionTimeOut：连接超时时间，   Watcher：事件通知处理器（回调）        ZooKeeper zooKeeper = new ZooKeeper(                "192.168.8.103:2181," +                "192.168.8.103:2182," +                "192.168.8.103:2183",15000,new ZnodeDemo() );       String path = zooKeeper.create("/bjsxt/test", "jianjian".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);//相当于create命令，四个参,路径，存放的值（字节数组），操作的权限，CreateMode（四种类型之一）//OpenACL,开放所有权限，create：创建权限，read：读取，还有一个anyoneID：对当前客户端开放所有权限        System.out.println(path);    /**     * 事件通知回调方法     * @param event     */    @Override    public void process(WatchedEvent event) &#123;        //获取连接事件  返回值相等表示连接成功        if (event.getState() == Event.KeeperState.SaslAuthenticated)&#123;//.SyncConnected？？            System.out.println("连接成功！");        &#125;    &#125;&#125;</code></pre><h4 id="2-获取Znode中的数据"><a href="#2-获取Znode中的数据" class="headerlink" title="2. 获取Znode中的数据"></a>2. 获取Znode中的数据</h4><h5 id="2-1获取指定节点中的数据"><a href="#2-1获取指定节点中的数据" class="headerlink" title="2.1获取指定节点中的数据"></a>2.1获取指定节点中的数据</h5><pre class=" language-java"><code class="language-java">  <span class="token comment" spellcheck="true">//获取指定结点的数据   路径  处理器  统计对象</span>        <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> data <span class="token operator">=</span> zooKeeper<span class="token punctuation">.</span><span class="token function">getData</span><span class="token punctuation">(</span><span class="token string">"/bjsxt/test0000000000"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">ZnodeDemo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Stat</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token comment" spellcheck="true">//output:jianjian</span></code></pre><h5 id="2-2获取所有子节点中的数据"><a href="#2-2获取所有子节点中的数据" class="headerlink" title="2.2获取所有子节点中的数据"></a>2.2获取所有子节点中的数据</h5><pre class=" language-Java"><code class="language-Java">//获取指定节点中的所有子节点中的数据        List<String> list = zooKeeper.getChildren("/bjsxt", new ZnodeDemo());//子节点路径，Watcher        //list存放的是返回的所有子节点的路径        for (String path:list             ) &#123;            byte[] data = zooKeeper.getData("/bjsxt/" + path, new ZnodeDemo(), new Stat());            System.out.println(new String(data));        &#125;        //output:jianjian</code></pre><h4 id="3-设置-Znode-中的值"><a href="#3-设置-Znode-中的值" class="headerlink" title="3 设置 Znode 中的值"></a>3 设置 Znode 中的值</h4><pre class=" language-java"><code class="language-java">        <span class="token comment" spellcheck="true">//设置Znode中的值   三个参   路径  设置的值  version：详细信息中的子节点更新次数</span>        <span class="token comment" spellcheck="true">//就是给定的版本号和当前的version不匹配，就不会修改   -1：任何版本都可以(匹配任何版本)</span>        Stat stat <span class="token operator">=</span> zooKeeper<span class="token punctuation">.</span><span class="token function">setData</span><span class="token punctuation">(</span><span class="token string">"/bjsxt/test0000000000"</span><span class="token punctuation">,</span> <span class="token string">"juejue"</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>stat<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h4 id="4-删除Znode"><a href="#4-删除Znode" class="headerlink" title="4.删除Znode"></a>4.删除Znode</h4><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">//删除   路径，版本</span>        zooKeeper<span class="token punctuation">.</span><span class="token function">delete</span><span class="token punctuation">(</span><span class="token string">"/bjsxt/test0000000000"</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h3 id="七、-Zookeeper-实战"><a href="#七、-Zookeeper-实战" class="headerlink" title="七、 Zookeeper 实战"></a>七、 Zookeeper 实战</h3><p>实战案例介绍：使用 Zookeeper 与 RMI 技术实现一个 RPC 框架。</p><p>RPC：（Remote Procedure Call）远程过程调用</p><h4 id="1-基于-RMI-实现远程方法调用"><a href="#1-基于-RMI-实现远程方法调用" class="headerlink" title="1 基于 RMI 实现远程方法调用"></a>1 基于 RMI 实现远程方法调用</h4><h5 id="1-1RMI-简-介"><a href="#1-1RMI-简-介" class="headerlink" title="1.1RMI 简 介"></a>1.1RMI 简 介</h5><p>RMI(Remote Method Invocation) 远程方法调用。 RMI 是从 JDK1.2 推出的功能，它可以实现在一个 Java 应用中可以像调用本地方法一样 调用另一个服务器中 Java 应用（JVM）中的内容。 RMI 是 Java 语言的远程调用，无法实现跨语言</p><h5 id="1-2执行流程"><a href="#1-2执行流程" class="headerlink" title="1.2执行流程"></a>1.2执行流程</h5><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329140808122.png" alt="image-20220329140808122"></p><p>Registry(注册表)是放置所有服务器对象的命名空间。 每次服务端创建一个对象时，它都会使用 bind()或 rebind()方法注册该对象。 这些是使用称为绑定名称的唯一名称注册的。 </p><p>要调用远程对象，客户端需要该对象的引用。即通过服务端绑定的名称从注册表中获取 对象(lookup()方法)。</p><h5 id="1-3RMI-的-API-介绍"><a href="#1-3RMI-的-API-介绍" class="headerlink" title="1.3RMI 的 API 介绍"></a>1.3RMI 的 API 介绍</h5><h6 id="1-3-1-Remote-接口"><a href="#1-3-1-Remote-接口" class="headerlink" title="1.3.1 Remote 接口"></a>1.3.1 Remote 接口</h6><p>java.rmi.Remote 定义了此接口为远程调用接口。如果接口被外部调用，需要继承此接口。</p><h6 id="1-3-2-RemoteException-类"><a href="#1-3-2-RemoteException-类" class="headerlink" title="1.3.2 RemoteException 类"></a>1.3.2 RemoteException 类</h6><p>java.rmi.RemoteException </p><p>继承了 Remote 接口的接口，如果方法是允许被远程调用的，需要抛出此异常。</p><h6 id="1-3-3-UnicastRemoteObject-类"><a href="#1-3-3-UnicastRemoteObject-类" class="headerlink" title="1.3.3 UnicastRemoteObject 类"></a>1.3.3 UnicastRemoteObject 类</h6><p>java.rmi.server.UnicastRemoteObject </p><p>此类实现了 Remote 接口和 Serializable 接口</p><p><strong>自定义接口实现类除了实现自定义接口还需要继承此类。</strong></p><h6 id="1-3-4-LocateRegistry-类"><a href="#1-3-4-LocateRegistry-类" class="headerlink" title="1.3.4 LocateRegistry 类"></a>1.3.4 LocateRegistry 类</h6><p>java.rmi.registry.LocateRegistry </p><p>可以通过 LocateRegistry 在本机上创建 Registry，通过特定的端口就可以访问这个 Registry。</p><h6 id="1-3-5-Naming-类"><a href="#1-3-5-Naming-类" class="headerlink" title="1.3.5 Naming 类"></a>1.3.5 Naming 类</h6><p>java.rmi.Naming </p><p>Naming 定义了发布内容可访问 RMI 名称。也是通过 Naming 获取到指定的远程方法</p><h5 id="1-4创建-Server"><a href="#1-4创建-Server" class="headerlink" title="1.4创建 Server"></a>1.4创建 Server</h5><h6 id="1-4-1创建项目"><a href="#1-4-1创建项目" class="headerlink" title="1.4.1创建项目"></a>1.4.1创建项目</h6><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329150012005.png" alt="image-20220329150012005"></p><h6 id="1-4-2创建接口"><a href="#1-4-2创建接口" class="headerlink" title="1.4.2创建接口"></a>1.4.2创建接口</h6><pre class=" language-Java"><code class="language-Java">/** *  定义允许远程调用接口，该接口必须要继承Remote接口 *  允许被远程调用的方法必须要抛出RemoteException */public interface DemoService extends Remote &#123;    String demo(String str) throws RemoteException;&#125;</code></pre><h6 id="1-4-3创建接口实现类"><a href="#1-4-3创建接口实现类" class="headerlink" title="1.4.3创建接口实现类"></a>1.4.3创建接口实现类</h6><pre class=" language-Java"><code class="language-Java">/** * 接口实现类必须要继承UnicastRemoteObject * 会自动添加构造方法，需要修改为public */public class DemoServiceImpl extends UnicastRemoteObject implements DemoService &#123;    public DemoServiceImpl() throws RemoteException &#123;    &#125;    @Override    public String demo(String str) throws RemoteException &#123;        return "Hello RMI"+str;    &#125;&#125;</code></pre><h6 id="1-4-4-编写主方法"><a href="#1-4-4-编写主方法" class="headerlink" title="1.4.4 编写主方法"></a>1.4.4 编写主方法</h6><pre class=" language-Java"><code class="language-Java">public class DemoServer &#123;    public static void main(String[] args) throws RemoteException, MalformedURLException, AlreadyBoundException &#123;        //将对象实例化        DemoService demoService = new DemoServiceImpl();        //创建本地注册表--给定别人访问注册表的端口        LocateRegistry.createRegistry(8888);        //将对象绑定到注册表当中   第一个参：查找对象使用rmi协议,最后必须要给绑定对象的唯一标识（注册表中不能有重复）        //第二个是绑定的对象    如果是别的机器，换localhost就可以了        Naming.bind("rmi://localhost:8888/demoService",demoService);    &#125;&#125;</code></pre><h5 id="1-5创建Client端"><a href="#1-5创建Client端" class="headerlink" title="1.5创建Client端"></a>1.5创建Client端</h5><h6 id="1-5-1创建项目"><a href="#1-5-1创建项目" class="headerlink" title="1.5.1创建项目"></a>1.5.1创建项目</h6><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329150249119.png" alt="image-20220329150249119"></p><h6 id="1-5-2复制服务端接口"><a href="#1-5-2复制服务端接口" class="headerlink" title="1.5.2复制服务端接口"></a>1.5.2复制服务端接口</h6><h6 id="1-5-3-创建主方法"><a href="#1-5-3-创建主方法" class="headerlink" title="1.5.3 创建主方法"></a>1.5.3 创建主方法</h6><pre class=" language-Java"><code class="language-Java">public class ClientDemo &#123;    public static void main(String[] args) throws MalformedURLException, NotBoundException, RemoteException &#123;        //把server中绑定的uri给过来，这样就能去注册表里找这个对象        DemoService demoService = (DemoService) Naming.lookup("rmi://localhost:8888/demoService");        String result = demoService.demo("JianJian");        System.out.println(result);    &#125;&#125;</code></pre><p>这就完事了</p><h4 id="2-使用-Zookeeper-作为注册中心"><a href="#2-使用-Zookeeper-作为注册中心" class="headerlink" title="2. 使用 Zookeeper 作为注册中心"></a>2. 使用 Zookeeper 作为注册中心</h4><h5 id="2-1-创建服务端"><a href="#2-1-创建服务端" class="headerlink" title="2.1 创建服务端"></a>2.1 创建服务端</h5><p>创建项目</p><h6 id="2-1-1-修改POM文件依赖"><a href="#2-1-1-修改POM文件依赖" class="headerlink" title="2.1.1 修改POM文件依赖"></a>2.1.1 修改POM文件依赖</h6><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.zookeeper<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>zookeeper<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.6.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></code></pre><h6 id="2-1-2创建接口"><a href="#2-1-2创建接口" class="headerlink" title="2.1.2创建接口"></a>2.1.2创建接口</h6><pre class=" language-Java"><code class="language-Java">public interface UsersService extends Remote &#123;    String findUsers(String str) throws RemoteException;&#125;</code></pre><h6 id="2-1-3-创建接口实现类"><a href="#2-1-3-创建接口实现类" class="headerlink" title="2.1. 3 创建接口实现类"></a>2.1. 3 创建接口实现类</h6><pre class=" language-Java"><code class="language-Java">public class UsersServiceImpl extends UnicastRemoteObject implements UsersService &#123;    public UsersServiceImpl() throws RemoteException &#123;    &#125;    @Override    public String findUsers(String str) throws RemoteException &#123;        return "Hello Zookeeper"+str;    &#125;&#125;</code></pre><h6 id="2-1-4-编写主方法"><a href="#2-1-4-编写主方法" class="headerlink" title="2.1.4  编写主方法"></a>2.1.4  编写主方法</h6><pre class=" language-Java"><code class="language-Java">public class ServerDemo implements Watcher &#123;    public static void main(String[] args) throws IOException, AlreadyBoundException, InterruptedException, KeeperException &#123;        UsersService usersService = new UsersServiceImpl();        LocateRegistry.createRegistry(8888);        String str = "rmi://localhost:8888/user";        Naming.bind(str,usersService);        //将url信息放到zookeeper节点        ZooKeeper zooKeeper = new ZooKeeper(                "192.168.8.103:2181," +                        "192.168.8.103:2182," +                        "192.168.8.103:2183",15000,new ServerDemo() );        //创建Znode        zooKeeper.create("/bjsxt/service",str.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);        System.out.println("服务发布成功");    &#125;    @Override    public void process(WatchedEvent event) &#123;        //获取连接事件  返回值相等表示连接成功        if (event.getState() == Event.KeeperState.SyncConnected)&#123;            System.out.println("连接成功！");        &#125;    &#125;&#125;</code></pre><h5 id="2-2-创建客户端"><a href="#2-2-创建客户端" class="headerlink" title="2.2 创建客户端"></a>2.2 创建客户端</h5><p>依赖</p><h6 id="2-2-1-创建接口"><a href="#2-2-1-创建接口" class="headerlink" title="2.2.1 创建接口"></a>2.2.1 创建接口</h6><pre class=" language-Java"><code class="language-Java">public interface UsersService&#123;    String findUsers(String str);&#125;</code></pre><h6 id="2-2-2-编写主方法"><a href="#2-2-2-编写主方法" class="headerlink" title="2.2.2 编写主方法"></a>2.2.2 编写主方法</h6><pre class=" language-Java"><code class="language-Java">public class ClientDemo implements Watcher &#123;    public static void main(String[] args) throws IOException, InterruptedException, KeeperException, NotBoundException &#123;        ZooKeeper zooKeeper = new ZooKeeper(                "192.168.8.103:2181," +                        "192.168.8.103:2182," +                        "192.168.8.103:2183",15000,new ClientDemo() );        byte[] data = zooKeeper.getData("/bjsxt/service", new ClientDemo(),null);        String url = new String(data);        //通过lookup      UsersService usersService = (UsersService) Naming.lookup(url);      String result = usersService.findUsers("JianJian");      System.out.println(result);    &#125;    @Override    public void process(WatchedEvent event) &#123;        if (event.getState() == Event.KeeperState.SyncConnected)&#123;            System.out.println("连接成功！");        &#125;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Maven不能导入依赖</title>
      <link href="/2022/03/28/maven-bu-neng-dao-ru-yi-lai/"/>
      <url>/2022/03/28/maven-bu-neng-dao-ru-yi-lai/</url>
      
        <content type="html"><![CDATA[<hr><hr><hr><h4 id="做Dubbo的Demo"><a href="#做Dubbo的Demo" class="headerlink" title="做Dubbo的Demo"></a>做Dubbo的Demo</h4><p>maven在一个项目里面，任何依赖都导不出来，重新导入和刷新以及网上的方法都已经试了超多，也找了一些学友求助。</p><p>但是把这些依赖放在另一个没有问题的项目中，就可以正常的导出依赖。</p><p>接着仔细一看dependencyManagement，这个标签把dependencies标签包住了，直接删除掉。简单来说就是，先删除dependencyManagement标签等自动引入完依赖之后再原封不动还回去</p><p>然后后面创建consumer之后，就差运行tomcat了，发现插件没有tomcat，再仔细一看，又有一个插件管理，删掉之后等自动引入完成就可以看到tomcat的插件了。</p><p>重点！！！子项目就别搞依赖管理和插件管理，那是父项目使用的，插件管理就是不会自动引入，所以就会没有用    </p><h4 id="一、作用"><a href="#一、作用" class="headerlink" title="一、作用"></a>一、作用</h4><p>使用dependencyManagement可以统一管理项目中依赖包的版本号，当需要变更版本号时只需在父pom中修改即可；如果某个子项目需要指定一个特殊的版本号时，只需要在自己项目的pom.xml中显示声明一个版本号即可，此时子项目会使用自己声明的版本号，而不继承父项目的版本号</p><h4 id="二、dependencyManagement与dependencies的区别"><a href="#二、dependencyManagement与dependencies的区别" class="headerlink" title="二、dependencyManagement与dependencies的区别"></a>二、dependencyManagement与dependencies的区别</h4><ul><li><p>dependencies相对于dependencyManagement，所有声明在dependencies里的依赖都会<strong>自动引入</strong>，并默认被所有的子项目继承</p></li><li><p>dependencyManagement里只是声明依赖，<strong>并不会自动引入</strong>，因此子项目需要显示声明依赖。在子项目中声明了依赖项，且没有指定具体版本，才会从父项目中继承该项，并且version和scope都读取自父pom；另外如果子项目中指定了版本号，则会使用子项目中指定的版本</p></li><li><p>⚠️注意：一个无子工程的独立工程中如果使用dependencyManagement，那么它自己的pom.xml文件引入的依赖也可以不指定版本</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Maven </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Vue3-axios报错解决</title>
      <link href="/2022/03/28/vue3-axios-bao-cuo-jie-jue/"/>
      <url>/2022/03/28/vue3-axios-bao-cuo-jie-jue/</url>
      
        <content type="html"><![CDATA[<hr><p>在做springboot整合vue的前后端分离项目时遇到此问题。</p><p>搜了一下，别人是这样说的：根本原因是 引入的axios库是使用vue2.0开发的一套组件库，而我们当前的项目为vue3，所有存在兼容性的问题。</p><p>网上的解决方案也都试了一遍，问了前端的小伙伴他也不知道，但是它建议我用vue2再来，我不服，没人踩这坑，我拼了半条命也要给他填了。</p><p>首先，如果你是简单的项目，<a href="https://so.csdn.net/so/search?q=axios&spm=1001.2101.3001.7020">axios</a>调用也只有一个弹窗测试，那么你可以这样做。</p><p><img src="/2022/03/28/vue3-axios-bao-cuo-jie-jue/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeuWwvA==,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="img"></p><p>注释掉就可以了，你就会发现可以用。</p><p>但是当你真想调用访问后端接口时，比如调用get</p><pre class=" language-vue"><code class="language-vue">   created() &#123;    // alert(123)    axios.get("http://localhost:xxxx/xxxx").then(function (resp)&#123;      console.log(resp)    &#125;)  &#125;</code></pre><p>你就会发现马上就报错了。不卖关子了，整体怎么解决呢。</p><h4 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h4><p>1.注释掉axios中的倒数第二行代码（如果你刚刚做了可以直接下一步）</p><p>2.去main.js中添加以下代码</p><pre class=" language-vue"><code class="language-vue">import axios from 'axios'import VueAxios from 'vue-axios'createApp(App).use(VueAxios,axios)</code></pre><p> 3.这个时候，确实不报刚刚的ues问题了，但是会报vue-axios没安装</p><p>4.没安装就去安装呗，但是你会发现，安装不上。（安装上的就已经解决完了）。</p><p>5.没安装上你仔细一看，报错是这样的</p><p><img src="/2022/03/28/vue3-axios-bao-cuo-jie-jue/image-20220328210140344.png" alt="image-20220328210140344"> 很简单，我就理解为是vue3和axios冲突完了，别的又发生冲突了，报错提示的非常明显了，那我们继续下一步，直接去package.json里改版本</p><p><img src="/2022/03/28/vue3-axios-bao-cuo-jie-jue/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeuWwvA==,size_20,color_FFFFFF,t_70,g_se,x_16-16484725345782.png" alt="img"></p><p>既然你说axios版本不太行，行，直接上最新的0.26.1。</p><p>然后就是控制台npm install一下，然后运行项目，到此这些问题就解决完了。</p><p>注：要是你运行还错，而且有关axios什么not found，请去你的vue文件里导入axios，</p><p>import axios from “axios”;<br>如果解决了，剩下的就是跨域问题了</p><p>跨域问题请看我的另一博客：<a href="https://blog.csdn.net/weixin_53156322/article/details/123416375">https://blog.csdn.net/weixin_53156322/article/details/123416375</a></p><p>感谢观看。</p>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Active持久化到本地DB</title>
      <link href="/2022/03/28/active-chi-jiu-hua-dao-ben-di-db/"/>
      <url>/2022/03/28/active-chi-jiu-hua-dao-ben-di-db/</url>
      
        <content type="html"><![CDATA[<hr><p>ActiveMQ持久化到本地数据库报错，改好配置文件启动后，访问不到ActiveMQ的管理界面，就去<strong>查看日志文件</strong>。</p><pre><code>message from server: “Host ‘XXXXXX-XXXXXXXX‘ is not allowed to connect to this MySQL server“</code></pre><p>​    这个异常是数据库只允许<strong>localhost或127.0.0.1</strong>访问，也就是你虚拟机自己访问，不允许远程访问。由于本地项目无法设置SSH通道，所以需要修改数据库的访问权限。</p><p>首先我是直接想去改数据库的访问权限的，但是navicat又不能直接修改数据库访问权限，只能对表进行修改，但是我们就是<strong>没有表</strong>呀！！！</p><p><strong>这个表就是得让ActiveMQ来创建的</strong></p><p>然后是想着创建一个新用户，再去配置文件里把root用户改为这个用户。结果失败了</p><h4 id="正解："><a href="#正解：" class="headerlink" title="正解："></a>正解：</h4><p>cmd</p><p>mysql -u root -p 回车，输密码</p><p><img src="/2022/03/28/active-chi-jiu-hua-dao-ben-di-db/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57ud57ud44GX,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="img"></p><p>然后这就完事了，管理界面可以访问，也会帮你创建表</p><p><img src="/2022/03/28/active-chi-jiu-hua-dao-ben-di-db/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57ud57ud44GX,size_16,color_FFFFFF,t_70,g_se,x_16.png" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> DB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Chrome恢复标签页</title>
      <link href="/2022/03/28/chrome-hui-fu-biao-qian-ye/"/>
      <url>/2022/03/28/chrome-hui-fu-biao-qian-ye/</url>
      
        <content type="html"><![CDATA[<h2 id="一不小心关闭了Chrome的标签页"><a href="#一不小心关闭了Chrome的标签页" class="headerlink" title="一不小心关闭了Chrome的标签页"></a>一不小心关闭了Chrome的标签页</h2><p>​          学习过程中总会有很多意外情况，比如另外一个屏幕新建了一个浏览器标签页，学习完了关电脑了，但是先关闭的是很多标签页的窗口，当然了，这些标签页再历史记录里都会有。</p><p><img src="/2022/03/28/chrome-hui-fu-biao-qian-ye/1562799979449.jpeg"></p><p>​          也算是有被自己的下饭操作秀到，第二天一打开浏览器发现上面一排标签页都没了，我确实慌了。</p><p>​                                                                                          <img src="/2022/03/28/chrome-hui-fu-biao-qian-ye/1564050376268.jpeg">                          </p><p>​        但是往往我们都是10~20+的标签页面，有各种各样的错误或者学习资源站点等等。还不是每一个都加入了收藏夹</p><p>无需记住被关闭的标签页的标题，一键恢复前一个被关闭的标签页，快捷键： <code> Ctrl + Shirt + T</code></p><p>​                                                                                      <img src="/2022/03/28/chrome-hui-fu-biao-qian-ye/1562799879092.jpeg"> </p>]]></content>
      
      
      <categories>
          
          <category> Other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小失误 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java</title>
      <link href="/2022/03/28/wo-de-di-yi-ge-bo-ke/"/>
      <url>/2022/03/28/wo-de-di-yi-ge-bo-ke/</url>
      
        <content type="html"><![CDATA[<h5 id><a href="#" class="headerlink" title></a></h5><p>最全的实例</p><pre class=" language-markdown"><code class="language-markdown">title: typora-vue-theme主题介绍date: 2018-09-07 09:25:00author: 赵奇img: /source/images/xxx.jpgtop: truecover: true    这个玩意是轮播图coverImg: /images/1.jpgpassword: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92toc: falsemathjax: falsesummary: 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要categories: Markdowntags:  这里就是标签  <span class="token list punctuation">-</span> Typora  <span class="token list punctuation">-</span> Markdown</code></pre><hr><h3 id="内容一"><a href="#内容一" class="headerlink" title="内容一"></a>内容一</h3><hr><h3 id="内容二"><a href="#内容二" class="headerlink" title="内容二"></a>内容二</h3><table><thead><tr><th>外币巴伯？？</th><th>乌西滴西</th></tr></thead></table><p>写好之后清理，生成，推送一下就好了</p><p>但是这样的话，一行代码太长不会自动换行</p><pre class=" language-markdown"><code class="language-markdown">太长的一条跳TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT阿萨大阿萨大 撒达哈哈哈哈和和和和和呵呵和啊倒萨大苏打看哈就肯定不止吧但是这样的话，一行代码太长就不会自动换行，而且下面的进度跳也是没有用的</code></pre><p>安静的拉萨空间</p><p>噢噢噢噢噢噢噢噢噢噢噢噢噢噢噢噢哦哦哦</p><p>什么叫做代码高亮，md文件里怎么写才能让显示后代码高亮呢 <code>hexo new page &#39;My-second-blog&#39;</code></p><p><code>asdasad as gao liang??</code>   好像就是两个英文的1旁边的<code> 这个东西</code>括起来的内容就是高亮</p><p>加粗：<strong>阿大撒了解的空间里</strong></p><p>斜体：<em>撒角度来看啊空间达拉斯空间</em></p><p>下划线：<u>爱睡觉的拉开点距离看</u></p><p>删除线：<del>删除删除删除删除DELETE</del></p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
