<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Git推送到Github时出现OpenSSL SSL_read: Connection was reset, errno 10054错误解决方法</title>
      <link href="/2022/05/10/git-tui-song-dao-github-shi-chu-xian-openssl-ssl-read-connection-was-reset-errno-10054-cuo-wu-jie-jue-fang-fa/"/>
      <url>/2022/05/10/git-tui-song-dao-github-shi-chu-xian-openssl-ssl-read-connection-was-reset-errno-10054-cuo-wu-jie-jue-fang-fa/</url>
      
        <content type="html"><![CDATA[<p>突然想把学习写的项目代码放到Github上,也是好久没推送代码了，报了个fatal: unable to access ‘<a href="https://github.com/ZG-jian/Demo.git/&#39;">https://github.com/ZG-jian/Demo.git/&#39;</a>: OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 10054</p><p><strong>找了一下解决方案：</strong></p><p>然后我是觉得我推的东西很多，就用的方法4，然后报错 Support for password authentication was removed on August 13, 2021. Please use a personal access token instead，解决完就成功推送了</p><p>方法1:自己配置的用户名邮箱可能输入错误了：</p><p>查看用户名，邮箱</p><pre class=" language-none"><code class="language-none">git config user.namegit config user.email</code></pre><p>修改用户名，邮箱：</p><pre class=" language-none"><code class="language-none">git config --global user.name "xxx"git config --global user.email"xxx"</code></pre><p>移除仓库，重新添加：</p><pre class=" language-none"><code class="language-none">git remote rm origingit remote add origin https://github.com/XXX</code></pre><p>方法2：移除本地代理：</p><pre class=" language-none"><code class="language-none">git config --global --unset-all remote.origin.proxy</code></pre><p> 方法3：修改解除<a href="https://so.csdn.net/so/search?q=SSL&spm=1001.2101.3001.7020">SSL</a>认证</p><pre class=" language-none"><code class="language-none">git config --global http.sslVerify "false"</code></pre><p>方法4：文件太大，修改缓冲区大小（缓冲区大小修改为500M）</p><pre class=" language-none"><code class="language-none">git config http.postBuffer 5242880003</code></pre><p>方法5：更新DNS缓存</p><pre class=" language-none"><code class="language-none">ipconfig /flushdns</code></pre>]]></content>
      
      
      <categories>
          
          <category> Other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git推送报错Support for password authentication was removed</title>
      <link href="/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/"/>
      <url>/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/</url>
      
        <content type="html"><![CDATA[<p>​        好久没有往<a href="https://so.csdn.net/so/search?q=Github&spm=1001.2101.3001.7020">Github</a>提交代码了，今天偶然提交代码的时候给报了一个 Support for password authentication was removed on August 13, 2021. Please use a personal access token instead.的错误</p><p>​        大概意思就是，你原先的密码凭证从2021年8月13日开始就不能用了，必须使用个人访问令牌（personal access token），就是把你的密码替换成token！</p><h2 id="为什么要把密码换成token"><a href="#为什么要把密码换成token" class="headerlink" title="为什么要把密码换成token"></a>为什么要把密码换成token</h2><p>​        <strong>下面是Github官方的解释：</strong> 近年来，GitHub 客户受益于 <a href="https://link.zhihu.com/?target=http://GitHub.com">http://GitHub.com</a> 的许多安全增强功能，例如双因素身份验证、登录警报、经过验证的设备、防止使用泄露密码和 WebAuthn 支持。 这些功能使攻击者更难获取在多个网站上重复使用的密码并使用它来尝试访问您的 GitHub 帐户。 尽管有这些改进，但由于历史原因，未启用双因素身份验证的客户仍能够仅使用其GitHub 用户名和密码继续对 Git 和 API 操作进行身份验证。</p><p>​        从 2021 年 8 月 13 日开始，我们将在对 Git 操作进行身份验证时不再接受帐户密码，并将要求使用基于令牌（token）的身份验证，例如个人访问令牌（针对开发人员）或 OAuth 或 GitHub 应用程序安装令牌（针对集成商） <a href="https://link.zhihu.com/?target=http://GitHub.com">http://GitHub.com</a> 上所有经过身份验证的 Git 操作。 您也可以继续在您喜欢的地方使用 SSH 密钥。如果你要使用ssh密钥可以参考<a href="https://link.csdn.net/?target=https://link.zhihu.com/?target=https%253A//cloud.tencent.com/developer/article/1861466">https://link.csdn.net/?target=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%253A%2F%2Fcloud.tencent.com%2Fdeveloper%2Farticle%2F1861466</a></p><p><strong>修改为token的好处：</strong></p><p>​        令牌（token）与基于密码的身份验证相比，令牌提供了许多安全优势： - 唯一： 令牌特定于 GitHub，可以按使用或按设备生成 - 可撤销：可以随时单独撤销令牌，而无需更新未受影响的凭据 - 有限 ： 令牌可以缩小范围以仅允许用例所需的访问 - 随机：令牌不需要记住或定期输入的更简单密码可能会受到的字典类型或蛮力尝试的影响</p><h2 id="如何生成token"><a href="#如何生成token" class="headerlink" title="如何生成token"></a>如何生成token</h2><p>1，打开Github，在个人设置页面，找到【Setting】，然后打开找到【Devloper Settting】，如下图。</p><p><img src="/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/Users/jianjian/blog/source/_posts/Git%E6%8E%A8%E9%80%81%E6%8A%A5%E9%94%99Support-for-password-authentication-was-removed/image-20220510195245993.png" alt="image-20220510195245993"></p><p>然后，选择个人访问令牌【Personal access tokens】，然后选中生成令牌【Generate new token】。</p><p><img src="/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/Users/jianjian/blog/source/_posts/Git%E6%8E%A8%E9%80%81%E6%8A%A5%E9%94%99Support-for-password-authentication-was-removed/image-20220510195254365.png" alt="image-20220510195254365"></p><p><img src="/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/Users/jianjian/blog/source/_posts/Git%E6%8E%A8%E9%80%81%E6%8A%A5%E9%94%99Support-for-password-authentication-was-removed/image-20220510195258529.png" alt="image-20220510195258529"></p><p><img src="/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/Users/jianjian/blog/source/_posts/Git%E6%8E%A8%E9%80%81%E6%8A%A5%E9%94%99Support-for-password-authentication-was-removed/image-20220510195302153.png" alt="image-20220510195302153"></p><p>在上个步骤中，选择要授予此令牌token的范围或权限。</p><ul><li>要使用token从命令行访问仓库，请选择repo</li><li>要使用token从命令行删除仓库，请选择delete_repo</li><li>其他根据需要进行勾选</li></ul><p>然后，点击【Generate token】生成令牌。</p><p><img src="/2022/05/10/git-tui-song-bao-cuo-support-for-password-authentication-was-removed/Users/jianjian/blog/source/_posts/Git%E6%8E%A8%E9%80%81%E6%8A%A5%E9%94%99Support-for-password-authentication-was-removed/image-20220510195305372.png" alt="image-20220510195305372"></p><p>生成token后，记得把你的token保存下来，以便进行后面的操作。把token直接添加远程仓库链接中，这样就可以避免同一个仓库每次提交代码都要输入token了。</p><pre class=" language-none"><code class="language-none">git remote set-url origin https://<your_token>@github.com/<USERNAME>/<REPO>.git<your_token>：换成你自己得到的token<USERNAME>：是你自己github的用户名<REPO>：是你的仓库名称示例git remote set-url origin https://ghp_JKXAvm5QHR3yaqxxxxxxxx@github.com/ZG-jian/Demo.git</code></pre>]]></content>
      
      
      <categories>
          
          <category> Other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL高版本配置</title>
      <link href="/2022/05/10/mysql-gao-ban-ben-pei-zhi/"/>
      <url>/2022/05/10/mysql-gao-ban-ben-pei-zhi/</url>
      
        <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>springboot+<a href="https://so.csdn.net/so/search?q=Mybatis&spm=1001.2101.3001.7020">Mybatis</a>+Mysql 在配置数据库连接的数据源信息时，不同版本的驱动配置不同，否则连接报错</p><h3 id="配置说明"><a href="#配置说明" class="headerlink" title="配置说明"></a>配置说明</h3><p>高本版的需要把驱动配置成：</p><pre class=" language-none"><code class="language-none">driver-class-name: com.mysql.cj.jdbc.Driver</code></pre><p>据我所知，5.8+的版本的mysql，驱动都应该配置这个驱动。</p><p>5.8以下的版本配置不变：</p><pre><code>driver-class-name: com.mysql.jdbc.Driver</code></pre><p>附上一个完整的连接信息：(mysql 8.0)</p><pre><code>spring:  datasource:    username: root    password: 123456    url: jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=UTC    driver-class-name: com.mysql.cj.jdbc.Driver</code></pre><p>maven依赖：</p><pre><code>&lt;dependency&gt;      &lt;groupId&gt;mysql&lt;/groupId&gt;      &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;      &lt;version&gt;8.0.11&lt;/version&gt;  &lt;/dependency&gt;</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker没运行就拉取报错</title>
      <link href="/2022/05/10/docker-mei-yun-xing-jiu-la-qu-bao-cuo/"/>
      <url>/2022/05/10/docker-mei-yun-xing-jiu-la-qu-bao-cuo/</url>
      
        <content type="html"><![CDATA[<p>今天在重启服务器，然后查看镜像和pull的时候报错</p><p>Cannot connect to the Docker daemon at unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock. Is the docker daemon running?</p><p>翻译过来就是：无法连接到Docker守护进程在unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F; Docker .sock。docker守护进程正在运行吗?</p><p>这个主要的问题就是<a href="https://so.csdn.net/so/search?q=docker&spm=1001.2101.3001.7020">docker</a>没有启动起来导致的…</p><p>然后只要这样</p><pre class=" language-none"><code class="language-none">systemctl start dockersystemctl status docker</code></pre><p> 看到running的标志，就是运行成功了…</p><p>为了避免日后重启再次出现类似情况，增加一个开机自动启动docker…</p><p>systemctl enable docker</p>]]></content>
      
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Navicat连接docker容器中的mysql报错10060：unknow error</title>
      <link href="/2022/05/05/shi-yong-navicat-lian-jie-docker-rong-qi-zhong-de-mysql-bao-cuo-10060-unknow-error/"/>
      <url>/2022/05/05/shi-yong-navicat-lian-jie-docker-rong-qi-zhong-de-mysql-bao-cuo-10060-unknow-error/</url>
      
        <content type="html"><![CDATA[<p>解决方案：</p><p>如果你确定不是防火墙什么的问题，而且你是<strong>挂起的虚拟机然后运行</strong>的话，你可以直接reboot重启虚拟机，然后会发现mysql容器就会停止运行，你再把它跑起来就可以正常运行了。</p><p>出了这个问题，你重启容器也是一样连接不上</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis笔记</title>
      <link href="/2022/04/25/redis-bi-ji/"/>
      <url>/2022/04/25/redis-bi-ji/</url>
      
        <content type="html"><![CDATA[<hr><h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><h3 id="Linux安装"><a href="#Linux安装" class="headerlink" title="Linux安装"></a>Linux安装</h3><p>企业种用的最多的部署方案还是Linux</p><p>先上传至&#x2F;opt下，然后解压至&#x2F;usr&#x2F;local</p><pre class=" language-bash"><code class="language-bash"><span class="token function">tar</span> -zxvf redis-6.2.6.tar.gz -C /usr/local/</code></pre><p>进去redis目录</p><p>安装GCC</p><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> -y gcc</code></pre><p>我们需要把源代码编译成可以执行的文件（redis根目录下）</p><p>编译完成，src就是编译完成后生成的目录</p><p><img src="/2022/04/25/redis-bi-ji/image-20220419200825015.png" alt="image-20220419200825015"></p><p>安装</p><p><img src="/2022/04/25/redis-bi-ji/image-20220419200914603.png" alt="image-20220419200914603"></p><p>进去src里面ls一下</p><p>然后就是文件作用，现在的话记住两个就行，一个是server，一个是cli</p><h4 id="服务启动"><a href="#服务启动" class="headerlink" title="服务启动"></a>服务启动</h4><h5 id="前台启动"><a href="#前台启动" class="headerlink" title="前台启动"></a>前台启动</h5><p>src下执行,端口为6379</p><pre class=" language-bash"><code class="language-bash">./redis-server</code></pre><p><img src="/2022/04/25/redis-bi-ji/image-20220419201207779.png" alt="image-20220419201207779"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220419201130113.png" alt="image-20220419201130113"></p><h5 id="后台启动"><a href="#后台启动" class="headerlink" title="后台启动"></a>后台启动</h5><p>修改redis.conf文件（回根目录）  257行左右  直接&#x2F;daemonize搜索就行</p><pre class=" language-none"><code class="language-none">daemonize yes    #由no改为yes</code></pre><p>然后就可以后台运行了</p><p><img src="/2022/04/25/redis-bi-ji/image-20220419201558533.png" alt="image-20220419201558533"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220419201644659.png" alt="image-20220419201644659"></p><p>然后也可以通过redis-cli连接到服务，这就说明单机版的redis就安装成功了</p><p><img src="/2022/04/25/redis-bi-ji/image-20220419201726223.png" alt="image-20220419201726223"></p><h3 id="Docker安装Redis"><a href="#Docker安装Redis" class="headerlink" title="Docker安装Redis"></a>Docker安装Redis</h3><p>先停一下之前的redis，直接kill -9 停掉</p><p><img src="/2022/04/25/redis-bi-ji/image-20220419201928012.png" alt="image-20220419201928012"></p><p>没安装docker就先y安装docker</p><p>yum -y install docker </p><p>然后启动一下docker</p><p>service docker start</p><p>直接拉一下redis</p><pre class=" language-none"><code class="language-none">docker pull redis</code></pre><p>启动一下容器</p><pre class=" language-none"><code class="language-none">docker run -d --name myredis -p 6379:6379 redis</code></pre><p>然后可以docker ps看一下</p><p>进去看看,然后再连一下，就很简单</p><pre class=" language-bash"><code class="language-bash">docker <span class="token function">exec</span> -it myredis /bin/bash</code></pre><p><img src="/2022/04/25/redis-bi-ji/image-20220419202614073.png" alt="image-20220419202614073"></p><p>然后两次exit退出来</p><h2 id="基本知识"><a href="#基本知识" class="headerlink" title="基本知识"></a>基本知识</h2><p>Redis能读的速度是110000次&#x2F;s，写81000次&#x2F;s</p><h4 id="默认16数据库"><a href="#默认16数据库" class="headerlink" title="默认16数据库"></a>默认16数据库</h4><p>​        Redis是一个字典结构的存储服务器，一个Redis实例提供了多个用来存储数据的字典，客户端可以指定将数据存储在哪个字典中。</p><p>16数据库是可以在配置文件种找到的，配置文件的databases 给的就是16    </p><h5 id="Redis-使用的到底是多线程还是单线程？"><a href="#Redis-使用的到底是多线程还是单线程？" class="headerlink" title="Redis 使用的到底是多线程还是单线程？"></a>Redis 使用的到底是多线程还是单线程？</h5><p>单线程，瓶颈在内存大小或者网络带宽</p><p>​        因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络 带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。</p><h5 id="IO多路复用技术"><a href="#IO多路复用技术" class="headerlink" title="IO多路复用技术"></a>IO多路复用技术</h5><p>难讲，自己找找看吧</p><h5 id="切换数据库"><a href="#切换数据库" class="headerlink" title="切换数据库"></a>切换数据库</h5><p>select </p><p>不指定就会存0库</p><p><img src="/2022/04/25/redis-bi-ji/image-20220419210536436.png" alt="image-20220419210536436"></p><h5 id="清空数据库"><a href="#清空数据库" class="headerlink" title="清空数据库"></a>清空数据库</h5><p>flushdb  —-清除当前库</p><h5 id="删除所有库"><a href="#删除所有库" class="headerlink" title="删除所有库"></a>删除所有库</h5><p>flushall   </p><h3 id="Key键"><a href="#Key键" class="headerlink" title="Key键"></a>Key键</h3><h5 id="keys"><a href="#keys" class="headerlink" title="keys"></a>keys</h5><p>查看所有key</p><pre class=" language-none"><code class="language-none">keys *</code></pre><p>有3个通配符 *, ? ,[] </p><p>*: 通配任意多个字符 </p><p>?: 通配单个字符 </p><p>[]: 通配括号内的某1个字符</p><h6 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h6><p>​    生产已经禁止。因为长时间阻塞redis而导致其他客户端的命令请求一直处于阻塞状态。 更安全的做法是采用scan。</p><pre class=" language-none"><code class="language-none">root@6c068b3fbf29:/data# redis-cli --scan "u*""user1""user</code></pre><h5 id="exists"><a href="#exists" class="headerlink" title="exists"></a>exists</h5><p>判断某个key是否存在，返回1表示存在，0不存在。 </p><p>语法结构：</p><pre class=" language-bash"><code class="language-bash">exists key</code></pre><p>示例：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#查看k1是否存在，如果存在返回1</span>exists k1<span class="token comment" spellcheck="true"># 查看k1 k2 k3是否存在，如果k1 k2存在，k3不存在，则返回2</span>exists k1 k2 k3</code></pre><h5 id="type"><a href="#type" class="headerlink" title="type"></a>type</h5><p>查看当前key 所储存的值的类型。返回当前key所储存的值的类型，如string 、list等。 </p><p>语法结构：</p><p>type key</p><h5 id="del"><a href="#del" class="headerlink" title="del"></a>del</h5><p>删除已存在的key，不存在的 key 会被忽略。</p><p>语法结构：</p><p>del key</p><p>示例： 可以设置多个key，返回删除成功的个数。</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 删除k1，如果成功返回1，失败返回0</span>del k1<span class="token comment" spellcheck="true"># 删除k1 k2 k3，如果k1 k2存在，k3不存在，则返回2</span>del k1 k2 k3</code></pre><h5 id="expire"><a href="#expire" class="headerlink" title="expire"></a>expire</h5><p>给key设置time秒的过期时间。设置成功返回 1 。 当 key 不存在返回 0。</p><pre class=" language-bash"><code class="language-bash">expire key <span class="token function">time</span></code></pre><p>示例：</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 给k1设置10秒后过期</span>expire k1 10</code></pre><h5 id="ttl"><a href="#ttl" class="headerlink" title="ttl"></a>ttl</h5><p>以秒为单位返回 key 的剩余过期时间。</p><p>ttl key</p><p>注意： 当 key 不存在时，返回 -2 。 当 key 存在但没有设置剩余生存时间时，返回 -1 。 否则，以秒为单 位，返回 key 的剩余生存时间。</p><h5 id="persist"><a href="#persist" class="headerlink" title="persist"></a>persist</h5><p>移除给定 key 的过期时间，使得 key 永不过期。</p><p>persist key</p><p>注意： 当过期时间移除成功时，返回 1 。 如果 key 不存在或 key 没有设置过期时间，返回 0 。</p><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><p>最大字符串512M，但是非常不建议大字符串</p><h5 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h5><p>String是Redis最基本的类型，一个key对应一个value。String是二进制安全的，意味着String可以包含 任何数据，比如序列化对象或者一张图片。String最多可以放512M的数据。</p><h4 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="set"><a href="#set" class="headerlink" title="set"></a>set</h5><p>用于设置给定 key 的值。如果 key 已经存储其他值， set 就重写旧值，且无视类型。</p><p>set key value</p><h5 id="get"><a href="#get" class="headerlink" title="get"></a>get</h5><p>用于获取指定 key 的值。如果 key 不存在，返回 nil 。</p><p>get key</p><h5 id="append"><a href="#append" class="headerlink" title="append"></a>append</h5><p>将给定的value追加到key原值末尾。 </p><p>语法格式:</p><pre class=" language-none"><code class="language-none">append key value</code></pre><p>注意： </p><ul><li>如果 key 已经存在并且是一个字符串， append 命令将 value 追加到 key 原来的值的末尾。 </li><li>如果 key 不存在， append 就简单地将给定 key 设为 value ，就像执行 set key value 一 样</li></ul><h5 id="strlen"><a href="#strlen" class="headerlink" title="strlen"></a>strlen</h5><p>获取指定 key 所储存的字符串值的长度。当 key 储存的不是字符串值时，返回一个错误。</p><pre class=" language-none"><code class="language-none">strlen key</code></pre><h5 id="setex"><a href="#setex" class="headerlink" title="setex"></a>setex</h5><p>给指定的 key 设置值及time 秒的过期时间。如果 key 已经存在， setex命令将会替换旧的值，并设置过 期时间。</p><pre class=" language-none"><code class="language-none">setex key time value</code></pre><p>示例：</p><pre class=" language-none"><code class="language-none">#向Redis中设置一个k1的键值对并且10秒后过期127.0.0.1:6379> setex k1 10 v1OK</code></pre><h5 id="setnx"><a href="#setnx" class="headerlink" title="setnx"></a>setnx</h5><pre class=" language-none"><code class="language-none">setnx key value</code></pre><p>只有在key不存在时设置key的值</p><p>key存在就返回0，不存在返回1</p><p>这个功能实现分布式锁用的比较多</p><h5 id="getrange"><a href="#getrange" class="headerlink" title="getrange"></a>getrange</h5><p>获取指定区间范围内的值，类似between……..and 的关系</p><pre class=" language-none"><code class="language-none">getrange key start end</code></pre><h5 id="setrange"><a href="#setrange" class="headerlink" title="setrange"></a>setrange</h5><p>​        从偏移量offset开始，覆写value（对于新的value长度如果小于旧值从offset到结束的长度时，长度小于的部分会保持不变），并返回当前value的长度</p><pre class=" language-bash"><code class="language-bash">setrange key offset value</code></pre><p>从1开始计数</p><h5 id="incr"><a href="#incr" class="headerlink" title="incr"></a>incr</h5><pre class=" language-bash"><code class="language-bash">incr key</code></pre><p>将 key 中储存的数字值增一。</p><p>注意： 如果 key 不存在，那么 key 的值会先被初始化为 0 ，然后再执行 incr 操作。 如字符串类型的值不能表示为数字、或者是其他类型，那么返回一个错误。</p><h5 id="incrby-x2F-decrby-key-step"><a href="#incrby-x2F-decrby-key-step" class="headerlink" title="incrby&#x2F;decrby key step"></a>incrby&#x2F;decrby key step</h5><pre class=" language-none"><code class="language-none"> incrby k1 10</code></pre><p>将key存储的数字值按照step进行增减。</p><h5 id="mset"><a href="#mset" class="headerlink" title="mset"></a>mset</h5><p>同时设置一个或多个 key-value 。</p><pre class=" language-none"><code class="language-none">mset key1 value1 key2 value2</code></pre><h5 id="mget"><a href="#mget" class="headerlink" title="mget"></a>mget</h5><p>返回所有(一个或多个)给定 key 的值。</p><p>mget key1 key2</p><p>注意: 如果给定的 key 里面，有某个 key 不存在，那么这个 key 返回特殊值 nil 。</p><h5 id="getset"><a href="#getset" class="headerlink" title="getset"></a>getset</h5><p>将给定key值设为value，并返回key的旧值（old value），简单一句话（先get然后立即set）。</p><p>getset key value</p><h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><h5 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h5><p>​        List是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右 边）。底层是一个双向链表，对两段操作性能极高，通过索引操作中间的节点性能较差。</p><p>​         一个List最多可以包含 $2^{32}-1$个元素 （ 每个列表超过40亿个元素）。</p><h4 id="常用命令-1"><a href="#常用命令-1" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="lpush-x2F-rpush"><a href="#lpush-x2F-rpush" class="headerlink" title="lpush&#x2F;rpush"></a>lpush&#x2F;rpush</h5><p>从左边（头部）&#x2F;右边（尾部）插入一个或多个值。</p><p>语法结构：</p><pre class=" language-none"><code class="language-none">lpush/rpush key1 value1 value2 value3……</code></pre><p>如：#从左边放入v1 v2 v3</p><p>lpush k1 v1 v2 v3</p><p>#从右边放入v4 v5 v6</p><p>rpush k1 v4 v5 v6</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425093418660.png" alt="image-20220425093418660"></p><h5 id="lrange"><a href="#lrange" class="headerlink" title="lrange"></a>lrange</h5><p>​        返回key列表中的start和end之间的元素（包含start和end）。 其中 0 表示列表的第一个元素，-1表示 最后一个元素。</p><pre class=" language-none"><code class="language-none">lrange key start end</code></pre><p>示例：</p><pre class=" language-none"><code class="language-none">#取出列表里前3个值，结果为v3 v2 v1127.0.0.1:6379> lrange k1 0 2#取出列表里全部值，结果为v3 v2 v1 v4 v5 v6127.0.0.1:6379> lrange k1 0 -1</code></pre><h5 id="lpop-x2F-rpop"><a href="#lpop-x2F-rpop" class="headerlink" title="lpop&#x2F;rpop"></a>lpop&#x2F;rpop</h5><p>移除并返回第一个值或最后一个值。</p><pre class=" language-none"><code class="language-none">lpop/rpop keylpop k1 从列表中删除v3，并返回，当前列表全部值v2 v1 v4 v5 v6rpop k1 从列表中删除v6，并返回，当前列表全部值v2 v1 v4 v5</code></pre><p>注意： 值在键在，值光键亡。</p><h5 id="lindex"><a href="#lindex" class="headerlink" title="lindex"></a>lindex</h5><p>获取列表index位置的值(从左开始  0开始计算)。</p><pre class=" language-none"><code class="language-none">lindex key index</code></pre><h5 id="llen"><a href="#llen" class="headerlink" title="llen"></a>llen</h5><p>获取列表长度。</p><p>llen key</p><h5 id="lrem"><a href="#lrem" class="headerlink" title="lrem"></a>lrem</h5><p>从左边开始删除与value相同的count个元素。</p><pre class=" language-none"><code class="language-none">lrem key count value#从左边开始删除k1列表中2个v1元素lrem k1 2 v1</code></pre><h5 id="linsert"><a href="#linsert" class="headerlink" title="linsert"></a>linsert</h5><p>在列表中value值的前边&#x2F;后边插入一个new value值（从左开始）。</p><pre class=" language-none"><code class="language-none">linsert key before/after value newvalue#示例  在v1前面插入一个v5linsert k1 before v1 v5 </code></pre><h5 id="lset"><a href="#lset" class="headerlink" title="lset"></a>lset</h5><p>将索引为index的值设置为value</p><pre class=" language-none"><code class="language-none">lset key index value</code></pre><h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>消息队列 </li><li>排行榜 </li><li>最新列表</li></ul><h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><p>Redis的Set是String类型的无序集合</p><h5 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h5><p>​        与List类似是一个列表功能，但Set是自动排重的，当需要存储一个列表数据，又不希望出现重复数据 时，Set是一个很好的选择。</p><p>​        Set是String类型的无序集合，它底层其实是一个value为null的hash表，所以添加、删除、查找的时间 复杂度都是O(1)</p><h4 id="常用命令-2"><a href="#常用命令-2" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="sadd"><a href="#sadd" class="headerlink" title="sadd"></a>sadd</h5><p>将一个或多个元素添加到集合key中，已经存在的元素将被忽略。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420161239626.png" alt="image-20220420161239626"></p><h5 id="smembers"><a href="#smembers" class="headerlink" title="smembers"></a>smembers</h5><p>取出该集合的所有元素。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420161344467.png" alt="image-20220420161344467"></p><h5 id="sismember"><a href="#sismember" class="headerlink" title="sismember"></a>sismember</h5><p>判断集合key中是否含有value元素，如有返回1，否则返回0。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420161429941.png" alt="image-20220420161429941"></p><h5 id="scard"><a href="#scard" class="headerlink" title="scard"></a>scard</h5><p>返回该集合的元素个数。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420161503192.png" alt="image-20220420161503192"></p><h5 id="srem"><a href="#srem" class="headerlink" title="srem"></a>srem</h5><p>删除集合中的一个或多个成员元素，不存在的成员元素会被忽略。</p><pre class=" language-none"><code class="language-none">srem key value1 value2……</code></pre><p><img src="/2022/04/25/redis-bi-ji/image-20220420161533211.png" alt="image-20220420161533211"></p><h5 id="spop"><a href="#spop" class="headerlink" title="spop"></a>spop</h5><p>随机删除集合中一个元素并返回该元素。</p><p>spop key</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420161630043.png" alt="image-20220420161630043"></p><h5 id="srandmember"><a href="#srandmember" class="headerlink" title="srandmember"></a>srandmember</h5><p>随机取出集合中count个元素，但不会删除。</p><pre class=" language-none"><code class="language-none">srandmember key count</code></pre><h5 id="smove"><a href="#smove" class="headerlink" title="smove"></a>smove</h5><p>将value元素从sourcekey集合移动到destinationkey集合中。</p><pre class=" language-none"><code class="language-none">smove sourcekey destinationkey value</code></pre><p>注意： 如果 sourcekey集合不存在或不包含指定的 value元素，则 smove 命令不执行任何操作，仅返回 0 。</p><h5 id="sinter"><a href="#sinter" class="headerlink" title="sinter"></a>sinter</h5><p>返回两个集合的交集元素。</p><pre class=" language-none"><code class="language-none">sinter key1 key2</code></pre><h5 id="sunion"><a href="#sunion" class="headerlink" title="sunion"></a>sunion</h5><p>返回两个集合的并集元素。</p><pre class=" language-none"><code class="language-none">sunion key1 key2</code></pre><h5 id="sdiff"><a href="#sdiff" class="headerlink" title="sdiff"></a>sdiff</h5><p>返回两个集合的差集元素（key1中的，不包含key2）</p><pre class=" language-none"><code class="language-none">sdiff key1 key2</code></pre><h4 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>黑白名单 </li><li>随机展示 </li><li>好友 </li><li>关注人 </li><li>粉丝 </li><li>感兴趣的人集合</li></ul><h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><p><img src="/2022/04/25/redis-bi-ji/image-20220425100900244.png" alt="image-20220425100900244"></p><h5 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h5><p>​        Hash是一个键值对的集合。Hash 是一个 String 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。</p><ul><li>Hash存储结构优化 <ul><li>如果field数量较少，存储结构优化为类数组结构 </li><li>如果field数量较多，存储结构使用HashMap结构</li></ul></li></ul><h4 id="常用命令-3"><a href="#常用命令-3" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="hset"><a href="#hset" class="headerlink" title="hset"></a>hset</h5><p>给key集合中的field赋值value。</p><pre class=" language-none"><code class="language-none">127.0.0.1:6379> hset user name JueJue(integer) 1127.0.0.1:6379> hset user age 3(integer) 1</code></pre><p>注意： </p><ul><li>如果哈希表不存在，一个新的哈希表被创建并进行HSET 操作。 </li><li>如果字段已经存在于哈希表中，旧值将被重写。</li></ul><h5 id="hget"><a href="#hget" class="headerlink" title="hget"></a>hget</h5><p>从key哈希中，取出field字段的值。</p><pre class=" language-none"><code class="language-none">hget key field</code></pre><h5 id="hmset"><a href="#hmset" class="headerlink" title="hmset"></a>hmset</h5><p>批量设置哈希的字段及值。</p><pre class=" language-none"><code class="language-none">hmset key field1 value1 field2 value2……</code></pre><h5 id="hexists"><a href="#hexists" class="headerlink" title="hexists"></a>hexists</h5><p>判断指定key中是否存在field  </p><pre class=" language-none"><code class="language-none">hexists key field</code></pre><p>注意： </p><p>如果哈希表含有给定字段，返回 1 。 如果哈希表不含有给定字段，或 key 不存在，返回 0 。</p><h5 id="hkeys"><a href="#hkeys" class="headerlink" title="hkeys"></a>hkeys</h5><p>获取该哈希中所有的field。</p><pre class=" language-none"><code class="language-none">hkeys key</code></pre><h5 id="hvals-key"><a href="#hvals-key" class="headerlink" title="hvals key"></a>hvals key</h5><p>获取该哈希中所有的value。</p><pre class=" language-none"><code class="language-none">hvals key</code></pre><h5 id="hincrby"><a href="#hincrby" class="headerlink" title="hincrby"></a>hincrby</h5><p>为哈希表key中的field字段的值加上增量increment。</p><pre class=" language-none"><code class="language-none">hincrby key field increment</code></pre><p>注意： </p><ul><li>增量也可以为负数，相当于对指定字段进行减法操作。 </li><li>如果哈希表的 key 不存在，一个新的哈希表被创建并执行 hincrby 命令。 </li><li>如果指定的字段不存在，那么在执行命令前，字段的值被初始化为 0 。 </li><li>对一个储存字符串值的字段执行 hincrby 命令将造成一个错误。</li></ul><p>hincrby user1 age 10 对user中的age字段做运算，增加10</p><h5 id="hdel"><a href="#hdel" class="headerlink" title="hdel"></a>hdel</h5><p>删除哈希表 key 中的一个或多个指定字段，不存在的字段将被忽略。</p><pre class=" language-none"><code class="language-none">hdel key field1 field2……</code></pre><h5 id="hsetnx"><a href="#hsetnx" class="headerlink" title="hsetnx"></a>hsetnx</h5><p>给key哈希表中不存在的的字段赋值 。</p><pre class=" language-none"><code class="language-none">hsetnx key field value</code></pre><p>注意： </p><ul><li>如果哈希表不存在，一个新的哈希表被创建并进行 hsetnx 操作。 </li><li>如果字段已经存在于哈希表中，操作无效。 </li><li>如果 key 不存在，一个新哈希表被创建并执行 hsetnx 命令。</li></ul><h4 id="使用场景-2"><a href="#使用场景-2" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>购物车 </li><li>存储对象</li></ul><h3 id="Zset"><a href="#Zset" class="headerlink" title="Zset"></a>Zset</h3><h5 id="简介-4"><a href="#简介-4" class="headerlink" title="简介"></a>简介</h5><p>​        Zset与Set非常相似，是一个没有重复元素的String集合。不同之处是Zset的每个元素都关联了一个分数 （score），这个分数被用来按照从低分到高分的方式排序集合中的元素。集合的元素是唯一的，但分数 可以重复。</p><p>注意： 因为元素是有序的，所以可以根据分数（score）或者次序（position）来获取一个范围内的元素。</p><h4 id="常用命令-4"><a href="#常用命令-4" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="zadd"><a href="#zadd" class="headerlink" title="zadd"></a>zadd</h5><p>将一个或多个元素（value）及分数（score）加入到有序集key中。</p><pre class=" language-none"><code class="language-none">zadd key score1 value1 score2 value2…… </code></pre><h6 id="注意：-1"><a href="#注意：-1" class="headerlink" title="注意："></a>注意：</h6><ul><li>如果某个元素已经是有序集的元素，那么更新这个元素的分数值，并通过重新插入这个元 素，来保证该元素在正确的位置上。 </li><li>分数值可以是整数值或双精度浮点数。 </li><li>如果有序集合 key 不存在，则创建一个空的有序集并执行 zadd 操作。</li></ul><h5 id="zrange"><a href="#zrange" class="headerlink" title="zrange"></a>zrange</h5><p>返回key集合中的索引start和索引end之间的元素（包含start和end）。</p><pre class=" language-none"><code class="language-none">zrange key start end [withscores]# 示例zrange k1 0 -1 返回集合中所有元素zrange k1 0 -1 withscores 返回集合中所有元素，并携带元素分数</code></pre><p>注意： </p><ul><li>其中元素的位置按分数值递增(从小到大)来排序。 其中 0 表示列表的第一个元素，-1表示最 后一个元素。 </li><li>withscores是可选参数，是否返回分数</li></ul><h5 id="zrangebyscore"><a href="#zrangebyscore" class="headerlink" title="zrangebyscore"></a>zrangebyscore</h5><p>​        返回key集合中的分数minscore和分数maxscore 之间的元素（包含minscore 和maxscore ）。其中元素的位置按分数值递增(从小到大)来排序。</p><p>​        withscores是可选参数，是否返回分数</p><pre class=" language-none"><code class="language-none">zrangebyscore key minscore maxscore [withscores]</code></pre><h5 id="zincrby"><a href="#zincrby" class="headerlink" title="zincrby"></a>zincrby</h5><p>为元素value的<strong>score</strong>加上<strong>increment</strong>的值。</p><pre class=" language-none"><code class="language-none">zincrby key increment valuezincrby k1 50 java 给java元素加上50分</code></pre><h5 id="zrem"><a href="#zrem" class="headerlink" title="zrem"></a>zrem</h5><p>删除该集合下value的元素。</p><pre class=" language-none"><code class="language-none">zrem k1 php 删除php</code></pre><h5 id="zcount"><a href="#zcount" class="headerlink" title="zcount"></a>zcount</h5><p>统计该集合在minscore 到maxscore分数区间中元素的个数。</p><pre class=" language-none"><code class="language-none">zcount key minscore maxscore</code></pre><h5 id="zrank"><a href="#zrank" class="headerlink" title="zrank"></a>zrank</h5><p>返回value在集合中的排名，从0开始。</p><pre class=" language-none"><code class="language-none">zrank key value</code></pre><h4 id="使用场景-3"><a href="#使用场景-3" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>延时队列 </li><li>排行榜 </li><li>限流</li></ul><h3 id="Bitmaps"><a href="#Bitmaps" class="headerlink" title="Bitmaps"></a>Bitmaps</h3><p>Bitmaps本身不是一种数据结构，实际上就是字符串，但是它可以对字符串的位进行操作</p><h5 id="简介-5"><a href="#简介-5" class="headerlink" title="简介"></a>简介</h5><p>​        在计算机中，用二进制（位）作为存储信息的基本单位，1个字节等于8位。 例如 “abc” 字符串是由 3 个字节组成，计算机存储时使用其二进制表示，”abc”分别对应的ASCII码是 97、98、99，对应的二进制是01100001、01100010、01100011，在内存中表示如下：</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425111357601.png" alt="image-20220425111357601"></p><p>合理地使用位能够有效地提高内存使用率和开发效率。 </p><p>Redis提供了Bitmaps这个 “数据结构” 可以实现对位的操作：</p><h4 id="常用命令-5"><a href="#常用命令-5" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="setbit"><a href="#setbit" class="headerlink" title="setbit"></a>setbit</h5><p>设置Bitmaps中某个偏移量的值。</p><pre class=" language-none"><code class="language-none">setbit key offset value</code></pre><h5 id="getbit"><a href="#getbit" class="headerlink" title="getbit"></a>getbit</h5><p>获取Bitmaps中某个偏移量的值。</p><pre class=" language-none"><code class="language-none">getbit key offset</code></pre><p> 如果偏移量未设置值，则也返回0。</p><h5 id="bitcount"><a href="#bitcount" class="headerlink" title="bitcount"></a>bitcount</h5><p>​        统计字符串被设置为1的bit数量。一般情况下，给定的整个字符串都会被进行统计，可以选择通过额外 的start和end参数，指定字节组范围内进行统计（包括start和end），0表示第一个元素，-1表示最后一 个元素。</p><pre class=" language-none"><code class="language-none">bitcount key [start end]</code></pre><h5 id="bitop"><a href="#bitop" class="headerlink" title="bitop"></a>bitop</h5><p>将多个bitmaps通过求交集&#x2F;并集方式合并成一个新的bitmaps。</p><pre class=" language-none"><code class="language-none">bitop and/or destkey sourcekey1 sourcekey2……</code></pre><h4 id="使用场景-4"><a href="#使用场景-4" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>活跃天数 </li><li>打卡天数 </li><li>登录天数 </li><li>用户签到 </li><li>统计活跃用户 </li><li>统计用户是否在线 </li><li>实现布隆过滤器</li></ul><h3 id="Geospatia"><a href="#Geospatia" class="headerlink" title="Geospatia"></a>Geospatia</h3><h5 id="简介-6"><a href="#简介-6" class="headerlink" title="简介"></a>简介</h5><p>​        GEO，Geographic,地理信息的缩写。该类型就是元素的二维坐标，在地图上就是经纬度。Redis基于该 类型，提供了经纬度设置、查询、范围查询、距离查询、经纬度Hash等常见操作。</p><h4 id="常用命令-6"><a href="#常用命令-6" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="geoadd"><a href="#geoadd" class="headerlink" title="geoadd"></a>geoadd</h5><p>​        用于存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称 (member)添加到指定的 key 中。</p><pre class=" language-none"><code class="language-none">geoadd key longitude latitude member# 将北京的经纬度和名称添加到chinageoadd china 116.405285 39.904989 beijing# 将成都和上海的经纬度、名称添加到chinageoadd china 104.065735 30.659462 chengdu 121.472644 31.231706 shanghai</code></pre><h5 id="geopos"><a href="#geopos" class="headerlink" title="geopos"></a>geopos</h5><p>从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。</p><pre class=" language-none"><code class="language-none">geopos key member [member ……]##返回china中名称为shanghai和beijing的经纬度geopos chinacity shanghai beijing</code></pre><h5 id="geodist"><a href="#geodist" class="headerlink" title="geodist"></a>geodist</h5><p>用于返回两个给定位置之间的距离。</p><pre class=" language-none"><code class="language-none">geodist key member1 member2 [m|km|ft|mi]</code></pre><p>参数说明： </p><p>m ：米，默认单位。 </p><p>km ：千米。 </p><p>mi ：英里。 </p><p>ft ：英尺。</p><h5 id="georadius"><a href="#georadius" class="headerlink" title="georadius"></a>georadius</h5><p>​        以给定的经纬度（longitude latitude）为中心， 返回键包含的位置元素当中， 与中心的距离不超过给 定最大距离（radius ）的所有位置元素。</p><pre class=" language-none"><code class="language-none">georadius key longitude latitude radius m|km|ft|mi#获取经纬度110 30为中心，在china内1200公里范围内的所有元素。georadius china 110 30 1200 km</code></pre><h4 id="使用场景-5"><a href="#使用场景-5" class="headerlink" title="使用场景"></a>使用场景</h4><ul><li>附近的电影院 </li><li>附近的好友 </li><li>离最近的火锅店</li></ul><h3 id="Hyperloglog"><a href="#Hyperloglog" class="headerlink" title="Hyperloglog"></a>Hyperloglog</h3><h5 id="简介-7"><a href="#简介-7" class="headerlink" title="简介"></a>简介</h5><p>​        在我们做站点流量统计的时候一般会统计页面UV(独立访客:unique visitor)和PV(即页面浏览量：page view)。redis HyperLogLog是用来做基数统计的算法，HyperLogLog的优点是：在输入元素的数量或者 体积非常非常大时，计算基数所需的空间总是固定的、并且使很小的。</p><h6 id="什么是基数"><a href="#什么是基数" class="headerlink" title="什么是基数"></a>什么是基数</h6><p>​        比如数据集{1,3,5,7,5,7,8}，那么这个数据集的基数集为{1,3,5,7,8},基数(不重复元素)为5.基数估计就是在 误差可接受的范围内，快速计算基数。</p><h4 id="常用命令-7"><a href="#常用命令-7" class="headerlink" title="常用命令"></a>常用命令</h4><h5 id="pfadd"><a href="#pfadd" class="headerlink" title="pfadd"></a>pfadd</h5><p>将所有元素参数添加到 Hyperloglog 数据结构中。</p><p>如果至少有个元素被添加返回 1， 否则返回 0。</p><pre class=" language-none"><code class="language-none">pfadd key element1 element2……pfadd book1 uid1 uid2 uid3</code></pre><p>注意： 添加元素到HyperLogLog中，如果内部有变动返回1，没有返回0。</p><h5 id="pfcount"><a href="#pfcount" class="headerlink" title="pfcount"></a>pfcount</h5><p>计算Hyperloglog 近似基数，可以计算多个Hyperloglog ，统计基数总数。</p><pre class=" language-none"><code class="language-none">pfcount key1 key2……</code></pre><h5 id="pfmerge"><a href="#pfmerge" class="headerlink" title="pfmerge"></a>pfmerge</h5><p>将一个或多个Hyperloglog（sourcekey1） 合并成一个Hyperloglog （destkey ）。</p><pre class=" language-none"><code class="language-none">pfmerge destkey sourcekey1 sourcekey2……</code></pre><h4 id="使用场景-6"><a href="#使用场景-6" class="headerlink" title="使用场景"></a>使用场景</h4><p>​        基数不大，数据量不大就用不上，会有点大材小用浪费空间，有局限性，就是只能统计基数数量，而没 办法去知道具体的内容是什么，和bitmap相比，属于两种特定统计情况，简单来说，HyperLogLog 去 重比 bitmaps 方便很多，一般可以bitmap和hyperloglog配合使用，bitmap标识哪些用户活跃。</p><ul><li>网站PV统计 </li><li>网站UV统计 </li><li>统计访问量(IP数) </li><li>统计在线用户数 </li><li>统计每天搜索不同词条的个数 </li><li>统计文章真实阅读数</li></ul><h3 id="可视化工具"><a href="#可视化工具" class="headerlink" title="可视化工具"></a>可视化工具</h3><p>直接安装就行</p><p>关闭防火墙也还是连接不上，但是我直接连上去了，我是防火墙一直关着，然后只是端口给错了才没连上</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420190437878.png" alt="image-20220420190437878"></p><p>视频里关闭防火墙连不上说是只允许本地访问，要修改配置文件才能远程访问</p><p>是不是我虚拟机配置了本地的ip就给了windows</p><p>注释掉这个</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420190651893.png" alt="image-20220420190651893"></p><p>关掉安全模式后重启</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420190838527.png" alt="image-20220420190838527"></p><p>搞错了，，md一直连接的是docker里的，然后docker里的好像也不用配置就可以直接远程连接上，我说这么管理界面的数据和虚拟机的数据不一样。</p><h3 id="Java整合Redis-Jedis"><a href="#Java整合Redis-Jedis" class="headerlink" title="Java整合Redis_Jedis"></a>Java整合Redis_Jedis</h3><p>？？？为什么文档没有这玩意，直接就到压测了</p><p>手写吧</p><p>创建maven项目，添加依赖</p><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>redis.clients<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>jedis<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.6.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>4.13.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></code></pre><p>运行成功</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420202933246.png" alt="image-20220420202933246"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220420202949899.png" alt="image-20220420202949899"></p><p>list操作</p><p>一点问题没有</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420203616406.png" alt="image-20220420203616406"></p><p>Set</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420204038939.png" alt="image-20220420204038939"></p><p>hash</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420210058735.png" alt="image-20220420210058735"></p><p>zset</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420210441400.png" alt="image-20220420210441400"></p><p>bitmaps</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420211514033.png" alt="image-20220420211514033"></p><p>geo</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420212002745.png" alt="image-20220420212002745"></p><p>hyperloglog</p><p><img src="/2022/04/25/redis-bi-ji/image-20220420212232637.png" alt="image-20220420212232637"></p><h3 id="Java整合Redis-Spring-Data-Redis"><a href="#Java整合Redis-Spring-Data-Redis" class="headerlink" title="Java整合Redis_Spring-Data-Redis"></a>Java整合Redis_Spring-Data-Redis</h3><h3 id="简介-8"><a href="#简介-8" class="headerlink" title="简介"></a>简介</h3><p>Spring-Data-Redis是spring大家族的一部分，通过简单的配置访问Redis服务，对Reids底层开发包(Jedis, JRedis, and RJC)进行了高度封装，RedisTemplate提供了Redis各种操作、异常处理及序列化，支持发布订阅。</p><h3 id="RedisTemplate介绍"><a href="#RedisTemplate介绍" class="headerlink" title="RedisTemplate介绍"></a><strong>RedisTemplate介绍</strong></h3><p>Spring封装了RedisTemplate对象来进行对Redis的各种操作，它支持所有的Redis原生的api。</p><pre class=" language-none"><code class="language-none">1org.springframework.data.redis.core2Class RedisTemplate<K,V></code></pre><blockquote><p>  <strong>注意：</strong></p><ul><li><strong>K</strong>：模板中的Redis key的类型，模板中的Redis key的类型（通常为String）如：RedisTemplate&lt;String, Object&gt;。</li><li><strong>V</strong>：模板中的Redis value的类型</li></ul></blockquote><h3 id="RedisTemplate中定义了对5种数据结构操作"><a href="#RedisTemplate中定义了对5种数据结构操作" class="headerlink" title="RedisTemplate中定义了对5种数据结构操作"></a><strong>RedisTemplate中定义了对5种数据结构操作</strong></h3><pre class=" language-JAVA"><code class="language-JAVA">redisTemplate.opsForValue();//操作字符串redisTemplate.opsForHash();//操作hashredisTemplate.opsForList();//操作listredisTemplate.opsForSet();//操作setredisTemplate.opsForZSet();//操作有序set</code></pre><h3 id="StringRedisTemplate与RedisTemplate"><a href="#StringRedisTemplate与RedisTemplate" class="headerlink" title="StringRedisTemplate与RedisTemplate"></a><strong>StringRedisTemplate与RedisTemplate</strong></h3><ul><li><p>两者的关系是StringRedisTemplate继承RedisTemplate。</p></li><li><p>两者的数据是不共通的；也就是说StringRedisTemplate只能管理StringRedisTemplate里面的数据，RedisTemplate只能管理RedisTemplate中的数据。</p></li><li><p>SDR默认采用的序列化策略有两种，一种是String的序列化策略，一种是JDK的序列化策略。</p><p>StringRedisTemplate默认采用的是String的序列化策略，保存的key和value都是采用此策略序列化保存的。</p><p>RedisTemplate默认采用的是JDK的序列化策略，保存的key和value都是采用此策略序列化保存的。</p></li></ul><p>测试方法写这一行</p><pre class=" language-none"><code class="language-none">redisTemplate.opsForValue().set("key1","value1");</code></pre><p>因为序列化方式不同，这种方式使用的是JDK的序列化 </p><p><img src="/2022/04/25/redis-bi-ji/image-20220421094909095.png" alt="image-20220421094909095"></p><p>加了配置类改序列化就好了</p><p>自定义序列化类</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.spirngdataredisdemo.conf;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;/** * 自定义序列化 */@Configurationpublic class RedisConfig &#123;    @Bean    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory redisConnectionFactory)&#123;        RedisTemplate<String, Object> redisTemplate = new RedisTemplate<>();        //添加序列化机制        redisTemplate.setKeySerializer(new StringRedisSerializer());        redisTemplate.setValueSerializer(new GenericJackson2JsonRedisSerializer());        redisTemplate.setHashKeySerializer(new StringRedisSerializer());        redisTemplate.setHashValueSerializer(new GenericJackson2JsonRedisSerializer());        redisTemplate.setConnectionFactory(redisConnectionFactory);        return redisTemplate;    &#125;&#125;</code></pre><p><img src="/2022/04/25/redis-bi-ji/image-20220421102104191.png" alt="image-20220421102104191"></p><p>添加List</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421102453038.png" alt="image-20220421102453038"></p><p>hash</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421102933751.png" alt="image-20220421102933751"></p><p>set</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421103247187.png" alt="image-20220421103247187"></p><p>zSet</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421104619834.png" alt="image-20220421104619834"></p><p>不多说了</p><pre class=" language-JAVA"><code class="language-JAVA">    /**     * 测试RedisTemplate操作redis服务     */    @Test    public void test()&#123;        //保存数据        redisTemplate.opsForValue().set("key1","value1");        //获取数据        redisTemplate.opsForValue().get("key1");    &#125;    @Test    void ListTest()&#123;//        redisTemplate.opsForList().rightPush("k2","v1");//        redisTemplate.opsForList().rightPush("k2","v2");//        redisTemplate.opsForList().rightPush("k2","v3");//        redisTemplate.opsForList().rightPush("k2","v4");        //获取元素        String k2 = (String) redisTemplate.opsForList().rightPop("k2");        System.out.println(k2);    &#125;    /**     * hash操作     */    @Test    public void hashTest()&#123;//        redisTemplate.opsForHash().put("user","name","JueJue");//        redisTemplate.opsForHash().put("user","age","20");        //获取元素        String s = (String) redisTemplate.opsForHash().get("user", "name");        System.out.println(s);    &#125;    /**     * set操作     */    @Test    public void setTest()&#123;//        redisTemplate.opsForSet().add("sss1","vvv1");//        redisTemplate.opsForSet().add("sss1","v2");//        redisTemplate.opsForSet().add("sss1","v2");//        redisTemplate.opsForSet().add("sss1","v3");        //获取数据        Set s = redisTemplate.opsForSet().members("sss1");        for (Object o : s) &#123;            System.out.println(o.toString());        &#125;        //获取set集合长度        System.out.println(redisTemplate.opsForSet().size("sss1"));    &#125;    @Test    public void zsetTest()&#123;        //添加元素//        redisTemplate.opsForZSet().add("z1","Java",66);//        redisTemplate.opsForZSet().add("z1","C",67);//        redisTemplate.opsForZSet().add("z1","C++",68);        //获取元素        Set k1 = redisTemplate.opsForZSet().range("z1", 0, -1);        for (Object o : k1) &#123;            System.out.println(o);        &#125;        System.out.println("-------------------------");        Set set = redisTemplate.opsForZSet().rangeByScore("z1", 60, 67);        for (Object o : set) &#123;            System.out.println(o);        &#125;    &#125;</code></pre><h2 id="Redis构建Web应用-网页缓存"><a href="#Redis构建Web应用-网页缓存" class="headerlink" title="Redis构建Web应用_网页缓存"></a>Redis构建Web应用_网页缓存</h2><p>就是用户发请求到nginx，然后反向代理负载均衡发到tomcat，之前没有加缓存，就会直接查询数据库</p><p>​        加了之后，请求到了；就会判断缓存中有没有，有就直接返回，没有就走数据库查询，如果数据库中有就把数据加到缓存中，下次查就有缓存了</p><p>创建springboot项目</p><p>写好之后，启动项目就会帮我们创建表</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421152448503.png" alt="image-20220421152448503"></p><p>然后随便添加一条数据，去浏览器地址栏访问</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421152747515.png" alt="image-20220421152747515"></p><p>上代码</p><pre class=" language-JAVA"><code class="language-JAVA">public GoodsEntity getById2(Long id)&#123;        //从数据库中查询商品信息        Optional<GoodsEntity> optionalGoodsEntity = goodsRepository.findById(id);        if (optionalGoodsEntity.isPresent())&#123;            return optionalGoodsEntity.get();        &#125;    return null;&#125;</code></pre><p>这个就是没有缓存的，那它的并发有多少呢？我们也不知道，所以 用一个压测的工具试一试（Jmeter）</p><p>使用</p><p>bin下运行这个</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421190842291.png" alt="image-20220421190842291"></p><p>新建线程组，然后写线程数和循环数，我就是1000*10&#x3D;10000了</p><p>然后还是右键新建取样器Http请求和监听器的报告</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421190123297.png" alt="image-20220421190123297"><img src="/2022/04/25/redis-bi-ji/image-20220421190321543.png" alt="image-20220421190321543"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220421190934598.png" alt="image-20220421190934598"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220421190246781.png" alt="image-20220421190246781"></p><p>一万并发达到4000（没有加缓存）</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421183607570.png" alt="image-20220421183607570"></p><p>写好之后，重启先去浏览器发起一次请求</p><pre class=" language-JAVA"><code class="language-JAVA">@Autowiredprivate StringRedisTemplate stringRedisTemplate;/** * 根据id查询商品信息 * @param id 商品id * @return */public GoodsEntity getById(Long id)&#123;    //查询缓存    String goodsString = stringRedisTemplate.opsForValue().get("goods:" + id);    //判定有没有缓存    if (StringUtils.isEmpty(goodsString))&#123;        //从数据库中查询商品信息        Optional<GoodsEntity> optionalGoodsEntity = goodsRepository.findById(id);        if (optionalGoodsEntity.isPresent())&#123;            GoodsEntity goodsEntity = optionalGoodsEntity.get();            //对象转Json字符串（fastJson）            String goodsEntityJson = JSON.toJSONString(goodsEntity);            //添加缓存            stringRedisTemplate.opsForValue().set("goods:" + id,goodsEntityJson);            //保存完缓存了，就可以返回了            return goodsEntity;        &#125;    &#125;else &#123;        //把字符串转对象        GoodsEntity goodsEntity = JSON.parseObject(goodsString, GoodsEntity.class);        return goodsEntity;    &#125;    return null;&#125;</code></pre><p>然后去redis管理页面就可以看见刚刚加的缓存</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421185105903.png" alt="image-20220421185105903"></p><p>然后进行压力测试</p><p>先清除一下</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421185312803.png" alt="image-20220421185312803"></p><p>屌炸了，牛逼</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421185350415.png" alt="image-20220421185350415"></p><p>再测试几次甚至能到9817</p><p>配置文件</p><pre class=" language-properties"><code class="language-properties"><span class="token comment" spellcheck="true">########################################################</span><span class="token comment" spellcheck="true">### 配置连接池数据库访问配置</span><span class="token comment" spellcheck="true">########################################################</span><span class="token attr-name">spring.datasource.driver-class-name</span><span class="token punctuation">=</span><span class="token attr-value">com.mysql.jdbc.Driver</span><span class="token attr-name">spring.datasource.url</span><span class="token punctuation">=</span><span class="token attr-value">jdbc:mysql://localhost:3306/goods?characterEncoding=utf-8&amp;&amp;useSSL=false</span><span class="token attr-name">spring.datasource.username</span><span class="token punctuation">=</span><span class="token attr-value">root</span><span class="token attr-name">spring.datasource.password</span><span class="token punctuation">=</span><span class="token attr-value">123456</span><span class="token comment" spellcheck="true"># 初始化大小，最小，最大</span><span class="token comment" spellcheck="true">#spring.datasource.initialSize=5</span><span class="token comment" spellcheck="true">#spring.datasource.minIdle=5</span><span class="token comment" spellcheck="true">#spring.datasource.maxActive=20</span><span class="token comment" spellcheck="true"># 配置获取连接等待超时的时间</span><span class="token comment" spellcheck="true">#spring.datasource.maxWait=60000</span><span class="token comment" spellcheck="true"># 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒</span><span class="token comment" spellcheck="true">#spring.datasource.timeBetweenEvictionRunsMillis=60000</span><span class="token comment" spellcheck="true"># 配置一个连接在池中最小生存的时间，单位是毫秒</span><span class="token comment" spellcheck="true">#spring.datasource.minEvictableIdleTimeMillis=300000</span><span class="token comment" spellcheck="true">#spring.datasource.validationQuery=SELECT 1 FROM DUAL</span><span class="token comment" spellcheck="true">#spring.datasource.testWhileIdle=true</span><span class="token comment" spellcheck="true">#spring.datasource.testOnBorrow=false</span><span class="token comment" spellcheck="true">#spring.datasource.testOnReturn=false</span><span class="token comment" spellcheck="true"># 打开PSCache，并且指定每个连接上PSCache的大小</span><span class="token comment" spellcheck="true">#spring.datasource.poolPreparedStatements=true</span><span class="token comment" spellcheck="true">#spring.datasource.maxPoolPreparedStatementPerConnectionSize=20</span><span class="token comment" spellcheck="true"># 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙</span><span class="token comment" spellcheck="true">#spring.datasource.filters=stat,wall,log4j</span><span class="token comment" spellcheck="true"># 通过connectProperties属性来打开mergeSql功能；慢SQL记录</span><span class="token comment" spellcheck="true">#spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000</span><span class="token comment" spellcheck="true"># 合并多个DruidDataSource的监控数据</span><span class="token comment" spellcheck="true">#spring.datasource.useGlobalDataSourceStat=true</span><span class="token comment" spellcheck="true">########################################################</span><span class="token comment" spellcheck="true">### Java Persistence Api --y   JPA配置</span><span class="token comment" spellcheck="true">########################################################</span><span class="token comment" spellcheck="true"># Specify the DBMS</span><span class="token attr-name">spring.jpa.database</span> <span class="token punctuation">=</span> <span class="token attr-value">MYSQL</span><span class="token comment" spellcheck="true"># Show or not log for each sql query</span><span class="token attr-name">spring.jpa.show-sql</span> <span class="token punctuation">=</span> <span class="token attr-value">true</span><span class="token comment" spellcheck="true"># Hibernate ddl auto (create, create-drop, update)</span><span class="token attr-name">spring.jpa.hibernate.ddl-auto</span> <span class="token punctuation">=</span> <span class="token attr-value">update</span><span class="token comment" spellcheck="true"># Naming strategy</span><span class="token comment" spellcheck="true">#[org.hibernate.cfg.ImprovedNamingStrategy  #org.hibernate.cfg.DefaultNamingStrategy]</span><span class="token attr-name">spring.jpa.hibernate.naming-strategy</span> <span class="token punctuation">=</span> <span class="token attr-value">org.hibernate.cfg.ImprovedNamingStrategy</span><span class="token comment" spellcheck="true"># stripped before adding them to the entity manager)</span><span class="token attr-name">spring.jpa.properties.hibernate.dialect</span> <span class="token punctuation">=</span> <span class="token attr-value">org.hibernate.dialect.MySQL5Dialect</span><span class="token comment" spellcheck="true">########################################################</span><span class="token comment" spellcheck="true">### 配置连接池数据库访问配置</span><span class="token comment" spellcheck="true">########################################################</span><span class="token comment" spellcheck="true">#Redis服务器连接地址</span><span class="token attr-name">spring.redis.host</span><span class="token punctuation">=</span><span class="token attr-value">192.168.8.11</span><span class="token comment" spellcheck="true">#Redis服务器连接端口</span><span class="token attr-name">spring.redis.port</span><span class="token punctuation">=</span><span class="token attr-value">6379</span><span class="token comment" spellcheck="true">#连接池最大连接数（使用负值表示没有限制）</span><span class="token attr-name">spring.redis.pool.max-active</span><span class="token punctuation">=</span><span class="token attr-value">8</span><span class="token comment" spellcheck="true">#连接池最大阻塞等待时间（使用负值表示没有限制）</span><span class="token attr-name">spring.redis.pool.max-wait</span><span class="token punctuation">=</span><span class="token attr-value">-1</span><span class="token comment" spellcheck="true">#连接池中的最大空闲连接</span><span class="token attr-name">spring.redis.pool.max-idle</span><span class="token punctuation">=</span><span class="token attr-value">8</span><span class="token comment" spellcheck="true">#连接池中的最小空闲连接</span><span class="token attr-name">spring.redis.pool.min-idle</span><span class="token punctuation">=</span><span class="token attr-value">0</span><span class="token comment" spellcheck="true">#连接超时时间（毫秒）</span><span class="token attr-name">spring.redis.timeout</span><span class="token punctuation">=</span><span class="token attr-value">30000</span><span class="token attr-name">logging.pattern.console</span><span class="token punctuation">=</span><span class="token attr-value">%d&amp;#123;MM/dd HH:mm:ss.SSS&amp;#125; %clr(%-5level) ---  [%-15thread] %cyan(%-50logger&amp;#123;50&amp;#125;):%msg%n</span></code></pre><h2 id="其他功能"><a href="#其他功能" class="headerlink" title="其他功能"></a>其他功能</h2><h3 id="发布与订阅"><a href="#发布与订阅" class="headerlink" title="发布与订阅"></a>发布与订阅</h3><p>先在一个终端上订阅channel</p><p>SUBSCRIBE channel</p><p>然后再开两个别的终端连上去，其中一个也订阅，就有两个订阅了</p><p>第三个就是发布者</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421193244222.png" alt="image-20220421193244222"></p><p>终端1和终端2的页面是一样的</p><p>所以这就是发布订阅的功能，以后想搞聊天，博客等等可以使用一下</p><h3 id="慢查询"><a href="#慢查询" class="headerlink" title="慢查询"></a>慢查询</h3><p>慢查询日志帮助开发和运维人员定位系统存在的慢操作</p><p>慢查询就是工作的时候某一条命令，它的执行效率特别差的时候可以给他找出来优化一下</p><p>开发和运维都会用到，工作中解决问题</p><h5 id="什么是慢查询"><a href="#什么是慢查询" class="headerlink" title="什么是慢查询"></a>什么是慢查询</h5><p>慢查询，顾名思义就是比较慢的查询，但是究竟是哪里慢呢？</p><h5 id="Redis命令执行的整个过程"><a href="#Redis命令执行的整个过程" class="headerlink" title="Redis命令执行的整个过程"></a>Redis命令执行的整个过程</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220421213049982.png" alt="image-20220421213049982"></p><p>两点说明： 1. 慢查询发生在第3阶段 2. 客户端超时不一定慢查询，但慢查询是客户端超时的一个可能因素 3. 慢查询日志是存放在Redis内存列表中。</p><h5 id="什么是慢查询日志"><a href="#什么是慢查询日志" class="headerlink" title="什么是慢查询日志"></a>什么是慢查询日志</h5><p>慢查询日志是Redis服务端在命令执行前后计算每条命令的执行时长，当超过某个阈值是记录下来的日 志。日志中记录了慢查询发生的时间，还有执行时长、具体什么命令等信息，它可以用来帮助开发和运 维人员定位系统中存在的慢查询。</p><h5 id="何获取慢查询日志"><a href="#何获取慢查询日志" class="headerlink" title="何获取慢查询日志"></a>何获取慢查询日志</h5><p>可以使用 slowlog get 命令获取慢查询日志，在 slowlog get 后面还可以加一个数字，用于指定获取 慢查询日志的条数，比如，获取3条慢查询日志： SLOWLOG get 3</p><h5 id="获取慢查询日志的长度"><a href="#获取慢查询日志的长度" class="headerlink" title="获取慢查询日志的长度"></a>获取慢查询日志的长度</h5><p>可以使用 slowlog len 命令获取慢查询日志的长度。</p><h5 id="怎么配置慢查询的参数"><a href="#怎么配置慢查询的参数" class="headerlink" title="怎么配置慢查询的参数"></a>怎么配置慢查询的参数</h5><ul><li>命令执行时长的指定阈值 slowlog-log-slower-than。</li></ul><p>​        slowlog-log-slower-than的作用是指定命令执行时长的阈值，执行命令的时长超过这个阈值时就会被记 录下来。</p><ul><li>存放慢查询日志的条数 slowlog-max-len。</li></ul><p>​         slowlog-max-len的作用是指定慢查询日志最多存储的条数。实际上，Redis使用了一个列表存放慢查询 日志，slowlog-max-len就是这个列表的最大长度。</p><h4 id="如何进行配置"><a href="#如何进行配置" class="headerlink" title="如何进行配置"></a>如何进行配置</h4><h5 id="查看慢日志配置"><a href="#查看慢日志配置" class="headerlink" title="查看慢日志配置"></a>查看慢日志配置</h5><p>客户端redis-cli连接上去之后config get slow*</p><pre class=" language-bash"><code class="language-bash">127.0.0.1:6379<span class="token operator">></span> config get slow*1<span class="token punctuation">)</span> <span class="token string">"slowlog-max-len"</span>2<span class="token punctuation">)</span> <span class="token string">"128"</span>3<span class="token punctuation">)</span> <span class="token string">"slowlog-log-slower-than"</span>4<span class="token punctuation">)</span> <span class="token string">"10000"</span>10000阈值，单位微秒，此处为10毫秒，128慢日志记录保存数量的阈值，此处保存128条。</code></pre><h5 id="修改Redis配置文件"><a href="#修改Redis配置文件" class="headerlink" title="修改Redis配置文件"></a>修改Redis配置文件</h5><p>比如，把slowlog-log-slower-than设置为1000，slowlog-max-len设置为1200：</p><pre class=" language-none"><code class="language-none">slowlog-log-slower-than 1000slowlog-max-len 1200</code></pre><h5 id="使用-config-set-命令动态修改。"><a href="#使用-config-set-命令动态修改。" class="headerlink" title="使用 config set 命令动态修改。"></a>使用 config set 命令动态修改。</h5><p>比如，还是把slowlog-log-slower-than设置为1000，slowlog-max-len设置为1200：</p><pre class=" language-bash"><code class="language-bash"><span class="token operator">></span> config <span class="token keyword">set</span> slowlog-log-slower-than 1000OK<span class="token operator">></span> config <span class="token keyword">set</span> slowlog-max-len 1200OK<span class="token operator">></span> config rewriteOK</code></pre><h4 id="实践建议"><a href="#实践建议" class="headerlink" title="实践建议"></a>实践建议</h4><p><strong>slowlog-max-len配置建议</strong></p><ul><li><p>线上建议调大慢查询列表，记录慢查询时Redis会对长命令做截断操作，并不会占用大量内存。 </p></li><li><p>增大慢查询列表可以减缓慢查询被剔除的可能，例如线上可设置为1000以上。</p></li></ul><p><strong>slowlog-log-slower-than配置建议</strong></p><ul><li><p>默认值超过10毫秒判定为慢查询，需要根据Redis并发量调整该值。 </p></li><li><p>由于Redis采用单线程响应命令，对于高流量的场景，如果命令执行时间在1毫秒以上，那么Redis 最多可支撑OPS不到1000。因此对于高OPS场景的Redis建议设置为1毫秒。</p></li></ul><h3 id="流水线popelines"><a href="#流水线popelines" class="headerlink" title="流水线popelines"></a>流水线popelines</h3><p>回去redisdemo项目</p><p>减少网络时间开销</p><p>回去之前的redisdemo项目测试</p><h5 id="1次网络命令通信模型"><a href="#1次网络命令通信模型" class="headerlink" title="1次网络命令通信模型"></a>1次网络命令通信模型</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220421212701439.png" alt="image-20220421212701439"></p><p>经历了1次时间 &#x3D; 1次网络时间 + 1次命令时间。</p><h5 id="批量网络命令通信模型"><a href="#批量网络命令通信模型" class="headerlink" title="批量网络命令通信模型"></a>批量网络命令通信模型</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220421212717693.png" alt="image-20220421212717693"></p><p>经历了 n次时间 &#x3D; n次网络时间 + n次命令时间</p><h5 id="什么是流水线？"><a href="#什么是流水线？" class="headerlink" title="什么是流水线？"></a>什么是流水线？</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220421212733784.png" alt="image-20220421212733784"></p><p>经历了 1次pipeline(n条命令) &#x3D; 1次网络时间 + n次命令时间，这大大减少了网络时间的开销，这就是流 水线。</p><p>案例展示 从北京到上海的一条命令的生命周期有多长？</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421212808232.png" alt="image-20220421212808232"></p><p>执行一条命令在redis端可能需要几百微秒，而在网络光纤中传输只花费了13毫秒。</p><p>注意： 在执行批量操作而没有使用pipeline功能，会将大量的时间耗费在每一次网络传输的过程上；而使 用pipeline后，只需要经过一次网络传输，然后批量在redis端进行命令操作。这会大大提高了效 率。</p><p>实现：先引入jedis依赖包</p><pre class=" language-JAVA"><code class="language-JAVA">/** * 没有pipeline测试 */@Testpublic void pipelineTest()&#123;    //开始时间    long startTime = System.currentTimeMillis();    //添加元素    for (int i = 0; i < 10000; i++) &#123;        jedis.hset("hashkey"+i,"field"+i,"value"+i);    &#125;    //结束时间    long endTime = System.currentTimeMillis();    System.out.println(endTime-startTime);&#125;/** * pipeline测试 */@Testpublic void pipelineTest2()&#123;    //开始时间    long startTime = System.currentTimeMillis();    //添加元素    for (int i = 0; i < 100; i++) &#123;        Pipeline pipeline = jedis.pipelined();        for (int j = i*100; j < (i+1)*100; j++) &#123;            pipeline.hset("hashkey"+j,"field"+j,"value"+j);        &#125;        pipeline.syncAndReturnAll();    &#125;    //结束时间    long endTime = System.currentTimeMillis();    System.out.println(endTime-startTime);&#125;</code></pre><p>没有pipeline的——–2765毫秒</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421204624848.png" alt="image-20220421204624848"></p><p>pipeline测试—-79毫秒</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421205148053.png" alt="image-20220421205148053"></p><p>所以以后批量添加的时候就要使用pipeline</p><h3 id="Redis数据安全"><a href="#Redis数据安全" class="headerlink" title="Redis数据安全"></a>Redis数据安全</h3><p>​        由于Redis的数据都存放在内存中，如果没有配置持久化，Redis重启后数据就全丢失了，于是需要开启 Redis的持久化功能，将数据保存到磁盘上，当Redis重启后，可以从磁盘中恢复数据。</p><h4 id="持久化机制概述"><a href="#持久化机制概述" class="headerlink" title="持久化机制概述"></a>持久化机制概述</h4><p>​        对于Redis而言，持久化机制是指把内存中的数据存为硬盘文件， 这样当Redis重启或服务器故障时能根 据持久化后的硬盘文件恢复数 据。</p><h4 id="持久化机制的意义"><a href="#持久化机制的意义" class="headerlink" title="持久化机制的意义"></a>持久化机制的意义</h4><p>redis持久化的意义，在于<strong>故障恢复</strong>。比如部署了一个redis，作为cache缓存，同时也可以保存一些比较 重要的数据。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220421212535122.png" alt="image-20220421212535122"></p><p>也可以定期把磁盘里的文件备份到云存储服务上去，就可以保证数据永久不丢失</p><h5 id="Redis提供了两个不同形式的持久化方式"><a href="#Redis提供了两个不同形式的持久化方式" class="headerlink" title="Redis提供了两个不同形式的持久化方式"></a>Redis提供了两个不同形式的持久化方式</h5><p>RDB(Redis DataBase) ——-其实就是把数据以快照的形式保存在磁盘上</p><p>AOF(Append Only File)———-可以理解为追加文件的方式</p><h4 id="持久化机制实战"><a href="#持久化机制实战" class="headerlink" title="持久化机制实战"></a>持久化机制实战</h4><h5 id="RDB是什么"><a href="#RDB是什么" class="headerlink" title="RDB是什么"></a>RDB是什么</h5><p>​        在指定的时间间隔内将内存的数据集快照写入磁盘，也就是行话讲的快照，它恢复时是将快照文件直接 读到内存里。</p><h5 id="配置dump-rdb文件"><a href="#配置dump-rdb文件" class="headerlink" title="配置dump.rdb文件"></a>配置dump.rdb文件</h5><p>400多行就是生成文件的名字，:set nu 就可设置行号</p><p>改一下生成文件的路径<br>rdb文件的保存位置，也可以修改。默认在Redis启动时命令行所在的目录下。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220422095200309.png" alt="image-20220422095200309"></p><h5 id="触发机制-主要三种方式"><a href="#触发机制-主要三种方式" class="headerlink" title="触发机制-主要三种方式"></a>触发机制-主要三种方式</h5><h6 id="RDB配置"><a href="#RDB配置" class="headerlink" title="RDB配置"></a>RDB配置</h6><p>快照默认配置： </p><ul><li>save 3600 1：表示3600秒内（一小时）如果至少有1个key的值变化，则保存。 </li><li>save 300 100：表示300秒内（五分钟）如果至少有100个 key 的值变化，则保存。 </li><li>save 60 10000：表示60秒内如果至少有 10000个key的值变化，则保存。</li></ul><h6 id="配置新的保存规则"><a href="#配置新的保存规则" class="headerlink" title="配置新的保存规则"></a>配置新的保存规则</h6><p>给redis.conf添加新的快照策略，30秒内如果有5次key的变化，则触发快照。配置修改后，需要重启 Redis服务。</p><p>加一个save 5 1做演示  5s内有一个key改变就出发</p><h5 id="flushall"><a href="#flushall" class="headerlink" title="flushall"></a>flushall</h5><p>执行flushall命令，也会触发rdb规则。</p><p>加两个数据触发就可以看见</p><p><img src="/2022/04/25/redis-bi-ji/image-20220422100616324.png" alt="image-20220422100616324"></p><p>然后加入redis出问题，那启动的时候就会自动的把这个文件加载到内存中</p><h5 id="save与bgsave"><a href="#save与bgsave" class="headerlink" title="save与bgsave"></a>save与bgsave</h5><p>手动触发Redis进行RDB持久化的命令有两种：</p><ol><li>save 该命令会阻塞当前Redis服务器，执行save命令期间，Redis不能处理其他命令，直到RDB过程完成 为止，不建议使用。</li><li>bgsave 执行该命令时，Redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。</li></ol><h5 id="高级配置"><a href="#高级配置" class="headerlink" title="高级配置"></a>高级配置</h5><h6 id="stop-writes-on-bgsave-error"><a href="#stop-writes-on-bgsave-error" class="headerlink" title="stop-writes-on-bgsave-error"></a>stop-writes-on-bgsave-error</h6><p>默认值是yes。当Redis无法写入磁盘的话，直接关闭Redis的写操作。</p><h6 id="rdbcompression"><a href="#rdbcompression" class="headerlink" title="rdbcompression"></a>rdbcompression</h6><p>​        默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算 法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照 会比较大。</p><h6 id="rdbchecksum"><a href="#rdbchecksum" class="headerlink" title="rdbchecksum"></a>rdbchecksum</h6><p>默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加 大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。</p><h6 id="恢复数据"><a href="#恢复数据" class="headerlink" title="恢复数据"></a>恢复数据</h6><p>只需要将rdb文件放在Redis的启动目录，Redis启动时会自动加载dump.rdb并恢复数据。</p><p>kill掉都可以恢复，只要有这个文件就会默认帮我们去加载</p><p><img src="/2022/04/25/redis-bi-ji/image-20220422101157274.png" alt="image-20220422101157274"></p><h5 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h5><ul><li>适合大规模的数据恢复 </li><li>对数据完整性和一致性要求不高更适合使用 </li><li>节省磁盘空间 </li><li>恢复速度快</li></ul><h5 id="劣势"><a href="#劣势" class="headerlink" title="劣势"></a>劣势</h5><p>在备份周期在一定间隔时间做一次备份，所以如果Redis意外down掉的话，就会丢失最后一次快照后的所有修改。</p><h4 id="AOF持久化机制"><a href="#AOF持久化机制" class="headerlink" title="AOF持久化机制"></a>AOF持久化机制</h4><p>AOF持久化机制通俗的理解就是日志记录</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425190344559.png" alt="image-20220425190344559"></p><h5 id="AOF是什么"><a href="#AOF是什么" class="headerlink" title="AOF是什么"></a>AOF是什么</h5><p>以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来。</p><p>默认不开启AOF，改一下开启 改完要重启redis服务<br>可以在redis.conf中配置文件名称，默认为appendonly.aof。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220422110902027.png" alt="image-20220422110902027"></p><h6 id="注意：-2"><a href="#注意：-2" class="headerlink" title="注意："></a>注意：</h6><p>AOF文件的保存路径，同RDB的路径一致，如果AOF和RDB同时启动，<strong>Redis默认读取AOF的数据。</strong></p><h5 id="AOF同步频率设置"><a href="#AOF同步频率设置" class="headerlink" title="AOF同步频率设置"></a>AOF同步频率设置</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220425190527044.png" alt="image-20220425190527044"></p><h6 id="参数："><a href="#参数：" class="headerlink" title="参数："></a>参数：</h6><p>1.appendfsync always </p><p>​    始终同步，每次Redis的写入都会立刻记入日志，性能较差但数据完整性比较好。 </p><p>2.appendfsync everysec </p><p>​    每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失。 </p><p>3.appendfsync no </p><p>​    redis不主动进行同步，把同步时机交给操作系统。</p><h5 id="优势-1"><a href="#优势-1" class="headerlink" title="优势"></a>优势</h5><ul><li>备份机制更稳健，丢失数据概率更低。 </li><li>可读的日志文本，通过操作AOF稳健，可以处理误操作。</li></ul><p>劣势 </p><ul><li>比起RDB占用更多的磁盘空间。 </li><li>恢复备份速度要慢。 </li><li>每次读写都同步的话，有一定的性能压力。</li></ul><p>保存的都是一堆命令</p><p><img src="/2022/04/25/redis-bi-ji/image-20220422111132449.png" alt="image-20220422111132449"></p><p>然后手动清除一下，再去aof文件中的最后一行把这个手动删除的命令删掉保存退出</p><p>然后你再启动的时候就会把aof文件里的命令再跑一遍</p><p><strong>基本上都是选每秒同步</strong></p><h4 id="如何选择持久化机制"><a href="#如何选择持久化机制" class="headerlink" title="如何选择持久化机制"></a>如何选择持久化机制</h4><h6 id="不要仅仅使用RDB"><a href="#不要仅仅使用RDB" class="headerlink" title="不要仅仅使用RDB"></a>不要仅仅使用RDB</h6><p>​        RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机， 那么会丢失最近5分钟的数据。</p><h6 id="也不要仅仅使用AOF"><a href="#也不要仅仅使用AOF" class="headerlink" title="也不要仅仅使用AOF"></a>也不要仅仅使用AOF</h6><p>1.你通过AOF做冷备，没有RDB做冷备，来的恢复速度更快。 </p><p>2.RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug。</p><p>冷备份，比如每天晚上十二点保存一个RDB的快照到云平台上</p><p>想恢复就直接拷去redis就行</p><h5 id="综合使用AOF和RDB两种持久化机制"><a href="#综合使用AOF和RDB两种持久化机制" class="headerlink" title="综合使用AOF和RDB两种持久化机制"></a>综合使用AOF和RDB两种持久化机制</h5><p>​        用AOF来保证数据不丢失，作为数据恢复的第一选择，用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复。</p><h3 id="Redis事务"><a href="#Redis事务" class="headerlink" title="Redis事务"></a>Redis事务</h3><p>数据库事务的四大特性 </p><ul><li>A：Atomic，原子性，将所有SQL作为原子工作单元执行，要么全部执行，要么全部不执行； </li><li>C：Consistent，一致性，事务完成后，所有数据的状态都是一致的，即A账户只要减去了100，B 账户则必定加上了100； </li><li>I：Isolation，隔离性，如果有多个事务并发执行，每个事务作出的修改必须与其他事务隔离； </li><li>D：Duration，持久性，即事务完成后，对数据库数据的修改被持久化存储。</li></ul><h5 id="Redis事务-1"><a href="#Redis事务-1" class="headerlink" title="Redis事务"></a>Redis事务</h5><p>​        Redis事务是一组命令的集合，一个事务中的所有命令都将被序列化，按照一次性、顺序性、排他性的执 行一系列的命令</p><h5 id="Redis事务三大特性"><a href="#Redis事务三大特性" class="headerlink" title="Redis事务三大特性"></a>Redis事务三大特性</h5><ol><li>单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其 他客户端发送来的命令请求所打断； </li><li>没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令 都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”。 </li><li>不保证原子性：redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚；</li></ol><h5 id="Redis事务执行的三个阶段"><a href="#Redis事务执行的三个阶段" class="headerlink" title="Redis事务执行的三个阶段"></a>Redis事务执行的三个阶段</h5><ul><li>开启：以 MULTI 开始一个事务； </li><li>入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面； </li><li>执行：由 EXEC 命令触发事务；</li></ul><h4 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h4><h5 id="Multi、Exec、discard"><a href="#Multi、Exec、discard" class="headerlink" title="Multi、Exec、discard"></a>Multi、Exec、discard</h5><p>​        事务从输入Multi命令开始，输入的命令都会依次压入命令缓冲队列中，并不会执行，直到输入Exec后， Redis会将之前的命令缓冲队列中的命令依次执行。组队过程中，可以通过discard来放弃组队。</p><h5 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h5><p>正常事务提交</p><p><strong><img src="/2022/04/25/redis-bi-ji/image-20220424080022115.png" alt="image-20220424080022115"></strong></p><p>取消</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424080124561.png" alt="image-20220424080124561"></p><p>事务里面出现<strong>语法错误</strong>，就会全部失败，就是一种连带责任</p><p>还有一种就是冤有头债有主</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424080509486.png" alt="image-20220424080509486"></p><h2 id="Redis集群"><a href="#Redis集群" class="headerlink" title="Redis集群"></a>Redis集群</h2><p><img src="/2022/04/25/redis-bi-ji/image-20220425191427072.png" alt="image-20220425191427072"></p><h4 id="什么是主从复制"><a href="#什么是主从复制" class="headerlink" title="什么是主从复制"></a>什么是主从复制</h4><p>主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后 者称为从节点(slave),数据的复制是单向的，只能由主节点到从节点。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425191658932.png" alt="image-20220425191658932"></p><p>写操作从主机点，从节点处理读操作</p><h4 id="主从复制的作用"><a href="#主从复制的作用" class="headerlink" title="主从复制的作用"></a>主从复制的作用</h4><p>1.<strong>数据冗余：</strong>主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 </p><p>2.<strong>故障恢复：</strong>当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服 务的冗余。 </p><p>3.<strong>负载均衡：</strong>在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务 （即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是 在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</p><p>4.<strong>高可用基石：</strong>除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是 Redis高可用的基础。</p><h4 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h4><p>学习就可以去一台机器搭建三个redis</p><p>就是新加三个配置文件，并针对端口做不同修改</p><p>redis6379.conf  redis6380.conf  6381.conf</p><p>就对应改下面三个地方</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425192020449.png" alt="image-20220425192020449"></p><p>启动三台</p><pre class=" language-none"><code class="language-none">./redis-server ../redis6379.conf./redis-server ../redis6380.conf./redis-server ../redis6381.conf</code></pre><p>查看是否搭建完成</p><p><strong><img src="/2022/04/25/redis-bi-ji/image-20220424084531105.png" alt="image-20220424084531105"></strong></p><p>然后再开几个终端连接上去</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424084757643.png" alt="image-20220424084757643"></p><p>但是还没有去配置认老大</p><p>就是在小弟这里配置</p><h5 id="配从库不配主库"><a href="#配从库不配主库" class="headerlink" title="配从库不配主库"></a>配从库不配主库</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220424084928252.png" alt="image-20220424084928252"></p><p>然后三台机器都可以看一下</p><p>主节点</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424085423087.png" alt="image-20220424085423087"></p><p>从节点</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424085519137.png" alt="image-20220424085519137"><img src="/2022/04/25/redis-bi-ji/image-20220424085538862.png" alt="image-20220424085538862"></p><p>然后你可以去试一试他们的数据是否同步    然后你会发现数据就是同步的</p><p>试一试从节点能不能保存数据（不能），只能读操作</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424085749352.png" alt="image-20220424085749352"></p><h4 id="主从复制原理剖析"><a href="#主从复制原理剖析" class="headerlink" title="主从复制原理剖析"></a>主从复制原理剖析</h4><p>主从复制可以分为3个阶段六个过程</p><ul><li>连接建立阶段</li><li>数据同步阶段</li><li>命令传播阶段</li></ul><p>复制过程大致分为6个过程</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425193232590.png" alt="image-20220425193232590"></p><p>1、保存主节点（master）信息。</p><p>2、从节点（slave）内部通过每秒运行的定时任务维护复制相关逻辑，当定时任务发现存在新的主 节点后，会尝试与该节点建立网络连接</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425193317658.png" alt="image-20220425193317658"></p><p>3、从节点与主节点建立网络连接 </p><p>从节点会建立一个 socket 套接字，从节点建立了一个端口为51234的套接字，专门用于接受主节点发送 的复制命令。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425193335769.png" alt="image-20220425193335769"></p><p>4、发送ping命令 </p><p>连接建立成功后从节点发送 ping 请求进行首次通信</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425193400062.png" alt="image-20220425193400062"></p><h6 id="作用："><a href="#作用：" class="headerlink" title="作用："></a>作用：</h6><ul><li>检测主从之间网络套接字是否可用。 </li><li>检测主节点当前是否可以接受命令 。</li></ul><p>4、权限验证。</p><p>​        如果主节点设置了 requirepass 参数，则需要密码验证，从节点必须配置 masterauth 参数保证与主节 点相同的密码才能通过验证；如果验证失败复制将终止，从节点重新发起复制流程。</p><p>5、同步数据集。 </p><p>​        主从复制连接正常通信后，对于首次建立复制的场景，主节点会把持有的数据全部发送给从节点，这部 分操作是耗时最长的步骤。</p><p>主节点那900多行有一个requirepass（注释掉的）  </p><p>如果你把他放开之后，就代表reids设置了密码  从节点连接的时候就要密码，不然到不了第五步的同步数据</p><h5 id="主从同步策略"><a href="#主从同步策略" class="headerlink" title="主从同步策略"></a>主从同步策略</h5><p>​        主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</p><pre class=" language-none"><code class="language-none">$3 \r \nset \r \n$4 \r \nname \r \n</code></pre><p><img src="/2022/04/25/redis-bi-ji/image-20220425193634389.png" alt="image-20220425193634389"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220425193756367.png" alt="image-20220425193756367"></p><p>偏移量相等说明master的数据就全部同步过去了。</p><p>6、命令持续复制。 </p><p>​        当主节点把当前的数据同步给从节点后，便完成了复制的建立流程。接下来主节点会持续地把写命令发 送给从节点，保证主从数据一致性。</p><h3 id="哨兵监控"><a href="#哨兵监控" class="headerlink" title="哨兵监控"></a>哨兵监控</h3><h4 id="Redis主从复制缺点"><a href="#Redis主从复制缺点" class="headerlink" title="Redis主从复制缺点"></a>Redis主从复制缺点</h4><p>当主机 Master 宕机以后，我们需要人工解决切换。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425193848246.png" alt="image-20220425193848246"></p><p>暴漏问题： 一旦主节点宕机，写服务无法使用，就需要手动去切换，重新选取主节点，手动设置主从关系。</p><h5 id="主从切换技术"><a href="#主从切换技术" class="headerlink" title="主从切换技术"></a>主从切换技术</h5><p>​        当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造 成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑<strong>哨兵模式。</strong></p><h5 id="哨兵概述"><a href="#哨兵概述" class="headerlink" title="哨兵概述"></a>哨兵概述</h5><p>​        哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独 立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。</p><h5 id="哨兵作用"><a href="#哨兵作用" class="headerlink" title="哨兵作用"></a>哨兵作用</h5><ul><li>集群监控：负责监控redis master和slave进程是否正常工作 </li><li>消息通知：如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员 </li><li>故障转移：如果master node挂掉了，会自动转移到slave node上</li><li>配置中心：如果故障转移发生了，通知client客户端新的master地址</li></ul><h4 id="哨兵监控环境搭建"><a href="#哨兵监控环境搭建" class="headerlink" title="哨兵监控环境搭建"></a>哨兵监控环境搭建</h4><p>参数就是3给2，5给3 7给4，懂我意思吧</p><p>新建sentinel-26379.conf文件</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#端口</span>port 26379<span class="token comment" spellcheck="true">#守护进程运行</span>daemonize <span class="token function">yes</span><span class="token comment" spellcheck="true">#日志文件</span>logfile <span class="token string">"26379.log"</span>sentinel monitor mymaster 127.0.0.1 6379 2</code></pre><h6 id="参数：-1"><a href="#参数：-1" class="headerlink" title="参数："></a>参数：</h6><p>sentinel monitor mymaster 192.168.92.128 6379 2 配置的含义是：该哨兵节点监控 192.168.92.128:6379这个主节点，该主节点的名称是mymaster，最后的2的含义与主节点的故障 判定有关：至少需要2个哨兵节点同意，才能判定主节点故障并进行故障转移。</p><p>然后写好一个sentinel配置文件之后，复制俩份，复制的两份都只改端口和日志文件。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424093534583.png" alt="image-20220424093534583"></p><p>学习嘛，也是一台机器搭建三个哨兵，生产环境就是一台机器放一个哨兵</p><p>启动方式，两种</p><p>记一种就算了，第一种</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 第一种</span>redis-sentinel 配置文件名字<span class="token comment" spellcheck="true">#第二种</span>redis-server 配置文件名字--sentinel</code></pre><p>连接进去哨兵</p><p>查看哨兵节点状态</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424094229091.png" alt="image-20220424094229091"></p><h4 id="哨兵工作原理"><a href="#哨兵工作原理" class="headerlink" title="哨兵工作原理"></a>哨兵工作原理</h4><h5 id="监控阶段"><a href="#监控阶段" class="headerlink" title="监控阶段"></a>监控阶段</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220425195154281.png" alt="image-20220425195154281"></p><p>注意： </p><ul><li>sentinel(哨兵1)—–&gt;向master(主)和slave(从)发起info，拿到全信息。 </li><li>sentinel(哨兵2)—–&gt;向master(主)发起info，就知道已经存在的sentinel(哨兵1)的信息，并且 连接slave(从)。 </li><li>sentinel(哨兵2)—–&gt;向sentinel(哨兵1)发起subscribe(订阅)。</li></ul><h5 id="通知阶段"><a href="#通知阶段" class="headerlink" title="通知阶段"></a>通知阶段</h5><p>sentinel不断的向master和slave发起通知，收集信息。</p><h5 id="故障转移阶段"><a href="#故障转移阶段" class="headerlink" title="故障转移阶段"></a>故障转移阶段</h5><p>​        通知阶段sentinel发送的通知没得到master的回应，就会把master标记为SRI_S_DOWN,并且把master 的状态发给各个sentinel，其他sentinel听到master挂了，说我不信，我也去看看，并把结果共享给各 个sentinel，当有一半的sentinel都认为master挂了的时候，就会把master标记为SRI_0_DOWN</p><p>问题来了： 这时就要把master给换掉了，到底谁当Master呢。</p><p>自己最先接到哪个sentinel的竞选通知就会把票投给它。</p><p>剔除一些情况： 1. 不在线的 2. 响应慢的 3. 与原来master断开时间久的 4. 优先级原则</p><h4 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h4><h4 id="演示故障转移"><a href="#演示故障转移" class="headerlink" title="演示故障转移"></a>演示故障转移</h4><p>直接kill掉主节点</p><p>kill完之后在哨兵节点种查看一下</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424102845205.png" alt="image-20220424102845205"></p><p>主节点不是6379么，然后现在变成6380，自动切换，所以这就是哨兵故障转移过程</p><p>注意：这里还是比较快切换过来的，但是一般来说会需要一段时间</p><p>然后我们重启一下6379看看</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424103503039.png" alt="image-20220424103503039"></p><p>故障转移，哨兵和所有的配置文件都会被改写</p><p>比如看一下，这块就是新加的内容</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424103744511.png" alt="image-20220424103744511"></p><h5 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h5><ul><li>哨兵系统中的主从节点，与普通的主从节点并没有什么区别，故障发现和转移是由哨兵来控制和完 成的。 </li><li>哨兵节点本质上是redis节点。 </li><li>每个哨兵节点，只需要配置监控主节点，便可以自动发现其他的哨兵节点和从节点。 </li><li>在哨兵节点启动和故障转移阶段，各个节点的配置文件会被重写(config rewrite)。</li></ul><h3 id="Cluster模式概述"><a href="#Cluster模式概述" class="headerlink" title="Cluster模式概述"></a>Cluster模式概述</h3><p>redis集群是一个由多个主从节点群组成的分布式服务集群</p><p>Redis有三种集群模式 </p><p>主从模式 </p><p>Sentinel模式 </p><p>Cluster模式</p><h4 id="哨兵模式的缺点"><a href="#哨兵模式的缺点" class="headerlink" title="哨兵模式的缺点"></a>哨兵模式的缺点</h4><ul><li>当master挂掉的时候，sentinel 会选举出来一个 master，选举的时候是没有办法去访问 Redis的，会存在访问瞬断的情况； </li><li>哨兵模式，对外只有master节点可以写，slave节点只能用于读。尽管Redis单节点最多支持 10W的QPS，但是在电商大促的时候，写数据的压力全部在master上。</li><li>Redis的单节点内存不能设置过大，若数据过大在主从同步将会很慢；在节点启动的时候，时间特别长；</li></ul><p>最大缺点：哨兵选举期间，不能对外提供服务</p><p><img src="/2022/04/25/redis-bi-ji/image-20220425195649429.png" alt="image-20220425195649429"></p><h5 id="Redis集群的优点"><a href="#Redis集群的优点" class="headerlink" title="Redis集群的优点"></a>Redis集群的优点</h5><ul><li>Redis集群有多个master，可以减小访问瞬断问题的影响 </li><li>Redis集群有多个master，可以提供更高的并发量　 </li><li>Redis集群可以分片存储，这样就可以存储更多的数据</li></ul><h4 id="Cluster模式搭建"><a href="#Cluster模式搭建" class="headerlink" title="Cluster模式搭建"></a>Cluster模式搭建</h4><p>​        Redis的集群搭建最少需要3个master节点，我们这里搭建3个master，每个下面挂一个slave节点，总 共6个Redis节点；</p><p>​        直接复制虚拟机，docker复制过去三台redis机器，视频里是三台上传好jar包，然后xshell都连接上点一个发送到所有会话，然后进行编译安装</p><p>重启之后都出现一个问题，三步解决</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424135120486.png" alt="image-20220424135120486"></p><p>搭建机器为Redis-1、2、3  自动分配，所以是8.17 18 19这三个ip</p><p>先使用发送键盘输入的所有会话</p><p>然后创建redis目录下创建一个redis-cluster目录</p><p>里面再创建8001、8002两个目录</p><p>配置文件分别拷贝进去一份</p><p>接着进行修改</p><p>先改端口6379改为8001，然后开启后台运行（daemonize yes）</p><p>然后</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424140725656.png" alt="image-20220424140725656"></p><p>接着</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424140818190.png" alt="image-20220424140818190"></p><p>改一下Xshell编码，加一个注释</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141144801.png" alt="image-20220424141144801"></p><p>启动集群模式</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141249738.png" alt="image-20220424141249738"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141404202.png" alt="image-20220424141404202"></p><p>修改集群离线的超时时间</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141534159.png" alt="image-20220424141534159"></p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141637020.png" alt="image-20220424141637020"></p><p>继续，关闭保护模式</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141721657.png" alt="image-20220424141721657"></p><p>开启AOF</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424141752025.png" alt="image-20220424141752025"></p><p>要配密码自己配，我不搞</p><p>但是配了密码就要在下面加一个masterauth xxx</p><p>拷贝一份去8002，修改  g就是全局修改</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424142748129.png" alt="image-20220424142748129"></p><p>这样所有配置文件就都弄好了，关闭一下防火墙（我是一直都关了的）</p><p>然后就可以开始启动服务了，这样就启动好了6台</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424143103158.png" alt="image-20220424143103158"></p><p>看一下也没有问题</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424143154967.png" alt="image-20220424143154967"></p><p>这样准备工作就完事了，就不用发送到所有会话了</p><p>如果配置了密码，就要</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424143324043.png" alt="image-20220424143324043"></p><p>1的意思就是每一个master下面有一个slave</p><pre class=" language-none"><code class="language-none">./redis-cli --cluster create --cluster-replicas 1 192.168.8.17:8001 192.168.8.17:8002 192.168.8.18:8001 192.168.8.18:8002 192.168.8.19:8001 192.168.8.19:8002</code></pre><p>然后回车输入yes，看见两个绿的就说明cluster模式就已经创建成功了</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424143701248.png" alt="image-20220424143701248"></p><p>可以查看帮助</p><pre class=" language-none"><code class="language-none">./redis-cli --cluster help</code></pre><p>然后可以通过add-node一直去水平无限拓展添加节点</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424144014581.png" alt="image-20220424144014581"></p><p>还可以check查看集群状态</p><p>连进去看看，连接到某一个连接</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424144124446.png" alt="image-20220424144124446"></p><p>-c：以集群方式连接</p><p>-h：ip地址是哪</p><p>-p：端口号</p><p>查看集群信息</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424144329706.png" alt="image-20220424144329706"></p><p>16384就是槽</p><p>到现在cluster模式就搭建完成了</p><h4 id="Cluster模式原理分析"><a href="#Cluster模式原理分析" class="headerlink" title="Cluster模式原理分析"></a>Cluster模式原理分析</h4><p>​        Redis Cluster将所有数据划分为16384个slots(槽位)，每个节点负责其中一部分槽位。槽位的信息存储 于每个节点中。只有master节点会被分配槽位，slave节点不会分配槽位。</p><p>槽位定位算法： k1 &#x3D; 127001 </p><p>​        Cluster 默认会对 key 值使用 crc16 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位。 </p><p>​        HASH_SLOT &#x3D; CRC16(key) % 16384</p><p>看我添加完就给我自动切换机器</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424144942831.png" alt="image-20220424144942831"></p><p>要是不在这个槽位，他就获取不到</p><p>我一获取，又给我自动切换了19的机器</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424145128067.png" alt="image-20220424145128067"></p><p>想把一堆数据放到同一个槽位里该怎么做？？</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424145736419.png" alt="image-20220424145736419"></p><p>获取也要加括号</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424145853865.png" alt="image-20220424145853865"></p><h5 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h5><p>myself代表就是当前连接的</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424150008375.png" alt="image-20220424150008375"></p><p>现在来干掉17的master</p><p>lsof -i:8001</p><p>kill -9 PID</p><p>然后去另一台机器上查看</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424150249548.png" alt="image-20220424150249548"></p><p>然后18的两个都是master了</p><h4 id="Java操作Redis集群"><a href="#Java操作Redis集群" class="headerlink" title="Java操作Redis集群"></a>Java操作Redis集群</h4><p>就是现在是cluster的集群</p><p>打开之前的redisdemo项目</p><pre class=" language-JAVA"><code class="language-JAVA">  @Test    public void clusterTest() &#123;        //构建Set集合保存redis节点        Set<HostAndPort> redisNodes = new HashSet<>();        redisNodes.add(new HostAndPort("192.168.8.17", 8001));        redisNodes.add(new HostAndPort("192.168.8.17", 8002));        redisNodes.add(new HostAndPort("192.168.8.18", 8001));        redisNodes.add(new HostAndPort("192.168.8.18", 8002));        redisNodes.add(new HostAndPort("192.168.8.19", 8001));        redisNodes.add(new HostAndPort("192.168.8.19", 8002));        //构建JedisCluster实例  建立连接        JedisCluster jedisCluster = new JedisCluster(redisNodes);        //添加元素//        jedisCluster.set("name","JueJue");        System.out.println(jedisCluster.get("name"));    &#125;</code></pre><p>针对Jedis完事</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424151219473.png" alt="image-20220424151219473"></p><p>针对Springdata-redis</p><p>新建一个springboot项目</p><p>添加lombok和redis依赖</p><p>直接去把之前的配置文件拿过来改一下</p><pre class=" language-properties"><code class="language-properties"><span class="token comment" spellcheck="true">#Redis服务器连接地址</span><span class="token attr-name">spring.redis.host</span><span class="token punctuation">=</span><span class="token attr-value">192.168.8.11</span><span class="token comment" spellcheck="true">#Redis服务器连接端口</span><span class="token attr-name">spring.redis.port</span><span class="token punctuation">=</span><span class="token attr-value">6379</span><span class="token comment" spellcheck="true">#连接池最大连接数（使用负值表示没有限制）</span><span class="token attr-name">spring.redis.pool.max-active</span><span class="token punctuation">=</span><span class="token attr-value">8</span><span class="token comment" spellcheck="true">#连接池最大阻塞等待时间（使用负值表示没有限制）</span><span class="token attr-name">spring.redis.pool.max-wait</span><span class="token punctuation">=</span><span class="token attr-value">-1</span><span class="token comment" spellcheck="true">#连接池中的最大空闲连接</span><span class="token attr-name">spring.redis.pool.max-idle</span><span class="token punctuation">=</span><span class="token attr-value">8</span><span class="token comment" spellcheck="true">#连接池中的最小空闲连接</span><span class="token attr-name">spring.redis.pool.min-idle</span><span class="token punctuation">=</span><span class="token attr-value">0</span><span class="token comment" spellcheck="true">#连接超时时间（毫秒）</span><span class="token attr-name">spring.redis.timeout</span><span class="token punctuation">=</span><span class="token attr-value">30000</span></code></pre><p>就是原来是单机，现在改成cluster.nodes</p><pre class=" language-properties"><code class="language-properties"><span class="token comment" spellcheck="true">#Redis服务器连接地址</span><span class="token attr-name">spring.redis.cluster.nodes</span><span class="token punctuation">=</span><span class="token attr-value">192.168.8.17:8001,192.168.8.17:8002,192.168.8.18:8001,192.168.8.18:8002,192.168.8.19:8001,192.168.8.19:8002</span><span class="token comment" spellcheck="true">#Redis服务器连接端口</span><span class="token attr-name">spring.redis.port</span><span class="token punctuation">=</span><span class="token attr-value">6379</span><span class="token comment" spellcheck="true">#连接池最大连接数（使用负值表示没有限制）</span><span class="token attr-name">spring.redis.pool.max-active</span><span class="token punctuation">=</span><span class="token attr-value">8</span><span class="token comment" spellcheck="true">#连接池最大阻塞等待时间（使用负值表示没有限制）</span><span class="token attr-name">spring.redis.pool.max-wait</span><span class="token punctuation">=</span><span class="token attr-value">-1</span><span class="token comment" spellcheck="true">#连接池中的最大空闲连接</span><span class="token attr-name">spring.redis.pool.max-idle</span><span class="token punctuation">=</span><span class="token attr-value">8</span><span class="token comment" spellcheck="true">#连接池中的最小空闲连接</span><span class="token attr-name">spring.redis.pool.min-idle</span><span class="token punctuation">=</span><span class="token attr-value">0</span><span class="token comment" spellcheck="true">#连接超时时间（毫秒）</span><span class="token attr-name">spring.redis.timeout</span><span class="token punctuation">=</span><span class="token attr-value">30000</span></code></pre><p>一样也是可以的没难度的</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424152043208.png" alt="image-20220424152043208"></p><h2 id="Redis企业级解决方案"><a href="#Redis企业级解决方案" class="headerlink" title="Redis企业级解决方案"></a>Redis企业级解决方案</h2><h3 id="Redis脑裂"><a href="#Redis脑裂" class="headerlink" title="Redis脑裂"></a>Redis脑裂</h3><p>出现在哨兵模式中</p><p>就是由于网络的原因，Master、Slave、Sentinel有延迟了</p><p>Sentinel问Master你还好吗，宕机没有，master不理，问了几次之后没理，就当你宕机，把slave重新升级成master，然后过一会网络好了，就有两个master，一山不容二虎，这就是redis脑裂问题，就是有两个master</p><h4 id="什么是Redis的集群脑裂"><a href="#什么是Redis的集群脑裂" class="headerlink" title="什么是Redis的集群脑裂"></a>什么是Redis的集群脑裂</h4><p>​        Redis的集群脑裂是指因为网络问题，导致Redis Master节点跟Redis slave节点和Sentinel集群处于不同 的网络分区，此时因为sentinel集群无法感知到master的存在，所以将slave节点提升为master节点。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424185227126.png" alt="image-20220424185227126"></p><h5 id="注意：-3"><a href="#注意：-3" class="headerlink" title="注意："></a>注意：</h5><p>此时存在两个不同的master节点，就像一个大脑分裂成了两个。集群脑裂问题中，如果客户端还 在基于原来的master节点继续写入数据，那么新的Master节点将无法同步这些数据，当网络问题 解决之后，sentinel集群将原先的Master节点降为slave节点，此时再从新的master中同步数据， 将会造成大量的数据丢失。</p><p>那客户端是连接新的master还是连接旧的？</p><p>出现脑裂现象会出现什么问题？</p><p>​        就是当Sentinel切换新master，新master就有写的功能，那有数据保存到新的master，原来的master是不是就会丢失一些数据</p><p>​    <strong>以后都可以这样理解，脑裂就是出现了两个主节点，解决方案不同技术不一样</strong></p><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>配置两个参数就可以</p><p>redis.conf配置参数：</p><pre class=" language-none"><code class="language-none">min-replicas-to-write 1min-replicas-max-lag 5</code></pre><h5 id="参数：-2"><a href="#参数：-2" class="headerlink" title="参数："></a>参数：</h5><p>第一个参数表示最少的slave节点为1个 </p><p>第二个参数表示数据复制和同步的延迟不能超过5秒</p><p><strong>配置了这两个参数：如果发生脑裂原Master会在客户端写入操作的时候拒绝请求。这样可以避免大量数据丢失。</strong></p><h3 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h3><h4 id="缓存冷启动"><a href="#缓存冷启动" class="headerlink" title="缓存冷启动"></a>缓存冷启动</h4><p>​        缓存中没有数据，由于缓存冷启动一点数据都没有，如果直接就对外提供服务了，那么并发量上来 Mysql就裸奔挂掉了。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424185419139.png" alt="image-20220424185419139"></p><p>缓存中没有数据，直接对外服务并发量上来数据库一下就挂掉</p><p>提前在redis放缓存就是缓存预热</p><h4 id="缓存冷启动场景"><a href="#缓存冷启动场景" class="headerlink" title="缓存冷启动场景"></a>缓存冷启动场景</h4><p>​        新启动的系统没有任何缓存数据，在缓存重建数据的过程中，系统性能和数据库负载都不太好，所以最 好是在系统上线之前就把要缓存的热点数据加载到缓存中，这种缓存预加载手段就是缓存预热</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424185449907.png" alt="image-20220424185449907"></p><h4 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h4><ul><li>提前给redis中灌入部分数据，再提供服务 </li><li>如果数据量非常大，<strong>就不可能将所有数据都写入redis</strong>，因为数据量太大了，第一是因为耗费的时间太长了，第二根本redis容纳不下所有的数据 </li><li>需要根据当天的具体访问情况，实时<strong>统计出访问频率较高的热数据</strong> </li><li>然后将访问频率较高的热数据写入redis中，肯定是热数据也比较多，我们也得多个服务并行读取数据去写，并行的分布式的缓存预热</li></ul><p><img src="/2022/04/25/redis-bi-ji/image-20220424185606718.png" alt="image-20220424185606718"></p><p>​        lua语言把Nginx日志直接发给消息中间件（只是一种解决方案），然后通过Storm（实时框架）统计访问次数,然后根据结果将热门的加到缓存中就好了</p><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p><img src="/2022/04/25/redis-bi-ji/image-20220424185709595.png" alt="image-20220424185709595"></p><p>缓存穿透就是用户对不存在的数据发起请求</p><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>​        <strong>缓存穿透是指缓存和数据库中都没有的数据</strong>，而用户不断发起请求，如发起为id为“-1”的数据或id为特别 大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。</p><h6 id="解释："><a href="#解释：" class="headerlink" title="解释："></a>解释：</h6><p>​        缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查 询）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。</p><h4 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h4><p><strong>1.对空值缓存：</strong>如果一个查询返回的数据为空（不管数据是否存在），我们仍然把这个空结果缓存， 设置空结果的过期时间会很短，最长不超过5分钟。</p><p><strong>2.布隆过滤器：</strong>如果想判断一个元素是不是在一个集合里，一般想到的是将集合中所有元素保存起来，然后通过比较确定。</p><h5 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h5><p>–byte数组实现</p><p>​        布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效 地插入和查询，可以用来告诉你 “某样东西一定不存在或者可能存在”。</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424185908110.png" alt="image-20220424185908110"></p><p>​    比如先放了个西瓜和香蕉，苹果不存在，但是它的hash值和对上了</p><p>注意： 布隆说不存在一定不存在，布隆说存在你要小心了，它有可能不存在。</p><h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><p>引入hutool包  </p><pre class=" language-xml"><code class="language-xml">   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>cn.hutool<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hutool-all<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.7.17<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></code></pre><p>可以在项目启动的时候把所有商品的id查询出来放进去布隆过滤器里面</p><pre class=" language-JAVA"><code class="language-JAVA">@Testpublic void FilterTest()&#123;    //初始化    BitMapBloomFilter bitMapBloomFilter = new BitMapBloomFilter(10);    //添加元素    bitMapBloomFilter.add("abc");    bitMapBloomFilter.add("123");    bitMapBloomFilter.add("juejue");    bitMapBloomFilter.add("qwe");    System.out.println(bitMapBloomFilter.contains("789"));    System.out.println(bitMapBloomFilter.contains("abc"));&#125;</code></pre><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>缓存击穿是指缓存中没有但数据库中有的单条数据</p><h5 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h5><p>​        某一个热点 key，在缓存过期的一瞬间，同时有大量的请求打进来，由于此时缓存过期了，所以请求最 终都会走到数据库，造成瞬时数据库请求量大、压力骤增，甚至可能打垮数据库。</p><h4 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h4><p><strong>1.互斥锁：</strong></p><p>​    在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程 拿不到锁就阻塞等着，等到第一个线程将数据写入缓存后，其他线程直接查询缓存。 </p><p><strong>2.热点数据不过期：</strong></p><p>​    直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存。</p><h5 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h5><pre class=" language-JAVA"><code class="language-JAVA">/** * 互斥锁解决缓存击穿 * * @param key 商品key */@Testpublic String lock(String key) throws InterruptedException &#123;    //获取key的值    String value = jedis.get(key);    //判断缓存是否过期    if (value == null) &#123;        //设置3分钟的超时时间，只有key不存在时候才能创建        Long setnx = jedis.setnx(key + "_mutex", "6");        //设置过期时间        jedis.pexpire(key + "_mutex", 3 * 60);        //设置成功        if (setnx == 1) &#123;            //DB操作            value = "db";            //保存缓存            jedis.setex(key,3*60,value);            jedis.del(key + "_mutex");            return value;        &#125;else &#123;            // 这个时候代表同时操作的其他线程已经load db并设置缓存了。 需要重新重新获取缓存            Thread.sleep(5000);            //重试            return lock(key);        &#125;    &#125;else &#123;        return value;    &#125;&#125;</code></pre><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>​    缓存雪崩发生时说明缓存中大批量的数据过期，而查询量巨大，请求直接到达数据库，造成数据库压力倍增</p><h5 id="概念-2"><a href="#概念-2" class="headerlink" title="概念"></a>概念</h5><p>​        缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发 到DB，DB瞬时压力过重雪崩。</p><p>缓存正常从Redis中获取，示意图如下：</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424195855987.png" alt="image-20220424195855987"></p><p>缓存失效瞬间示意图如下：</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424195913256.png" alt="image-20220424195913256"></p><h5 id="解决方案-3"><a href="#解决方案-3" class="headerlink" title="解决方案"></a>解决方案</h5><ul><li><strong>过期时间打散：</strong>既然是大量缓存集中失效，那最容易想到就是让他们不集中生效。可以给缓存的过 期时间时加上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。 </li><li><strong>热点数据不过期：</strong>该方式和缓存击穿一样，也是要着重考虑刷新的时间间隔和数据异常如何处理的情况。</li><li><strong>加互斥锁:</strong> 该方式和缓存击穿一样，按 key 维度加锁，对于同一个 key，只允许一个线程去计算， 其他线程原地阻塞等待第一个线程的计算结果，然后直接走缓存即可。</li></ul><h6 id="加锁排队代码"><a href="#加锁排队代码" class="headerlink" title="加锁排队代码"></a>加锁排队代码</h6><pre class=" language-JAVA"><code class="language-JAVA">/** * 互斥锁解决缓存击穿 * * @param key 商品key */@Testpublic String lock(String key) throws InterruptedException &#123;    //获取key的值    String value = jedis.get(key);    //判断缓存是否过期    if (value == null) &#123;        //设置3分钟的超时时间，只有key不存在时候才能创建        Long setnx = jedis.setnx(key + "_mutex", "6");        //设置过期时间        jedis.pexpire(key + "_mutex", 3 * 60);        //设置成功        if (setnx == 1) &#123;            //DB操作            value = "db";            //保存缓存            jedis.setex(key,3*60,value);            jedis.del(key + "_mutex");            return value;        &#125;else &#123;            Thread.sleep(5000);            //重试            return lock(key);        &#125;    &#125;else &#123;        return value;    &#125;&#125;</code></pre><h3 id="Redis开发规范"><a href="#Redis开发规范" class="headerlink" title="Redis开发规范"></a>Redis开发规范</h3><h4 id="key设计技巧"><a href="#key设计技巧" class="headerlink" title="key设计技巧"></a>key设计技巧</h4><ul><li>1、把表名转换为key前缀，如 tag: </li><li>2、把第二段放置用于区分key的字段，对应msyql中主键的列名，如 user_id </li><li>3、第三段放置主键值，如 2,3,4 </li><li>4、第四段写存储的列名</li></ul><h5 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h5><pre><code># 表名 主键 主键值 存储列名字set user:user_id:1:name JueJueset user:user_id:1:age 20#查询这个用户keys user:user_id:9*</code></pre><p>冒号的方式你打开管理工具看缓存就有层级目录</p><p><img src="/2022/04/25/redis-bi-ji/image-20220424170722693.png" alt="image-20220424170722693"></p><p><strong>要是有业务的话，在表名前面加一个业务名就可以</strong></p><h4 id="value设计"><a href="#value设计" class="headerlink" title="value设计"></a>value设计</h4><h5 id="拒绝bigkey"><a href="#拒绝bigkey" class="headerlink" title="拒绝bigkey"></a>拒绝bigkey</h5><p>​        防止网卡流量、慢查询，string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。</p><h4 id="命令使用"><a href="#命令使用" class="headerlink" title="命令使用"></a>命令使用</h4><h5 id="1、禁用命令"><a href="#1、禁用命令" class="headerlink" title="1、禁用命令"></a>1、禁用命令</h5><p>​        禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐 进式处理。 </p><h5 id="2、合理使用select"><a href="#2、合理使用select" class="headerlink" title="2、合理使用select"></a>2、合理使用select</h5><p>​        redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线 程处理，会有干扰。</p><h5 id="3、使用批量操作提高效率"><a href="#3、使用批量操作提高效率" class="headerlink" title="3、使用批量操作提高效率"></a>3、使用批量操作提高效率</h5><h6 id="原生命令："><a href="#原生命令：" class="headerlink" title="原生命令："></a>原生命令：</h6><p>​    例如mget、mset。 </p><h6 id="非原生命令："><a href="#非原生命令：" class="headerlink" title="非原生命令："></a>非原生命令：</h6><p>​    可以使用pipeline提高效率。pipeline方式，就很快</p><h6 id="注意：-4"><a href="#注意：-4" class="headerlink" title="注意："></a>注意：</h6><p>​    但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。</p><h5 id="4、不建议过多使用Redis事务功能"><a href="#4、不建议过多使用Redis事务功能" class="headerlink" title="4、不建议过多使用Redis事务功能"></a>4、不建议过多使用Redis事务功能</h5><p>​    Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot 上。</p><p>集群版本要求就是在一个槽上</p><h4 id="客户端使用"><a href="#客户端使用" class="headerlink" title="客户端使用"></a>客户端使用</h4><p>1.Jedis ：<a href="https://github.com/xetorthio/jedis">https://github.com/xetorthio/jedis</a> 重点推荐 </p><p>2.Spring Data redis ：<a href="https://github.com/spring-projects/spring-data-redis">https://github.com/spring-projects/spring-data-redis</a> 使用Spring框架时推荐 3.Redisson ：<a href="https://github.com/mrniko/redisson">https://github.com/mrniko/redisson</a> 分布式锁、阻塞队列的时重点推荐 </p><h6 id="1、避免多个应用使用一个Redis实例"><a href="#1、避免多个应用使用一个Redis实例" class="headerlink" title="1、避免多个应用使用一个Redis实例"></a>1、避免多个应用使用一个Redis实例</h6><p>​    不相干的业务拆分，公共数据做服务化。 </p><h6 id="2、使用连接池"><a href="#2、使用连接池" class="headerlink" title="2、使用连接池"></a>2、使用连接池</h6><p>​    可以有效控制连接，同时提高效率，标准使用方式:</p><pre class=" language-JAVA"><code class="language-JAVA">执行命令如下：Jedis jedis = null;try &#123;    jedis = jedisPool.getResource();//具体的命令    jedis.executeCommand()&#125; catch (Exception e) &#123;    logger.error("op key &#123;&#125; error: " + e.getMessage(), key, e);&#125; finally &#123;//注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。if (jedis != null)    jedis.close();&#125;</code></pre><h3 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h3><p><img src="/2022/04/25/redis-bi-ji/image-20220424202532521.png" alt="image-20220424202532521"></p><p>就是查缓存了查笔记本，然后同时又有请求去修改这个笔记本，所以这就数据不一致了</p><p>缓存说明： 从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。</p><p><strong>缓存不一致理论上来说是可以设置过期时间来保证一致性的；越短越能保证</strong></p><h4 id="三种更新策略"><a href="#三种更新策略" class="headerlink" title="三种更新策略"></a>三种更新策略</h4><ul><li>先更新数据库，再更新缓存 </li><li>先删除缓存，再更新数据库 </li><li>先更新数据库，再删除缓存</li></ul><p>我们还是得以数据库中的数据为准</p><h5 id="先更新数据库，再更新缓存"><a href="#先更新数据库，再更新缓存" class="headerlink" title="先更新数据库，再更新缓存"></a>先更新数据库，再更新缓存</h5><p>这套方案，大家是普遍反对的。为什么呢？ </p><h6 id="线程安全角度"><a href="#线程安全角度" class="headerlink" title="线程安全角度"></a>线程安全角度</h6><p>同时有请求A和请求B进行更新操作，那么会出现 </p><p>（1）线程A更新了数据库 </p><p>（2）线程B更新了数据库 </p><p>（3）线程B更新了缓存 </p><p>（4）线程A更新了缓存 这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。 这就导致了脏数据，因此不考虑。</p><h5 id="先删缓存，再更新数据库"><a href="#先删缓存，再更新数据库" class="headerlink" title="先删缓存，再更新数据库"></a>先删缓存，再更新数据库</h5><p>​    该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出 现如下情形: </p><p>（1）请求A进行写操作，删除缓存 </p><p>（2）请求B查询发现缓存不存在 </p><p>（3）请求B去数据库查询得到旧值 </p><p>（4）请求B将旧值写入缓存 </p><p>（5）请求A将新值写入数据库 </p><p>注意： </p><p>该数据永远都是脏数据。</p><h5 id="先更新数据库，再延时删缓存-正解"><a href="#先更新数据库，再延时删缓存-正解" class="headerlink" title="先更新数据库，再延时删缓存(正解)"></a>先更新数据库，再延时删缓存(正解)</h5><p><img src="/2022/04/25/redis-bi-ji/image-20220424204451253.png" alt="image-20220424204451253"></p><p>这种情况存在并发问题吗？ </p><p>（1）缓存刚好失效 </p><p>（2）请求A查询数据库，得一个旧值 </p><p>（3）请求B将新值写入数据库 </p><p>（4）请求B删除缓存 </p><p>（5）请求A将查到的旧值写入缓存</p><p>发生这种情况的概率又有多少? </p><p>​        发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗 时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快 于写操作的，因此步骤（3）耗时比步骤（2）更短，这一情形很难出现</p><p>加过期时间</p><p>先更新数据库，在删除缓存，而且删除缓存是延时的删除缓存</p><p>就是缓存添加成功后等个1s再删掉</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FastDFS笔记</title>
      <link href="/2022/04/19/fastdfs-bi-ji/"/>
      <url>/2022/04/19/fastdfs-bi-ji/</url>
      
        <content type="html"><![CDATA[<hr><h1 id="FastDFS"><a href="#FastDFS" class="headerlink" title="FastDFS"></a>FastDFS</h1><p>分布式文件系统</p><h4 id="为什么要使用？"><a href="#为什么要使用？" class="headerlink" title="为什么要使用？"></a>为什么要使用？</h4><h5 id="单机时代"><a href="#单机时代" class="headerlink" title="单机时代"></a>单机时代</h5><p>​    我们通常直接在项目目录下建立静态资源文件夹，用于存放项目中的文件资源，然后还可以按不同类型建立不同子目录比如resource&#x2F;img、resource&#x2F;file</p><p>优点：方便</p><p>缺点：文件越多越混乱</p><h5 id="独立文件服务器"><a href="#独立文件服务器" class="headerlink" title="独立文件服务器"></a>独立文件服务器</h5><p>引入一个独立图片服务器</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419135816244.png" alt="image-20220419135816244"></p><p>流程： 项目上传文件时，首先通过ftp或者ssh将文件上传到图片服务器 的某个目录下，再通过Ngnix或者Apache来访问此目录下的文 件，返回一个独立域名的图片URL地址，前端使用文件时就通过 这个URL地址读取。</p><h5 id="分布式文件系统"><a href="#分布式文件系统" class="headerlink" title="分布式文件系统"></a>分布式文件系统</h5><p>​        业务发展，单台服务器存储和响应也很快到达了瓶颈，新的业 务需要文件访问具有高响应性、高可用性来支持系统。</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419135910310.png" alt="image-20220419135910310"></p><h6 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h6><ul><li>扩展能力: 毫无疑问，扩展能力是一个分布式文件系统最重要的特点； </li><li>高可用性: 在分布式文件系统中，高可用性包含两层，一是整个文件系统的可用性，二是数据 的完整和一致性； </li><li>弹性存储: 可以根据业务需要灵活地增加或缩减数据存储以及增删存储池中的资源，而不需要 中断系统运行。</li></ul><h6 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h6><p>​        系统复杂度稍高，需要更多服务器</p><p>独立文件服务器缺点：容灾、单点故障、垂直扩展稍差</p><p>分布式文件系统缺点：系统复杂度稍高</p><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>FastDFS是一个开源的轻量级分布式文件系统。它解决了大数据量 存储和负载均衡等问题。特别适合以中小文件（建议范围：4KB &lt; file_size &lt;500MB）为载体的在线服务，如相册网站、视频网站等等。</p><p>FastDFS特性： </p><ul><li>文件不分块存储，上传的文件和OS文件系统中的文件一一对应 </li><li>支持相同内容的文件只保存一份，节约磁盘空间 </li><li>下载文件支持HTTP协议，可以使用内置Web Server，也可以和其他Web Server配合使用 </li><li>支持在线扩容 </li><li>支持主从文件</li></ul><h4 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h4><p>FastDFS服务端有三个角色：跟踪服务器（&#x3D;&#x3D;tracker&#x3D;&#x3D;）、存储服务器 （storage）和客户端（client）。</p><h5 id="tracker"><a href="#tracker" class="headerlink" title="tracker"></a>tracker</h5><p>​        跟踪服务器，主要做调度工作，起负载均衡的作用。在内存中记录 集群中所有存储组和存储服务器的状态信息，是客户端和数据服务 器交互的枢纽。 </p><h5 id="storage"><a href="#storage" class="headerlink" title="storage"></a>storage</h5><p>​        存储服务器（又称：存储节点或数据服务器），文件和文件属性 （meta data）都保存到存储服务器上。Storage server直接利用 OS的文件系统调用管理文件。 </p><h5 id="client"><a href="#client" class="headerlink" title="client"></a>client</h5><p>​        客户端，作为业务请求的发起方，通过专有接口，使用TCP&#x2F;IP协议 与跟踪器服务器或存储节点进行数据交互。FastDFS向使用者提供 基本文件访问接口，比如upload、download、append、delete 等，以客户端库的方式提供给用户使用。 </p><h5 id="group"><a href="#group" class="headerlink" title="group"></a>group</h5><p>​        组， 也可称为卷。 同组内服务器上的文件是完全相同的 ，同一组 内的storage server之间是对等的， 文件上传、 删除等操作可以在 任意一台storage server上进行 。</p><h5 id="流程："><a href="#流程：" class="headerlink" title="流程："></a>流程：</h5><p>​        Tracker相当于FastDFS的大脑，不论是上传还是下载都是通过 tracker来分配资源；客户端一般可以使用Ngnix等静态服务器 来调用或者做一部分的缓存；存储服务器内部分为卷（或者叫 做组），卷于卷之间是平行的关系，可以根据资源的使用情况 随时增加，卷内服务器文件相互同步备份，以达到容灾的目的。</p><h4 id="上传机制"><a href="#上传机制" class="headerlink" title="上传机制"></a>上传机制</h4><p>​        首先客户端请求Tracker服务获取到存储服务器的ip地址和端口，然后客户端根据返回的IP地址和端口号请求上传文件，存储服务器接 收到请求后生产文件，并且将文件内容写入磁盘并返回给客户端 file_id、路径信息、文件名等信息，客户端保存相关信息上传完毕。</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419140919363.png" alt="image-20220419140919363"></p><p>内部机制如下 </p><h5 id="1、选择Tracker-server"><a href="#1、选择Tracker-server" class="headerlink" title="1、选择Tracker server"></a>1、选择Tracker server</h5><p>当集群中不止一个Tracker server时，由于Tracker之间是完全对等 的关系，客户端在upload文件时可以任意选择一个trakcer。 </p><h5 id="2、选择Storage-server"><a href="#2、选择Storage-server" class="headerlink" title="2、选择Storage server"></a>2、选择Storage server</h5><p>当选定Group后，Tracker会在Group内选择一个Storage Server给 客户端 </p><h5 id="3、选择Storage"><a href="#3、选择Storage" class="headerlink" title="3、选择Storage"></a>3、选择Storage</h5><p>path 当分配好Storage Server后，客户端将向Storage发送写文件请求， Storage将会为文件分配一个数据存储目录。</p><p>注意： &#x3D;&#x3D;剩余存储空间最多的优先。&#x3D;&#x3D;</p><h5 id="4、生成Fileid"><a href="#4、生成Fileid" class="headerlink" title="4、生成Fileid"></a>4、生成Fileid</h5><p>​        选定存储目录之后，Storage会为文件生一个Fileid，由Storage Server Ip、文件创建时间、文件大小、文件crc32和一个随机数拼接而成，然后将这个二进制串进行base64编码，转换为可打印的字符串。</p><h5 id="5、生成文件名"><a href="#5、生成文件名" class="headerlink" title="5、生成文件名"></a>5、生成文件名</h5><p>当文件存储到某个子目录后，即认为该文件存储成功，接下来会为 该文件生成一个文件名，文件名由group、存储目录、两级子目 录、fileid、文件后缀名（由客户端指定，主要用于区分文件类型） 拼接而成。</p><p>小总结：FastDFS上传文件成功后返回文件名由<strong>group、存储目录、两级子目录、fileid、文件后缀名</strong>组成</p><h4 id="下载机制"><a href="#下载机制" class="headerlink" title="下载机制"></a>下载机制</h4><p>​        客户端带上文件名信息请求Tracker服务获取到存储服务器的ip地址和端口，然后客户端根据返回的IP地址和端口号请求下载文件，存 储服务器接收到请求后返回文件给客户端。</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419141326561.png" alt="image-20220419141326561"></p><h6 id="内部机制如下"><a href="#内部机制如下" class="headerlink" title="内部机制如下"></a>内部机制如下</h6><p>1 client询问tracker下载文件的storage，参数为文件标识（组名和文件名） </p><p>2 tracker返回一台可用的storage </p><p> client直接和storage通讯完成文件下载</p><p>FastDFS分布式文件系统在下载文件的时候<strong>客户端带文件名请求</strong>&#x3D;&#x3D;Stroage&#x3D;&#x3D;</p><h3 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h3><p>准备安装在zk-03机器</p><p>下载安装GCC</p><pre class=" language-none"><code class="language-none">yum install gcc-c++ perl-devel pcre-devel openssl-devel zlib-devel wget</code></pre><p>传两文件过去</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418195342025.png" alt="image-20220418195342025"></p><p>V6是6.几的一个版本，V1是他的依赖包，都解压去&#x2F;usr&#x2F;local下</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418195755475.png" alt="image-20220418195755475"></p><p>然后也可以下载安装，我懒</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419141629434.png" alt="image-20220419141629434"></p><p>进去依赖包执行一下</p><pre class=" language-none"><code class="language-none">编译./make.sh安装./make.sh  install</code></pre><p>这样依赖就安装好了</p><p>然后去fastdfs目录下也重复编译安装步骤一次</p><p>复制配置文件</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418200724071.png" alt="image-20220418200724071"></p><h4 id="创建tracker服务"><a href="#创建tracker服务" class="headerlink" title="创建tracker服务"></a>创建tracker服务</h4><h5 id="创建tracker目录"><a href="#创建tracker目录" class="headerlink" title="创建tracker目录"></a>创建tracker目录</h5><p>mkdir -p &#x2F;data&#x2F;fastdfs&#x2F;tracker</p><h6 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h6><p>vim &#x2F;etc&#x2F;fdfs&#x2F;tracker.conf</p><p>搜索改目录并改端口</p><p>base_path&#x3D;&#x2F;data&#x2F;fastdfs&#x2F;tracker（需要预先创建）</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418201106850.png" alt="image-20220418201106850"></p><p>保存退出后</p><p>cd &#x2F;etc&#x2F;init.d&#x2F;</p><p>启动一下</p><p>.&#x2F;fdfs_trackerd start</p><p>检查tracker服务</p><p>netstat -lntup |grep fdfs</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418203414236.png" alt="image-20220418203414236"></p><h5 id="创建storage服务"><a href="#创建storage服务" class="headerlink" title="创建storage服务"></a>创建storage服务</h5><p>创建storage目录</p><pre class=" language-none"><code class="language-none">mkdir -p /data/fastdfs/storagemkdir -p /data/fastdfs/base</code></pre><p>修改配置文件</p><p>vim &#x2F;etc&#x2F;fdfs&#x2F;storage.conf</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418204336829.png" alt="image-20220418204336829"></p><p>然后搜serverport看一下是不是之前改的8888</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418204448189.png" alt="image-20220418204448189"></p><p>能看见两个角色就是启动成功</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418204647779.png" alt="image-20220418204647779"></p><p>还少一个客户端</p><p>修改Client配置文件</p><p>vim &#x2F;etc&#x2F;fdfs&#x2F;client.conf</p><p>然后也是改basepath和ip地址挤端口</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418204853250.png" alt="image-20220418204853250"></p><p>跟踪服务器要是有多台可以另一行</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220418204840508.png" alt="image-20220418204840508"></p><p>创建目录</p><p>mkdir -p &#x2F;data&#x2F;fastdfs&#x2F;client</p><h3 id="FastDFS指令"><a href="#FastDFS指令" class="headerlink" title="FastDFS指令"></a>FastDFS指令</h3><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419142215345.png" alt="image-20220419142215345"></p><p>运维用的多    </p><h5 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h5><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419085819688.png" alt="image-20220419085819688"></p><h6 id="指令参数"><a href="#指令参数" class="headerlink" title="指令参数"></a>指令参数</h6><pre class=" language-none"><code class="language-none">fdfs_upload_file <config_file> <local_filename> [storage_ip:port][store_path_index]</code></pre><h6 id="参数含义："><a href="#参数含义：" class="headerlink" title="参数含义："></a>参数含义：</h6><p>1  <config_file>：配置文件路径 </config_file></p><p>2  <local_filename>：本地文件路径 </local_filename></p><p>3  [storage_ip:port] ：（可选参数）</p><p>4 [store_path_index] ：（可选参数）</p><p>注意： 上传文件后会返回文件在FastDFS中的唯一文件标识，即卷名 +文件名</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419090048051.png" alt="image-20220419090048051"></p><h5 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h5><h6 id="指令参数-1"><a href="#指令参数-1" class="headerlink" title="指令参数"></a>指令参数</h6><pre class=" language-none"><code class="language-none">fdfs_download_file <config_file> <file_id> [local_filename] [<download_offset><download_bytes>]</code></pre><h6 id="参数含义：-1"><a href="#参数含义：-1" class="headerlink" title="参数含义："></a>参数含义：</h6><p>1   <config_file>：配置文件路径 </config_file></p><p>2   <file_id>：文件在FastDFS中的唯一文件标识，即卷名+文件名 </file_id></p><p>3  [local_filename] ：文件下载地址</p><p>4  <download_offset>：（可选参数）文件下载开始时间 </download_offset></p><p>5  <download_bytes>：（可选参数）文件下载的字节数</download_bytes></p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419091454103.png" alt="image-20220419091454103"></p><h5 id="查看文件信息指令"><a href="#查看文件信息指令" class="headerlink" title="查看文件信息指令"></a>查看文件信息指令</h5><h6 id="指令参数-2"><a href="#指令参数-2" class="headerlink" title="指令参数"></a>指令参数</h6><pre class=" language-none"><code class="language-none">fdfs_file_info <config_file> <file_id></code></pre><p>参数含义： </p><p>1   <config_file>：配置文件路径 </config_file></p><p>2  <file_id>：文件在FastDFS中的唯一文件标识，即卷名+文件名</file_id></p><h5 id="删除指令"><a href="#删除指令" class="headerlink" title="删除指令"></a>删除指令</h5><pre class=" language-none"><code class="language-none">fdfs_delete_file <config_file> <file_id></code></pre><p>含义同上</p><h6 id="注意"><a href="#注意" class="headerlink" title="注意:"></a>注意:</h6><pre><code> 删除指令使用后，文件在该卷中的所有备份都会被删除，因为 卷内的存储节点会相互同步，故慎用。</code></pre><h2 id="SpringBoot操作FastDFS"><a href="#SpringBoot操作FastDFS" class="headerlink" title="SpringBoot操作FastDFS"></a>SpringBoot操作FastDFS</h2><p>由GitHub大牛tobato在原作者发布的客户端基础上进行大量重构而来</p><h5 id="主要特性"><a href="#主要特性" class="headerlink" title="主要特性"></a>主要特性</h5><ul><li>1 对关键部分代码加入了单元测试，便于理解与服务端的接口交易，提高接口质量 </li><li>2 将以前对byte硬解析风格重构为使用对象+注解的形式，尽量增强了代码的可读性 </li><li>3 支持对服务端的连接池管理 </li><li>4 支持上传图片时候检查图片格式，并且自动生成缩略图 </li><li>5 在SpringBoot当中自动导入依赖</li></ul><pre class=" language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!--引入fastdfs依赖--></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.github.tobato<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>fastdfs-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.26.5<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></code></pre><p>直接写在测试里的</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian;import com.github.tobato.fastdfs.domain.fdfs.StorePath;import com.github.tobato.fastdfs.domain.proto.storage.DownloadByteArray;import com.github.tobato.fastdfs.service.FastFileStorageClient;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import java.io.*;@SpringBootTestclass FastdfsDemoApplicationTests &#123;    //fastdfs存储节点的客户端对象    @Autowired    private FastFileStorageClient fastFileStorageClient;    /**     * 测试springboot下javaAPI对分布式文件系统上传文件操作     */    @Test    public void testUpload() throws FileNotFoundException &#123;        //1.读取本地文件        File file = new File("J:\\login.jpg");        //2.创建传输文件的输入流        FileInputStream fileInputStream = new FileInputStream(file);        //3.文件上传        /**         * 第一个参数：输入文件内容的输入流         * 文件大小         * 文件拓展名         * 描述文件的元数据         */        StorePath storePath = fastFileStorageClient.uploadFile(fileInputStream, file.length(), "jpg", null);        //4.将卷名和文件名一起打印        System.out.println(storePath.getFullPath());        //5.将卷名和文件名分开打印        System.out.println("------------------------");        System.out.println(storePath.getGroup());        System.out.println(storePath.getPath());        //group1/M00/00/00/wKgIEGJeEt-ALjUOAAqFA9rZsJU238.jpg        //------------------------        //group1        //M00/00/00/wKgIEGJeEt-ALjUOAAqFA9rZsJU238.jpg    &#125;    /**     * springboot环境下JavaApi对分布式文件系统的下载文件操作     */    @Test    public void testDownload() throws IOException &#123;        //1.下载文件        /**         * 第一个参数：文件处于存储节点卷名         * 文件名         * 下载回调函数         */        byte[] bytes = fastFileStorageClient.downloadFile("group1", "M00/00/00/wKgIEGJeEt-ALjUOAAqFA9rZsJU238.jpg", new DownloadByteArray());        //2.创建文件输出流        FileOutputStream fileOutputStream = new FileOutputStream("J:\\aaa.jpg");        //3.使用文件输出流将文件内容字节数组写出去        fileOutputStream.write(bytes);        //4.刷新一下输出流        fileOutputStream.flush();        //5.关闭流        fileOutputStream.close();    &#125;&#125;</code></pre><p>上传</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419094059528.png" alt="image-20220419094059528"></p><p>下载</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419100121712.png" alt="image-20220419100121712"></p><h3 id="文件上传-基于FastDFS实现"><a href="#文件上传-基于FastDFS实现" class="headerlink" title="文件上传-基于FastDFS实现"></a>文件上传-基于FastDFS实现</h3><p>就是上传到FastDFS里，而不是放在项目的某个目录下</p><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.springframework.boot<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spring-boot-starter-thymeleaf<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.springframework.boot<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spring-boot-starter-web<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></code></pre><p>写个index.html</p><pre class=" language-html"><code class="language-html"><span class="token doctype">&lt;!DOCTYPE html></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>html</span> <span class="token attr-name">lang</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>en<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>head</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">charset</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>UTF-8<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>title</span><span class="token punctuation">></span></span>LikeU.Admin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>title</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>icon<span class="token punctuation">"</span></span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>favicon.ico<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">charset</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>utf-8<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">http-equiv</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>X-UA-Compatible<span class="token punctuation">"</span></span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>IE<span class="token punctuation">=</span>edge<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>meta</span> <span class="token attr-name">content</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>width<span class="token punctuation">=</span>device-width, initial-scale<span class="token punctuation">=</span>1, maximum-scale<span class="token punctuation">=</span>1, user-scalable<span class="token punctuation">=</span>no<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>viewport<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token comment" spellcheck="true">&lt;!--富文本编辑器wangEditor--></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>https://cdn.staticfile.org/wangEditor/10.0.13/wangEditor.min.css<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>https://cdn.staticfile.org/wangEditor/10.0.13/fonts/w-e-icon.woff<span class="token punctuation">"</span></span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>stylesheet<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>https://cdn.staticfile.org/wangEditor/10.0.13/wangEditor.min.js<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script language-javascript"></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>head</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>body</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>jumbotron<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>container<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>editor<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>欢迎使用富文本编辑器<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>button</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>btn btn-primary btn-lg<span class="token punctuation">"</span></span> <span class="token attr-name">id</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>btnGenCode<span class="token punctuation">"</span></span> <span class="token attr-name">role</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>button<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>保存 »<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>button</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>body</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>text/javascript<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token script language-javascript">    <span class="token keyword">var</span> E <span class="token operator">=</span> window<span class="token punctuation">.</span>wangEditor    <span class="token keyword">var</span> editor <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">E</span><span class="token punctuation">(</span><span class="token string">'#editor'</span><span class="token punctuation">)</span>       <span class="token comment" spellcheck="true">//配置服务端接口了</span>    editor<span class="token punctuation">.</span>customConfig<span class="token punctuation">.</span>uploadImgServer <span class="token operator">=</span><span class="token string">'/upload'</span>    <span class="token comment" spellcheck="true">//参数名字</span>    editor<span class="token punctuation">.</span>customConfig<span class="token punctuation">.</span>uploadFileName <span class="token operator">=</span><span class="token string">'file'</span>    <span class="token comment" spellcheck="true">//显示图片大小和类型</span>    editor<span class="token punctuation">.</span>customConfig<span class="token punctuation">.</span>uploadImgMaxSize <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token comment" spellcheck="true">//2M</span>    editor<span class="token punctuation">.</span>customConfig<span class="token punctuation">.</span>uploadImgAccept <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'jpg'</span><span class="token punctuation">,</span> <span class="token string">'jpeg'</span><span class="token punctuation">,</span> <span class="token string">'png'</span><span class="token punctuation">,</span> <span class="token string">'gif'</span><span class="token punctuation">,</span> <span class="token string">'bmp'</span><span class="token punctuation">,</span> <span class="token string">'webp'</span><span class="token punctuation">]</span>    editor<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">//以下是博客别人的写法</span>    <span class="token comment" spellcheck="true">// 配置服务器端地址</span>    <span class="token comment" spellcheck="true">//  editor.customConfig.uploadImgServer = 'http://localhost:8080/upload/editor'</span>    <span class="token comment" spellcheck="true">//配置指定文件名</span>    <span class="token comment" spellcheck="true">// editor.customConfig.uploadFileName = 'file'</span>    <span class="token comment" spellcheck="true">//如果图片不大，可以用base64存储</span>    <span class="token comment" spellcheck="true">//editor.customConfig.uploadImgShowBase64 = true</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>html</span><span class="token punctuation">></span></span></code></pre><p>wangEditor富文本编辑器</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419111505928.png" alt="image-20220419111505928"></p><p>配置</p><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true">#############分布式文件系统的配置#########</span><span class="token key atrule">fdfs</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">#超时时间</span>  <span class="token key atrule">connect-timeout</span><span class="token punctuation">:</span> <span class="token number">600</span>  <span class="token comment" spellcheck="true">#连接时间</span>  <span class="token key atrule">so-timeout</span><span class="token punctuation">:</span> <span class="token number">1500</span>  <span class="token key atrule">tracker-list</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> 192.168.8.16<span class="token punctuation">:</span><span class="token number">22122</span></code></pre><h6 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h6><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.controller;import com.github.tobato.fastdfs.domain.fdfs.StorePath;import com.github.tobato.fastdfs.service.FastFileStorageClient;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.multipart.MultipartFile;import java.io.IOException;/** * 图片控制层 */@RestControllerpublic class UploadController &#123;    //fastdfs存储节点的客户端对象    @Autowired    private FastFileStorageClient fastFileStorageClient;    /**     * 图片上传     * @param file     */    @PostMapping("/upload")//图片上传，必须post请求    public void upload(MultipartFile file) throws IOException &#123;        //1.判断文件是否为空        if(file!=null)&#123;            //2.获取上传图片名字            String filename = file.getOriginalFilename();            //3.图片后缀名 jpg            String fileSuffix = filename.substring(filename.lastIndexOf("."));            //4.上传图片            StorePath storePath = fastFileStorageClient.uploadFile(file.getInputStream(), file.getSize(), fileSuffix, null);            //5.上传成功返回图片路径            System.out.println(storePath.getFullPath());            //TODO 保存到数据库  jdbc  mybatis plus        &#125;    &#125;&#125;</code></pre><p>然后一次性上传图片限制的话，控制器就得是数组接收了</p><p>然后上传成功得有返回值，这就不整了，运行项目，上传图片，进去断点</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419143733498.png" alt="image-20220419143733498"></p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419111257653.png" alt="image-20220419111257653"></p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419111351266.png" alt="image-20220419111351266"></p><h2 id="FastDFS集成Nginx"><a href="#FastDFS集成Nginx" class="headerlink" title="FastDFS集成Nginx"></a>FastDFS集成Nginx</h2><p>Nginx服务器是一个高性能的web服务器与反向代理服务器。</p><p>当只有静态资源的时候我们也可以使用Nginx来作为服务器</p><h4 id="FastDFS集成Nginx的2个原因"><a href="#FastDFS集成Nginx的2个原因" class="headerlink" title="FastDFS集成Nginx的2个原因"></a>FastDFS集成Nginx的2个原因</h4><h5 id="1-为分布式文件系统提供Http服务支持"><a href="#1-为分布式文件系统提供Http服务支持" class="headerlink" title="1 为分布式文件系统提供Http服务支持"></a>1 为分布式文件系统提供Http服务支持</h5><p>​        通过Nginx的web服务代理访问分布式文件系统的存储节点，从而实现通过http请求访问存储节点资源。</p><h5 id="2-解决复制延迟问题"><a href="#2-解决复制延迟问题" class="headerlink" title="2 解决复制延迟问题"></a>2 解决复制延迟问题</h5><p>​        由于FastDFS的同卷的存储节点之间需要同步，当文件尚未同步完 成时，访问请求到达改节点，获取的数据将是未同步完的不完整数 据，即为复制延迟问题。通过Nginx检测请求的存储节点的数据， 若该存储节点的数据尚未同步完成，则将请求转发至数据的原存储 节点，从而解决复制延迟问题。</p><h3 id="环境搭建-1"><a href="#环境搭建-1" class="headerlink" title="环境搭建"></a>环境搭建</h3><p>我就懒直接传进去安装包</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419112455553.png" alt="image-20220419112455553"></p><h5 id="下载方式"><a href="#下载方式" class="headerlink" title="下载方式"></a>下载方式</h5><p>下载Fast DFS的Nginx模块包</p><pre class=" language-none"><code class="language-none">wget https://github.com/happyfish100/fastdfs-nginx-module/archive/V1.22.tar.gz</code></pre><p>下载Nginx软件包</p><pre class=" language-none"><code class="language-none">wget https://nginx.org/download/nginx-1.19.2.tar.gz</code></pre><p>解压到local下</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419112701751.png" alt="image-20220419112701751"></p><p>安装nginx依赖</p><pre class=" language-none"><code class="language-none">yum install -y gcc gcc-c++ zlib zlib-devel openssl openssl-devel pcre pcre-devel gd-devel epel-release</code></pre><p>检查</p><p>.&#x2F;configure –add-module&#x3D;&#x2F;usr&#x2F;local&#x2F;fastdfs-nginx-module-1.22&#x2F;src</p><p>make</p><p>make install</p><p>然后在这个nginx就可以使用这个模块了</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419132532506.png" alt="image-20220419132532506"></p><p>​    进去</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419132613471.png" alt="image-20220419132613471"></p><p>拷贝文件</p><pre class=" language-none"><code class="language-none">cp mime.types /etc/fdfs/cp http.conf /etc/fdfs/然后去/usr/local/fastdfs-nginx-module-1.22/srccp mod_fastdfs.conf /etc/fdfs/切换到/etc/fdfs/vim mod_fastdfs.conf </code></pre><p>改这个</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419133019512.png" alt="image-20220419133019512"></p><p>还有这服务器地址</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419133104343.png" alt="image-20220419133104343"></p><p>文件url中是否有group的名字</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419133129909.png" alt="image-20220419133129909"></p><p>还有这个</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419133224807.png" alt="image-20220419133224807"></p><p>切换目录</p><p>&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf</p><p>vim nginx.conf</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419133833315.png" alt="image-20220419133833315"></p><p>启动一下</p><p>.&#x2F;nginx -c &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419133959908.png" alt="image-20220419133959908"></p><p>安装一下lsof</p><p>yum install lsof</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419134134944.png" alt="image-20220419134134944"></p><h6 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h6><p>上传一张图片</p><p>先搞张图片放在opt下</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419134832345.png" alt="image-20220419134832345"></p><p>然后复制路径反手打开一个浏览器</p><p>然后就可以通过nginx+fastdfs访问网络上的图片资源</p><p><img src="/2022/04/19/fastdfs-bi-ji/image-20220419134948622.png" alt="image-20220419134948622"></p><h4 id><a href="#" class="headerlink" title></a></h4>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>springboot整合sawgger报错</title>
      <link href="/2022/04/13/springboot-zheng-he-sawgger-bao-cuo/"/>
      <url>/2022/04/13/springboot-zheng-he-sawgger-bao-cuo/</url>
      
        <content type="html"><![CDATA[<h4 id="报错内容"><a href="#报错内容" class="headerlink" title="报错内容"></a>报错内容</h4><p>Failed to start bean ‘documentationPluginsBootstrapper</p><p><strong>解决swagger空指针问题，或者springboot切换到2.6以下的版本</strong>，同样一模一样的代码，换了之后就可以</p><p><img src="/2022/04/13/springboot-zheng-he-sawgger-bao-cuo/image-20220307131609357.png" alt="image-20220307131609357"></p><p>​        一开始网上的各种解决方都试过了，比如依赖循环？？swagger依赖Google的guava，加一个最新版本的guava？编写swagger配置类？JDK问题？但是我用的是jdk1.8不会有问题的呀？？？</p>]]></content>
      
      
      <categories>
          
          <category> SpringBoot </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>恢复VMware左侧目录</title>
      <link href="/2022/04/13/hui-fu-wu-guan-vmware-zuo-ce-xu-ni-ji-mu-lu/"/>
      <url>/2022/04/13/hui-fu-wu-guan-vmware-zuo-ce-xu-ni-ji-mu-lu/</url>
      
        <content type="html"><![CDATA[<h5 id="或者点这里"><a href="#或者点这里" class="headerlink" title="或者点这里"></a>或者点这里</h5><p><img src="/2022/04/13/hui-fu-wu-guan-vmware-zuo-ce-xu-ni-ji-mu-lu/image-20220413195134345.png" alt="image-20220413195134345"></p><h6 id><a href="#" class="headerlink" title></a></h6>]]></content>
      
      
      <categories>
          
          <category> other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小失误 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dubbo笔记</title>
      <link href="/2022/04/13/dubbo-bi-ji/"/>
      <url>/2022/04/13/dubbo-bi-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="二、-Dubbo-架构讲解"><a href="#二、-Dubbo-架构讲解" class="headerlink" title="二、 Dubbo 架构讲解"></a>二、 Dubbo 架构讲解</h2><h3 id="1-架构图"><a href="#1-架构图" class="headerlink" title="1.架构图"></a>1.架构图</h3><p>Provider在运行时是要依赖于IOC容器的</p><p>1.发布 2.订阅</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220228185855334.png" alt="image-20220228185855334"></p><p>先把Spring启动，而且Provider；最终会缓存到Spring的IOC容器当中。Provider启动好以后，第二步，就是去注册中心（Registry）中注册，也叫服务的注册与发布，接下来就是启动Consumer（服务的消费者，也就是谁调用我们的Provider），然后Consumer启动时，就完成了架构图中的第二步，也就是服务的订阅。因为Consumer要去调用Provider，它肯定得知道Provider的一些信息（IP，端口，暴露的服务等），而这些信息，Provider启动的时候都已经放到了注册中心当中了，那Consumer启动去链接注册中心，从注册中心去订阅这些信息，那Consumer不就拿到或者已知了Ip地址和服务的名字是什么等。</p><p>3就是通知，之前说过zookeeper是有观察者模式的，当Provider发生变化之后就会通知我们的Consumer，那在Dubbo当中我们就可以使用zookeeper作为注册中心。那下面，4，当我们把Provider和Consumer都启动好了，Consumer就可以调用Provider的服务了，也就是实现invoke，唯独只有这一条线是实线，因为它调用时基于同步的方式来调用的。</p><p>再来说说，还记得学java时候，方法的调用有两种，一种是并发的，一种是串行化的，比如没有涉及到多线程编程，那所有的方法就是串行化的（就比如A调用B，A要等B执行完了之后回到调用点再往下走），要是基于多线程的方式，那多线程就不叫调用方法了，叫启动方法，就是一个线程启动方法，启动完不管，继续往下走再启动再往下走，也就是异步的方法调用。所以我们要知道Consumer在调用Provider的时候是同步的，那就会有一个线程阻塞的情况出现，也就是只有Provider的代码执行完了，Consumer才会继续往下执行。</p><p>那剩下就还有一个Monitor，作用就是监控中心，每隔 2 分钟 Consumer 和 Provider 会把数据包发送给 Monitor，所以它就能实时的知道他们两的服务的压力或者像服务的基本信息等，然后来对这些信息做一个统计。</p><h3 id="2-架构说明"><a href="#2-架构说明" class="headerlink" title="2 架构说明"></a>2 架构说明</h3><h5 id="2-1虚线"><a href="#2-1虚线" class="headerlink" title="2.1虚线"></a>2.1虚线</h5><p>虚线表示异步，实线表示同步。异步不阻塞线程性能高，同步阻塞线程必须等待响应结果才能继续执行，相对性能低。 </p><h5 id="2-2Provider"><a href="#2-2Provider" class="headerlink" title="2.2Provider"></a>2.2Provider</h5><p>暴露服务的服务提供方。 </p><h5 id="2-3Container"><a href="#2-3Container" class="headerlink" title="2.3Container"></a>2.3Container</h5><p>服务运行容器。Dubbo 完全基于 Spring 实现的。 </p><h5 id="2-4Registry"><a href="#2-4Registry" class="headerlink" title="2.4Registry"></a>2.4Registry</h5><p>服务注册与发现的注册中心。注册中心，放置所有 Provider 对外提供的信息。包含 Provider 的 IP，访问端口，访问遵守的协议，对外提供的接口，接口中有哪些方法等相关信 息。 </p><h5 id="2-5Consumer"><a href="#2-5Consumer" class="headerlink" title="2.5Consumer"></a>2.5Consumer</h5><p>调用远程服务的服务消费方。 </p><h5 id="2-6Monitor"><a href="#2-6Monitor" class="headerlink" title="2.6Monitor"></a>2.6Monitor</h5><p>统计服务的调用次调和调用时间的监控中心。监控中心，监控 Provider 的压力情况等。 每隔 2 分钟 Consumer 和 Provider 会把调用次数发送给 Monitor，由 Monitor 进行统计。 </p><h3 id="3-执行流程"><a href="#3-执行流程" class="headerlink" title="3 执行流程"></a>3 执行流程</h3><ol start="0"><li><p>start：启动 Spring 容器时会把 Provider 启动。 </p></li><li><p>register：把 Provider 相关信息注册到 Registry 里 </p></li><li><p>subscribe：Consumer 从 Registry 中订阅 Provider 的信息 </p></li><li><p>notify：通知给 Consumer </p></li><li><p>invoke：Consumer 根据 Registry 通知的信息进行调用 Provider 中方法。</p></li><li><p>count:Consumer 和 Provider 把调用次数信息异步发送给 Monitor 进行统计</p></li></ol><h2 id="三、-Dubbo-支持的协议"><a href="#三、-Dubbo-支持的协议" class="headerlink" title="三、 Dubbo 支持的协议"></a>三、 Dubbo 支持的协议</h2><h3 id="1-Dubbo-协议-官方推荐协议"><a href="#1-Dubbo-协议-官方推荐协议" class="headerlink" title="1 Dubbo 协议(官方推荐协议)"></a>1 Dubbo 协议(官方推荐协议)</h3><p>优点： </p><p>​    采用 NIO 复用单一长连接，并使用线程池并发处理请求，减少握手和加大并发效率， 性能较好（推荐使用） </p><p>缺点： </p><p>​    大文件上传时,可能出现问题(不使用 Dubbo 文件上传) </p><p>同步的调用方式，在做文件上传时，由于文件上传的容量比较大，就会导致调用的过程是非常耗时的，如果链接的时间很长，就可能会涉及到超时的一些问题，所以一般我们都不使用Dubbo来做文件上传，在Consumer就去做了，我们用Dubbo要做的是就是把上传的文件名保存到我们的数据库当中</p><h3 id="2-RMI-Remote-Method-Invocation-协议"><a href="#2-RMI-Remote-Method-Invocation-协议" class="headerlink" title="2 RMI(Remote Method Invocation)协议"></a>2 RMI(Remote Method Invocation)协议</h3><p>优点: </p><p>​    JDK 自带的能力。 </p><p>缺点: </p><p>​    偶尔连接失败. </p><h3 id="3-Hessian-协议"><a href="#3-Hessian-协议" class="headerlink" title="3 Hessian 协议"></a>3 Hessian 协议</h3><p>优点: </p><p>​    可与原生 Hessian 互操作，基于 HTTP 协议 </p><p>缺点:</p><p>​     需 hessian.jar 支持，http短链接的开销很大</p><p>Hessian，基于Http，就是A请求B，相应了，完事了，一会再请求，还得在再建立一次链接。那我们在使用Dubbo的时候使用哪种协议，就是使用官方推荐的Dubbo协议，来完成远程服务的一个调用</p><h2 id="四、-Dubbo-支持的注册中心"><a href="#四、-Dubbo-支持的注册中心" class="headerlink" title="四、 Dubbo 支持的注册中心"></a>四、 Dubbo 支持的注册中心</h2><h4 id="1-Zookeeper-官方推荐"><a href="#1-Zookeeper-官方推荐" class="headerlink" title="1 Zookeeper(官方推荐)"></a>1 Zookeeper(官方推荐)</h4><p>优点: 支持分布式.很多周边产品. </p><p>缺点: 受限于 Zookeeper 软件的稳定性。Zookeeper 是一款专门为分布式架构提供辅助型处 理的软件，稳定较优。 </p><h4 id="2-Multicast"><a href="#2-Multicast" class="headerlink" title="2 Multicast"></a>2 Multicast</h4><ol><li>优点: 去中心化,不需要单独安装软件. </li><li>缺点: Provider 和 Consumer 和 Registry 不能跨机房(路由)</li></ol><h4 id="3-Redis"><a href="#3-Redis" class="headerlink" title="3.Redis"></a>3.Redis</h4><ol><li>优点: 支持集群,性能高 </li><li>缺点: 要求服务器时间同步.否则可能出现集群失败问题.</li></ol><h4 id="4-Simple"><a href="#4-Simple" class="headerlink" title="4.Simple"></a>4.Simple</h4><ol><li>优点: 标准 RPC 服务.没有兼容问题 </li><li>缺点: 不支持集群</li></ol><h1 id="Dubbo概念-核心组件"><a href="#Dubbo概念-核心组件" class="headerlink" title="Dubbo概念_核心组件"></a>Dubbo概念_核心组件</h1><h4 id="注册中心Registry"><a href="#注册中心Registry" class="headerlink" title="注册中心Registry"></a>注册中心Registry</h4><p>Dubbo微服务体系中，注册中心是其核心组件之一。Dubbo通过 注册中心实现了分布式环境中各服务之间的注册与发现，是各个分 布式节点之间的纽带。</p><h5 id="其主要作用如下"><a href="#其主要作用如下" class="headerlink" title="其主要作用如下:"></a>其主要作用如下:</h5><p>动态加入：一个服务提供者通过注册中心可以动态地把自己暴露给其他消费者，无须消费者逐个去更新配置文件。 </p><p>动态发现：一个消费者可以动态地感知新的配置、路由规则和新的服务提供者，无须重启服务使之生效。 </p><p>动态调整：注册中心支持参数的动态调整，新参数自动更新到所有相关服务节点。 </p><p>统一配置：避免了本地配置导致每个服务的配置不一致问题。</p><p>常见的注册中心有zookeeper 、eureka、consul、etcd。</p><h4 id="服务提供者Provider"><a href="#服务提供者Provider" class="headerlink" title="服务提供者Provider"></a>服务提供者Provider</h4><p>服务的提供方 </p><h4 id="服务消费者Consumer"><a href="#服务消费者Consumer" class="headerlink" title="服务消费者Consumer"></a>服务消费者Consumer</h4><p>调用远程服务的服务消费方</p><h4 id="监控中心Monitor"><a href="#监控中心Monitor" class="headerlink" title="监控中心Monitor"></a>监控中心Monitor</h4><p>主要负责监控统计调用次数和调用时间等。</p><h3 id="配置开发环境-Zookeeper注册中心"><a href="#配置开发环境-Zookeeper注册中心" class="headerlink" title="配置开发环境_Zookeeper注册中心"></a>配置开发环境_Zookeeper注册中心</h3><p>这里就是在docker安装一个zookeeper了</p><p>docker拉去镜像</p><pre class=" language-none"><code class="language-none">docker pull zookeeper</code></pre><p>启动运行容器</p><p>docker run –name zk -d -p 2181:2181 zookeeper            </p><p>进入容器</p><p>docker exec -it zk &#x2F;bin&#x2F;bash</p><p>exec：在运行的容器厚葬执行命令</p><p>-it：交互式</p><p>然后进去bin一下客户端</p><p>.&#x2F;zkCli.sh 连接</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220411152821009.png" alt="image-20220411152821009">然后就可以Ctrl+c退出和exit退出容器了</p><h3 id="配置开发环境-管理控制台"><a href="#配置开发环境-管理控制台" class="headerlink" title="配置开发环境_管理控制台"></a>配置开发环境_管理控制台</h3><h5 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h5><p>Dubbo-admin管理平台，图形化的服务管理页面，安装时需要指定 注册中心地址，即可从注册中心中获取到所有的提供者&#x2F;消费者进行 配置管理。</p><p>还是使用docker来安装</p><h5 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h5><pre class=" language-bash"><code class="language-bash">docker pull docker.io/apache/dubbo-admin</code></pre><p>启动运行容器</p><pre class=" language-bash"><code class="language-bash">docker run -d \-p 9600:8080 -e admin.registry.address<span class="token operator">=</span>zookeeper://192.168.8.11:2181 -e admin.config-center<span class="token operator">=</span>zookeeper://192.168.8.11:2181 -e admin.metadata-report.address<span class="token operator">=</span>zookeeper://192.168.8.11:2181 --restart<span class="token operator">=</span>always docker.io/apache/dubbo-admin</code></pre><h5 id="参数："><a href="#参数：" class="headerlink" title="参数："></a>参数：</h5><p>–restart：always 容器退出时总是重启 </p><p>admin.registry.address：注册中心 </p><p>admin.config-center：配置中心 </p><p>admin.metadata-report.address：元数据中心</p><p>不是docker的话就特别复杂，通过docker就可以一键启动</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220411154623785.png" alt="image-20220411154623785"></p><h5 id="可视化界面"><a href="#可视化界面" class="headerlink" title="可视化界面"></a>可视化界面</h5><p><img src="/2022/04/13/dubbo-bi-ji/image-20220411154734327.png" alt="image-20220411154734327"></p><p>账号密码都是root</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220411155422661.png" alt="image-20220411155422661"></p><p>当然，服务现在还是没有的，因为dubbo还没开发服务</p><h2 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a>高级特性</h2><h3 id="地址缓存"><a href="#地址缓存" class="headerlink" title="地址缓存"></a>地址缓存</h3><p><strong>服务生产者地址会缓存</strong></p><p>面试的时候可能会问的</p><p>就是Dubbo注册中心挂了，服务是否可以正常访问？？</p><p>答：因为dubbo服务消费者在第一次调用时 ， 会将服务提供方地址缓存到本地 ，以后在调用则不会访问注册中心。服务提供者地址发生变化时，注册中心会通服务消费者。</p><p>可以手动去docker里面关掉zookeeper，会发现两个案例还是可以访问的</p><h3 id="超时时间域配置覆盖关系"><a href="#超时时间域配置覆盖关系" class="headerlink" title="超时时间域配置覆盖关系"></a>超时时间域配置覆盖关系</h3><p>超时机制也是保护服务的一种手段</p><p>就是调用去查，然后耗时很久，又没有拿到数据，那不就是一直在等</p><p>那高并发情景下，很多用户都要访问这个服务，都去请求生产者，线程堆积，<strong>服务雪崩</strong></p><p>问题： </p><ul><li>服务消费者在调用服务提供者的时候发生了阻塞、等待的情形，这个时候，服务消费者会一 直等待下去。 </li><li>在某个峰值时刻，大呈的请求都在同时请求服务消费者，会造成线程的大呈堆积，势必会造 成雪崩。 </li><li>dubbo利用超时机制来解决这个问题，设置一个超时时间，在这个时间段内，无法完成服务访问，则自动断开连接。</li></ul><h4 id="配置超时时间"><a href="#配置超时时间" class="headerlink" title="配置超时时间"></a>配置超时时间</h4><p>就可以在两个dubbo注解中加timeout属性</p><h5 id="生产端"><a href="#生产端" class="headerlink" title="生产端"></a>生产端</h5><p>使用timeout属性配置超时时间，默认值1000，单位毫秒。</p><p>服务生产者配3000就是：3s数据库没返回就断开</p><h5 id="消费端"><a href="#消费端" class="headerlink" title="消费端"></a>消费端</h5><p>服务消费者配2000就是：2s服务生产者返回就断开</p><h4 id="超时时间优先级"><a href="#超时时间优先级" class="headerlink" title="超时时间优先级"></a>超时时间优先级</h4><p>上面有提到dubbo支持多种场景下设置超时时间，也说过超时是针 对消费端的。那么既然超时是针对消费端，为什么服务端也可以设置超时呢？</p><p><strong>总结：</strong></p><p>​        这其实是一种策略，其实服务端的超时配置是消费端的缺省配 置，即如果服务端设置了超时，任务消费端可以不设置超时时间，简化了配置。另外针对控制的粒度，Dubbo支持了接口级 别也支持方法级别，可以根据不同的实际情况精确控制每个方 法的超时时间。</p><p>然后就是在企业中不建议把超时时间配置在Reference里面</p><p>为什么？？</p><p>一般来说就是谁开发的接口，谁去Service里定义，就是测试的时候测出来多少秒，然后写的时间稍微大一些</p><p><strong>Reference的优先级比较高，所以说就是Reference的超时时间会覆盖掉Service的</strong></p><h3 id="重试机制"><a href="#重试机制" class="headerlink" title="重试机制"></a>重试机制</h3><p>超时问题： </p><p>如果出现网络抖动，则会出现请求失败。</p><p>如何解决 ：</p><p>Dubbo提供重试机制来避免类似问题的发生。</p><h5 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h5><p>Service里面加一个retries &#x3D; 次数</p><p><strong>Dubbo在调用服务不成功时，默认会重试两次。</strong></p><p>就是超时机制和重试都是有默认的，就是你不配置也有这个功能</p><p><strong>如果消费者配置了重试次数，提供者也配置了重试次数，则以消费者为准</strong></p><h3 id="多版本"><a href="#多版本" class="headerlink" title="多版本"></a>多版本</h3><p>Dubbo提供多版本的配置，方便我们做服务的灰度发布，或者是解决不兼容的问题。</p><h5 id="灰度发布-金丝雀发布-："><a href="#灰度发布-金丝雀发布-：" class="headerlink" title="灰度发布(金丝雀发布)："></a>灰度发布(金丝雀发布)：</h5><p>当出现新功能时，会让一部分用户先使用新功能，用户反馈没 问题时，再将所有用户迁移到新功能。</p><h5 id="版本迁移步骤"><a href="#版本迁移步骤" class="headerlink" title="版本迁移步骤"></a>版本迁移步骤</h5><p>1 在低压力时间段，先升级一半提供者为新版本 </p><p>2 再将所有消费者升级为新版本 </p><p>3 然后将剩下的一半提供者升级为新版本</p><p>就是Service里一个version属性，<strong>Reference里面一个version属性，决定服务提供者的版本</strong></p><p>如果不需要区分版本：</p><p>配个”*”</p><p>按道理来说就是不同的版本要部署在不同的服务器上</p><p>这里就是老版本运行，然后直接修改版本和设置的数据，再改一下dubbo的端口（因为我们所有都在一个机器）</p><p>复制后改名就行</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220412131232185.png" alt="image-20220412131232185"></p><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>Dubbo是一个分布式服务框架，能避免单点故障和支持服务的横向扩容。一个服务通常会部署多个实例。</p><h5 id="Dubbo内置负载均衡策略"><a href="#Dubbo内置负载均衡策略" class="headerlink" title="Dubbo内置负载均衡策略"></a>Dubbo内置负载均衡策略</h5><p>1 RandomLoadBalance：随机负载均衡，随机的选择一个，默认负载均衡。 </p><p>2 RoundRobinLoadBalance：轮询负载均衡。 </p><p>3 LeastActiveLoadBalance：最少活跃调用数，相同活跃数的随机。</p><p>4 ConsistentHashLoadBalance：一致性哈希负载均衡，相同参数的请求总是落在同一台机器上。</p><h5 id="负载均衡策略配置"><a href="#负载均衡策略配置" class="headerlink" title="负载均衡策略配置"></a>负载均衡策略配置</h5><p>如果不指定负载均衡，默认使用随机负载均衡。我们也可以根据自己的需要，显式指定一个负载均衡。</p><p>生产方消费方都可以配置</p><p>就是去掉版本，然后改端口，再复制服务改名启动就行</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220412141552680.png" alt="image-20220412141552680"></p><p>然后点开管理面板查看服务提供者就会看见你启动的多个了</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220412142036873.png" alt="image-20220412142036873"></p><p>不记得配置的名字就可以直接两下shirt搜balance，去dubbo的AbstractLoadBalance，然后进去他实现类第一行就是一个他对应的配置的名字</p><p><strong>就是出现订单生产者集群之后才需要选择负载均衡的策略</strong></p><h3 id="集群容错"><a href="#集群容错" class="headerlink" title="集群容错"></a>集群容错</h3><p>Dubbo框架为服务集群容错提供了一系列好的解决方案，在此称为 dubbo服务集群容错模式。</p><h4 id="容错模式"><a href="#容错模式" class="headerlink" title="容错模式"></a>容错模式</h4><ul><li>Failover Cluster：失败重试。默认值。当出现失败，重试其它服务器，默认重试2次，使用 retries配置。一般用于读操作 </li><li>Failfast Cluster : 快速失败，只发起一次调用，失败立即报错。通常用于写操作。 </li><li>Failsafe Cluster : 失败安全，出现异常时，直接忽略。返回一个空结果。日志不重要操作。 </li><li>Failback Cluster : 失败自动恢复，后台记录失败请求，定时重发。非常重要的操作。 </li><li>Forking Cluster：并行调用多个服务器，只要有一个成功即返回。 </li><li>Broadcast Cluster：广播调用所有提供者，逐个调用，任意一台报错则报错。 同步要求高的可以 使用这个模式。</li></ul><p>接口幂等性：</p><p>就是不管前端这块卡了还是咋样，用户肯定会点点点，但是最终数据库都只有一条，就是幂等性</p><p>所以快速失败就是解决幂等性问题</p><p>海枯石烂发到成功–Failback</p><h4 id="集群容错配置"><a href="#集群容错配置" class="headerlink" title="集群容错配置"></a>集群容错配置</h4><p>就是Reference配置一个cluster就行</p><h3 id="服务降级"><a href="#服务降级" class="headerlink" title="服务降级"></a>服务降级</h3><p>​    服务降级，当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心 任务的正常运行。</p><p>两种场景： </p><ul><li>当下游的服务因为某种原因响应过慢，下游服务主动停掉一些不太重要的业务，释放出服务 器资源，增加响应速度！ </li><li>当下游的服务因为某种原因不可用，上游主动调用本地的一些降级逻辑，避免卡顿，迅速返回给用户！</li></ul><h5 id="为什么需要降级"><a href="#为什么需要降级" class="headerlink" title="为什么需要降级"></a>为什么需要降级</h5><p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心 服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即 使是有损服务。</p><p>就比如订单都快运行不了了，还要你的日志服务干嘛。</p><h5 id="服务降级方式"><a href="#服务降级方式" class="headerlink" title="服务降级方式"></a>服务降级方式</h5><p>也是在消费方</p><h6 id="第一种"><a href="#第一种" class="headerlink" title="第一种"></a>第一种</h6><pre class=" language-none"><code class="language-none">mock="force:return null"</code></pre><p><strong>含义：</strong></p><p>​        表示消费方对该服务的方法调用都直接返回null值，不发起远程 调用。用来屏蔽不重要服务不可用时对调用方的影响。</p><h6 id="第二种"><a href="#第二种" class="headerlink" title="第二种"></a>第二种</h6><pre class=" language-none"><code class="language-none">mock="fail:return null"</code></pre><p><strong>含义</strong>：</p><p> 表示消费方对该服务的方法调用在失败后，再返回null值，不抛 异常。用来容忍不重要服务不稳定时对调用方的影响。</p><p> Dubbo技术中服务降级解决___保证核心服务可用___问题</p><h3 id="服务限流原理"><a href="#服务限流原理" class="headerlink" title="服务限流原理"></a>服务限流原理</h3><h4 id="限流算法"><a href="#限流算法" class="headerlink" title="限流算法"></a>限流算法</h4><h5 id="漏桶算法"><a href="#漏桶算法" class="headerlink" title="漏桶算法"></a>漏桶算法</h5><p><img src="/2022/04/13/dubbo-bi-ji/image-20220413184111583.png" alt="image-20220413184111583"></p><p><strong>原理</strong>： </p><p>​        漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一 定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶 算法能强行限制数据的传输速率。</p><h5 id="令牌桶算法"><a href="#令牌桶算法" class="headerlink" title="令牌桶算法"></a>令牌桶算法</h5><p><img src="/2022/04/13/dubbo-bi-ji/image-20220413184148175.png" alt="image-20220413184148175"></p><p>原理: </p><p>​        令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令 牌，而如果请求需要被处理，则需要先从桶里获取一个令牌， 当桶里没有令牌可取时，则拒绝服务。</p><h5 id="漏桶-vs-令牌桶的区别"><a href="#漏桶-vs-令牌桶的区别" class="headerlink" title="漏桶 vs 令牌桶的区别"></a>漏桶 vs 令牌桶的区别</h5><p>漏桶的天然特性决定了它不会发生突发流量，就算每秒1000个请求 到来，那么它对后台服务输出的访问速率永远恒定。而令牌桶则不 同，其特性可以“预存”一定量的令牌，因此在应对突发流量的时候 可以在短时间消耗所有令牌，其突发流量处理效率会比漏桶高，但 是导向后台系统的压力也会相应增多。</p><p>限流技术主要解决___保护系统___问题?</p><p>限流算法中___令牌桶算法___算法具有应对突发性的流量?</p><h3 id="服务限流实现"><a href="#服务限流实现" class="headerlink" title="服务限流实现"></a>服务限流实现</h3><p>​        为了防止某个消费者的QPS或是所有消费者的QPS总和突然飙升而 导致的重要服务的失效，系统可以对访问流量进行控制，这种对集 群的保护措施称为服务限流。</p><h5 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h5><pre class=" language-none"><code class="language-none">@Service(executes = 10)</code></pre><p>注意： 服务端并发执行（或占用线程池线程数）不能超过10个</p><h5 id="连接控制"><a href="#连接控制" class="headerlink" title="连接控制"></a>连接控制</h5><pre class=" language-none"><code class="language-none"> @Service(actives= 10)</code></pre><p>注意： 占用连接的请求的数不能超过10个。</p><h3 id="结果缓存"><a href="#结果缓存" class="headerlink" title="结果缓存"></a>结果缓存</h3><p>就是Reference里的cache属性</p><p>通过原子类的方式实现自增的效果<br><img src="/2022/04/13/dubbo-bi-ji/image-20220412163942544.png" alt="image-20220412163942544"></p><p>这个方法会进入一个无限循环体内，就不断自增赋值给自己，如果失败了就说明别的线程已经获取设置了，然后又继续循环自增    </p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220412164659080.png" alt="image-20220412164659080"></p><p>刷新就会一直往后自增，说明服务的消费者一直在消费用户生产者，一直远程调用</p><p>然后去Reference加一个cache&#x3D;”lru”</p><p>加了之后就会把我们的结果缓存起来，就不会一直去发生远程调用，这就是结果缓存</p><p>刷新刷来刷去都是0和12</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220412164915129.png" alt="image-20220412164915129"></p><p>这里就是服务消费者加缓存了</p><p>那要是想服务生产者加缓存怎么办？？</p><p>​    就直接引入一个redis就可以，或者将缓存加到java的内存中都是可以的</p><p>主要解决问题，响应慢</p><h2 id="项目打包"><a href="#项目打包" class="headerlink" title="项目打包"></a>项目打包</h2><h3 id="1-基于-SpringBoot-整合-Dubbo-的打包方式"><a href="#1-基于-SpringBoot-整合-Dubbo-的打包方式" class="headerlink" title="1 基于 SpringBoot 整合 Dubbo 的打包方式"></a>1 基于 SpringBoot 整合 Dubbo 的打包方式</h3><p>通过 SpringBoot 打包插件打包项目</p><p>一定要注意的就是，一定要包含打包插件。</p><p>笔记里面的是没有版本的，然后显示artifactId not found，搜到的解决方案就是加版本就好了，确实也是添加版本之后就没有问题了</p><p>打包consumer的时候一直报错没有找到服务接口api的jar，想了一想，然后去把api项目先install了一下，这样就有api的jar了，之后发现确实是这样子，但是然后又报错There are test failures.，，就是鬼知道在test里添加了什么代码，只要点一下一排按钮的那个闪电按钮，就是不测试直接打包就可以了，但是我的lifeCycle里的install好像打包完也没有看见有jar呀，原来我把显示关了，怪不得看不见。</p><p>然后就可以移动出去这个jar包了，接着在命令行使用java命令运行就ok，provider的打包方式和这个也是一样的</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220303205137614.png" alt="image-20220303205137614"></p><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.springframework.boot<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spring-boot-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.2.2.RELEASE<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span></code></pre><h3 id="2-基于-Assembly-插件打包"><a href="#2-基于-Assembly-插件打包" class="headerlink" title="2 基于 Assembly 插件打包"></a>2 基于 Assembly 插件打包</h3><p>我就不去打包了，到时候有需要的时候，再回过头来看就可以了。</p><h4 id="2-1Assembly-插件"><a href="#2-1Assembly-插件" class="headerlink" title="2.1Assembly 插件"></a>2.1Assembly 插件</h4><p>Assembly是Mave的打包插件，他的作用是可以帮助我们对<strong>jar项目做打包处理</strong>。在Spring 整合 dubbo 的项目中，需要使Assembly 打包插件来对项目做打包处理。</p><p>在这种情况下，因为consumer是一个war项目，启动就会生成war包了，就是不需要使用这个插件来打包，所以我们就是需要依赖这插件对provider进行打包处理</p><h4 id="2-2使用步骤"><a href="#2-2使用步骤" class="headerlink" title="2.2使用步骤"></a>2.2使用步骤</h4><ol><li>需要在项目根下创建一个目录，名称为 assembly </li><li>将示例中 bin,conf 目录拷贝到 assembly 的根目录中 </li><li>删除 conf 目录中 dubbo.properties 配置文件中的内容 </li><li>修改项目的 POM 文件添加 assembly 的打包插件 </li><li>在 assembly 目录下添加 assembly.xml 配置文件</li><li>运行打包插件，对项目进行打包处理。可以使用 maven 的 install 命令，也可以使用 插件的命令</li><li>修改 start.sh 或 start.bat 中配置信息，将启动类修改为当前 dubbo 版本的启动类</li></ol><pre class=" language-bash"><code class="language-bash"><span class="token function">nohup</span> java <span class="token variable">$JAVA_OPTS</span> <span class="token variable">$JAVA_MEM_OPTS</span> <span class="token variable">$JAVA_DEBUG_OPTS</span> <span class="token variable">$JAVA_JMX_OPTS</span>-classpath <span class="token variable">$CONF_DIR</span><span class="token keyword">:</span><span class="token variable">$LIB_JARS</span> org.apache.dubbo.container.Main <span class="token operator">></span><span class="token variable">$STDOUT_FILE</span> 2<span class="token operator">></span><span class="token operator">&amp;</span>1 <span class="token operator">&amp;</span></code></pre><h2 id="Dubbo-监控与管理"><a href="#Dubbo-监控与管理" class="headerlink" title="Dubbo 监控与管理"></a>Dubbo 监控与管理</h2><h3 id="1-监控平台-dubbo-monitor"><a href="#1-监控平台-dubbo-monitor" class="headerlink" title="1 监控平台: dubbo-monitor"></a>1 监控平台: dubbo-monitor</h3><h4 id="1-1Dubbo-Monitor-简介"><a href="#1-1Dubbo-Monitor-简介" class="headerlink" title="1.1Dubbo Monitor 简介"></a>1.1Dubbo Monitor 简介</h4><p>主要用来统计服务的调用次数和调用时间，服务消费者和提供者，在内存中累计调用次 数和调用时间，定时每分钟发送一次统计数据到监控中心，监控中心则使用数据绘制图表来显示。</p><h4 id="1-2Dubbo-Monitor-的使用"><a href="#1-2Dubbo-Monitor-的使用" class="headerlink" title="1.2Dubbo Monitor 的使用"></a>1.2Dubbo Monitor 的使用</h4><p>修改Monitor的配置文件，就是改一下你注册中心的ip</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220302130749227.png" alt="image-20220302130749227"></p><p>然后启动就是直接去bin下bat就可，Linux下就是.sh</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220302132031678.png" alt="image-20220302132031678"></p><p>然后就可以打开浏览器，输入本机ip和端口，主页如下</p><p><img src="/2022/04/13/dubbo-bi-ji/image-20220302132131419.png" alt="image-20220302132131419"></p><p>比如主页就是对上面菜单的介绍</p><p>主页</p><p>应用的依赖</p><p>注册的服务（不包括Consumer，注册的就是provider），consumer不是服务的注册（不记得就看架构图）</p><p>Host  当前provider和consumer的主机</p><p>注册中心的地址</p><p>服务器地址</p><p>状态</p><p>日志</p><p>系统环境的信息</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ为什么使用信道而不直接使用TCP连接通信？</title>
      <link href="/2022/04/08/rabbitmq-wei-shi-me-shi-yong-xin-dao-er-bu-zhi-jie-shi-yong-tcp-lian-jie-tong-xin/"/>
      <url>/2022/04/08/rabbitmq-wei-shi-me-shi-yong-xin-dao-er-bu-zhi-jie-shi-yong-tcp-lian-jie-tong-xin/</url>
      
        <content type="html"><![CDATA[<p>TCP连接的创建和销毁开销特别大。</p><p>创建需要3次握手，销毁需要4次分手。高峰时每秒成千上万条TCP连接的创建会造成资源巨大的浪费。而且操作系统每秒处理TCP连接数也是有限制的， 会造成性能瓶颈。</p><p>而如果一条线程使用一条信道，一条TCP链接可以容纳无限的信道，即使每秒成千上万的请求也不会成为性 能的瓶颈。</p><p><img src="/2022/04/08/rabbitmq-wei-shi-me-shi-yong-xin-dao-er-bu-zhi-jie-shi-yong-tcp-lian-jie-tong-xin/1562800613510.jpeg" alt="1562800613510"></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ笔记</title>
      <link href="/2022/04/08/rabbitmq-bi-ji/"/>
      <url>/2022/04/08/rabbitmq-bi-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h1><h4 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h4><p> MQ全称Message Queue（消息队列），是在消息的传输过程中保存消息的容器。多用于系统之间的异步通信。</p><h4 id="MQ的优势"><a href="#MQ的优势" class="headerlink" title="MQ的优势"></a>MQ的优势</h4><h5 id="应用解耦"><a href="#应用解耦" class="headerlink" title="应用解耦"></a>应用解耦</h5><p>在电商平台中，用户下订单需要调用订单系统，此时订单系统还需 要调用库存系统、支付系统、物流系统完成业务。此时会产生两个问题：</p><p>1 如果库存系统出现故障，会造成整个订单系统崩溃。 </p><p>2 如果需求修改，新增了一个X系统，此时必须修改订单系统的代码。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408103539142.png" alt="image-20220408103539142"></p><p>如果在系统中引入MQ，即订单系统将消息先发送到MQ中，MQ再转发到其他系统，则会解决以下问题：</p><p>1 由于订单系统只发消息给MQ，不直接对接其他系统，如果库存系统出现故障，不影响整个订单。</p><p>2 如果需求修改，新增了一个X系统，此时无需修改订单系统的代码，只需修改MQ将消息发送给X系统即可。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408103642727.png" alt="image-20220408103642727"></p><h5 id="异步提速"><a href="#异步提速" class="headerlink" title="异步提速"></a>异步提速</h5><p>如果订单系统同步访问每个系统，则用户下单等待时长如下：</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408103357196.png" alt="image-20220408103357196"></p><p>如果引入MQ，则用户下单等待时长如下：</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408103413238.png" alt="image-20220408103413238"></p><h5 id="削峰填谷"><a href="#削峰填谷" class="headerlink" title="削峰填谷"></a>削峰填谷</h5><p>假设我们的系统每秒只能承载1000请求，如果请求瞬间增多到每秒 5000，则会造成系统崩溃。此时引入mq即可解决该问题</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408103429479.png" alt="image-20220408103429479"></p><p>使用了MQ之后，限制消费消息的速度为1000，这样一来，高峰期 产生的数据势必会被积压在MQ中，高峰就被“削”掉了，但是因为消 息积压，在高峰期过后的一段时间内，消费消息的速度还是会维持在1000，直到消费完积压的消息，这就叫做“填谷”。</p><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><h5 id="短时间内需要处理大量请求"><a href="#短时间内需要处理大量请求" class="headerlink" title="短时间内需要处理大量请求"></a>短时间内需要处理大量请求</h5><p>如果直接连接系统处理业务，会耗费大量资源，有可能造成系统瘫痪。</p><p>如：秒杀，抢红包，抢火车票</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408104625502.png" alt="image-20220408104625502"></p><p>而使用MQ后，可以先让用户将请求发送到MQ中，MQ会先保存 请求消息，不会占用系统资源，且MQ会进行消息排序，先请求 的秒杀成功，后请求的秒杀失败。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408104612270.png" alt="image-20220408104612270"></p><h5 id="消息分发"><a href="#消息分发" class="headerlink" title="消息分发"></a>消息分发</h5><p>如电商网站要推送促销信息，该业务耗费时间较多，但对时效性 要求不高，可以使用MQ做消息分发。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408104655872.png" alt="image-20220408104655872"></p><h5 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h5><p>假如我们需要将数据保存到数据库之外，还需要一段时间将数据同步到缓存（如Redis）、搜索引擎（如Elasticsearch）中。此 时可以将数据库的数据作为消息发送到MQ中，并同步到缓存、 搜索引擎中。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408104712580.png" alt="image-20220408104712580"></p><h5 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h5><p>在电商系统中，订单完成后，需要及时的通知子系统（进销存系 统发货，用户服务积分，发送短信）进行下一步操作。为了保证 订单系统的高性能，应该直接返回订单结果，之后让MQ通知子 系统做其他非实时的业务操作。这样能保证核心业务的高效及时。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408104744539.png" alt="image-20220408104744539"></p><h5 id="离线处理"><a href="#离线处理" class="headerlink" title="离线处理"></a>离线处理</h5><p>在银行系统中，如果要查询近十年的历史账单，这是非常耗时的操作。如果发送同步请求，则会花费大量时间等待响应。此时使用MQ发送异步请求，等到查询出结果后获取结果即可。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408104814969.png" alt="image-20220408104814969"></p><h4 id="AMQP"><a href="#AMQP" class="headerlink" title="AMQP"></a>AMQP</h4><p>高级消息队列协议</p><p>RabbitMQ是由Erlang语言编写的基于AMQP的MQ产品。</p><p>MQ的标准非常简单</p><p>就是放一个容器，容器中可以存一个单向队列，FIFO策略，接着就是一个发送者，把消息发送到队列里，不管使用什么办法。</p><p>另外一端就是consumer消费者，拿消息，运行之后不管主动还是被动的从队列中把消息拿出来。处理掉就可以</p><p>就是保证这三个角色传递消息了，他就是MQ标准</p><p>AMQP中多了一个<strong>交换器</strong>，对于发送消息的人来说，它不需要知道队列是什么，知道交换器就可以，就是发消息发到交换器</p><p>那对于consumer来说就只需要知道自己的队列就行</p><p>其实真正的开发过程中，consumer还是要指定一下交换器的位置的</p><p>基于erlang，这个语言开发出来的产品，有几个特性，特别适合处理<strong>高并发</strong>，</p><p>处理高并发的时候服务器的<strong>吞吐量</strong>也是特别大的</p><p>然后就是对于<strong>多线程</strong>的处理也是特别好,这就是erlang这个语种开发的特点。</p><h5 id="AMQP工作过程"><a href="#AMQP工作过程" class="headerlink" title="AMQP工作过程"></a>AMQP工作过程</h5><p>生产者(Publisher)将消息发布到交换机(Exchange)，交换机根据规 则将消息分发给交换机绑定的队列(Queue)，队列再将消息投递给 订阅了此队列的消费者。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408105734730.png" alt="image-20220408105734730"></p><h4 id="RabbitMQ工作原理"><a href="#RabbitMQ工作原理" class="headerlink" title="RabbitMQ工作原理"></a>RabbitMQ工作原理</h4><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408105836497.png" alt="image-20220408105836497"></p><h5 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h5><p>消息的生产者。也是一个向交换机发布消息的客户端应用程序。 </p><h5 id="Connection"><a href="#Connection" class="headerlink" title="Connection"></a>Connection</h5><p>连接。生产者&#x2F;消费者和RabbitMQ服务器之间建立的TCP连接。 </p><h5 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h5><p>信道。是TCP里面的虚拟连接。例如：Connection相当于电缆， Channel相当于独立光纤束，一条TCP连接中可以创建多条信 道，增加连接效率。无论是发布消息、接收消息、订阅队列都是通过信道完成的。 </p><h5 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h5><p>消息队列服务器实体。即RabbitMQ服务器 </p><h5 id="Virtual-host"><a href="#Virtual-host" class="headerlink" title="Virtual host"></a>Virtual host</h5><p>虚拟主机。出于多租户和安全因素设计的，把AMQP的基本组件 划分到一个虚拟的分组中。每个vhost本质上就是一个mini版的 RabbitMQ服务器，拥有自己的队列、交换机、绑定和权限机 制。当多个不同的用户使用同一个RabbitMQ服务器时，可以划分出多个虚拟主机。RabbitMQ默认的虚拟主机路径是 &#x2F; </p><h5 id="Exchange"><a href="#Exchange" class="headerlink" title="Exchange"></a>Exchange</h5><p>交换机。用来接收生产者发送的消息，并根据分发规则，将这些消息分发给服务器中的队列中。不同的交换机有不同的分发规 则。 </p><h5 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h5><p>消息队列。用来保存消息直到发送给消费者。它是消息的容器， 也是消息的终点。消息一直在队列里面，等待消费者链接到这个 队列将其取走。 </p><h5 id="Binding"><a href="#Binding" class="headerlink" title="Binding"></a>Binding</h5><p>消息队列和交换机之间的虚拟连接，绑定中包含路由规则，绑定信息保存到交换机的路由表中，作为消息的分发依据。 </p><h5 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h5><p>消息的消费者。表示一个从消息队列中取得消息的客户端应用程序。</p><h4 id="安装Erlang"><a href="#安装Erlang" class="headerlink" title="安装Erlang"></a>安装Erlang</h4><p>1.安装<em><strong>epel</strong></em>源</p><pre class=" language-none"><code class="language-none">yum install -y epel-release</code></pre><p>2.添加存储库条目</p><pre class=" language-bash"><code class="language-bash"><span class="token function">wget</span> https://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpmrpm -Uvh erlang-solutions-1.0-1.noarch.rpm//报错-bash: wget: 未找到命令然后去安装一下wgetyum <span class="token function">install</span> -y <span class="token function">wget</span>再走一遍</code></pre><p>3.安装erlang</p><pre class=" language-bash"><code class="language-bash">yum <span class="token function">install</span> -y erlang</code></pre><p>4.验证安装是否成功</p><p><strong>erl -version</strong></p><h4 id="安装RabbitMQ–解压安装"><a href="#安装RabbitMQ–解压安装" class="headerlink" title="安装RabbitMQ–解压安装"></a>安装RabbitMQ–解压安装</h4><p>1.为了外部能够正常访问RabbitMQ服务，先关闭防火墙</p><h5 id><a href="#" class="headerlink" title></a></h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 关闭运行的防火墙</span>systemctl stop firewalld.service<span class="token comment" spellcheck="true"># 禁止防火墙自启动</span>systemctl disable firewalld.service</code></pre><h5 id="2-RabbitMQ是通过主机名进行访问的，必须给服务器添加主机名"><a href="#2-RabbitMQ是通过主机名进行访问的，必须给服务器添加主机名" class="headerlink" title="2.RabbitMQ是通过主机名进行访问的，必须给服务器添加主机名"></a>2.RabbitMQ是通过主机名进行访问的，必须给服务器添加主机名</h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 修改文件</span>vim /etc/sysconfig/network<span class="token comment" spellcheck="true"># 添加如下内容</span>NETWORKING<span class="token operator">=</span>yesHOSTNAME<span class="token operator">=</span>juejue<span class="token comment" spellcheck="true"># 修改文件</span>vim /etc/hosts<span class="token comment" spellcheck="true"># 添加如下内容</span>服务器ip juejue</code></pre><h5 id="3-使用rz命令上传RabbitMQ压缩文件"><a href="#3-使用rz命令上传RabbitMQ压缩文件" class="headerlink" title="3 使用rz命令上传RabbitMQ压缩文件"></a>3 使用rz命令上传RabbitMQ压缩文件</h5><h5 id="4-安装RabbitMQ"><a href="#4-安装RabbitMQ" class="headerlink" title="4 安装RabbitMQ"></a>4 安装RabbitMQ</h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 解压RabbitMQ</span><span class="token function">tar</span> xf rabbitmq-server-generic-unix-3.9.13.tar.xz<span class="token comment" spellcheck="true"># 重命名：</span><span class="token function">mv</span> rabbitmq_server-3.9.13 rabbitmq<span class="token comment" spellcheck="true"># 移动文件夹：</span><span class="token function">mv</span> rabbitmq /usr/local/</code></pre><h5 id="5-配置环境变量"><a href="#5-配置环境变量" class="headerlink" title="5  配置环境变量"></a>5  配置环境变量</h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 编辑/etc/profile文件</span>vim /etc/profile<span class="token comment" spellcheck="true">#添加如下内容</span><span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span>:/usr/local/rabbitmq/sbin<span class="token comment" spellcheck="true"># 运行文件，让修改内容生效</span><span class="token function">source</span> /etc/profile</code></pre><h5 id="6-开启管控台插件"><a href="#6-开启管控台插件" class="headerlink" title="6 开启管控台插件"></a>6 开启管控台插件</h5><pre class=" language-bash"><code class="language-bash">rabbitmq-plugins <span class="token function">enable</span> rabbitmq_management</code></pre><p>就是rabbitMQ自带的一个控制台插件，我们可以通过浏览器访问控制台，通过控制台来管理队列、消息、交换机等等</p><h5 id="7-后台运行"><a href="#7-后台运行" class="headerlink" title="7 后台运行"></a>7 后台运行</h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#启动rabbitmq</span>rabbitmq-server -detached<span class="token comment" spellcheck="true">#停止rabbitmq</span>rabbitmqctl stop    </code></pre><h5 id="8-通过管控台访问RabbitMQ"><a href="#8-通过管控台访问RabbitMQ" class="headerlink" title="8 通过管控台访问RabbitMQ"></a>8 通过管控台访问RabbitMQ</h5><p>路径： <a href="http://ip地址:15672/">http://ip地址:15672</a> ，用户名： guest ，密码： guest</p><p>rabbitMQ默认占用的端口号是5672，但是不是直接访问，而是访问它的管控台插件，管控台插件占用的是15672</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408130202366.png" alt="image-20220408130202366"></p><p>但是你会发现登录不了，因为这个现在是远程访问，默认不让远程使用管理员访问</p><p>就有两种解决办法，一是让管理员可以远程访问，二是再创建一个用户</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408130215521.png" alt="image-20220408130215521"></p><p>配置允许使用 guest远程访问</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 创建配置文件夹</span><span class="token function">mkdir</span> -p /usr/local/rabbitmq/etc/rabbitmq<span class="token comment" spellcheck="true"># 创建配置文件</span>vim /usr/local/rabbitmq/etc/rabbitmq/rabbitmq.conf<span class="token comment" spellcheck="true"># 添加如下内容</span>loopback_users<span class="token operator">=</span>none<span class="token comment" spellcheck="true"># 重启RabbitMQ</span>rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl start_app//对应停止。重新加载配置，启动</code></pre><p> 然后就可以使用guest用户来访问了</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408130327271.png" alt="image-20220408130327271"></p><h4 id="账户管理"><a href="#账户管理" class="headerlink" title="账户管理"></a>账户管理</h4><p>因为RabbitMQ并不推荐我们远程使用guest用户访问，因为会变的不安全，因为不修改账户名和密码那他们都是guest</p><p>guest账户默认只允许本地使用，我们可以创建新账户远程访问 RabbitMQ    </p><h5 id="1-创建账户"><a href="#1-创建账户" class="headerlink" title="1 创建账户"></a>1 创建账户</h5><h5 id="-1"><a href="#-1" class="headerlink" title></a></h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 创建账户</span>rabbitmqctl add_user 用户名 密码</code></pre><h5 id="2-给用户授予管理员角色"><a href="#2-给用户授予管理员角色" class="headerlink" title="2 给用户授予管理员角色"></a>2 给用户授予管理员角色</h5><pre class=" language-bash"><code class="language-bash">rabbitmqctl set_user_tags 用户名 administrator</code></pre><h5 id="3-给用户授权"><a href="#3-给用户授权" class="headerlink" title="3 给用户授权"></a>3 给用户授权</h5><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># "/"表示虚拟机</span><span class="token comment" spellcheck="true"># juejue表示用户名</span><span class="token comment" spellcheck="true"># ".*" ".*" ".*" 表示完整权限</span>rabbitmqctl set_permissions -p <span class="token string">"/"</span> juejue <span class="token string">".*"</span> <span class="token string">".*"</span> <span class="token string">".*"</span></code></pre><h5 id="4-通过管控台访问rabbitmq"><a href="#4-通过管控台访问rabbitmq" class="headerlink" title="4 通过管控台访问rabbitmq"></a>4 通过管控台访问rabbitmq</h5><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408130546799.png" alt="image-20220408130546799"></p><p>推荐自己创建交换机</p><h4 id="docker安装"><a href="#docker安装" class="headerlink" title="docker安装"></a>docker安装</h4><pre class=" language-bash"><code class="language-bash">curl -fsSL https://get.docker.com <span class="token operator">|</span> <span class="token function">bash</span> -s docker --mirror Aliyun<span class="token comment" spellcheck="true"># 启动docker</span>systemctl start docker</code></pre><p>安装好之后拉一下镜像</p><pre class=" language-bash"><code class="language-bash">docker pull rabbitmq</code></pre><p>启动RabbitMQ容器</p><pre class=" language-none"><code class="language-none">docker run -d --hostname juejue --name rabbit -p 15672:15672 -p 5672:5672 rabbitmq</code></pre><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220405150415806.png" alt="image-20220405150415806"></p><p>开启管控台插件</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 查询rabbitmq容器ID</span>docker <span class="token function">ps</span>  <span class="token comment" spellcheck="true"># 进入容器</span>docker <span class="token function">exec</span> -it 容器ID /bin/bash<span class="token comment" spellcheck="true"># 开启管控台插件</span>rabbitmq-plugins <span class="token function">enable</span> rabbitmq_management<span class="token comment" spellcheck="true"># 退出容器</span>ctrl+p+q</code></pre><p>然后容器的rabbitMQ是可以直接使用guest用户登陆的</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220405151331098.png" alt="image-20220405151331098"></p><p>不理解，，难道我重新启动rabbitmq，之前创建的juejue用户就没了？整的我要重新创建一遍</p><h4 id="简单模式"><a href="#简单模式" class="headerlink" title="简单模式"></a>简单模式</h4><p>RabbitMQ共有六种工作模式：简单模式（Simple）、工作队列模式（Work Queue）、发布订阅模式（Publish&#x2F;Subscribe）、路由 模式（Routing）、通配符模式（Topics）、远程调用模式（RPC， 不常用，这里不说)</p><p>就是简单使用Java原生API去实现，这里不过多展示</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408134152170.png" alt="image-20220408134152170"></p><h6 id="特点："><a href="#特点：" class="headerlink" title="特点："></a>特点：</h6><p>1 一个生产者对应一个消费者，通过队列进行消息传递。 </p><p>2 该模式使用direct交换机，direct交换机是RabbitMQ默认交换机。运行代码就可以看见发送的消息了</p><p>（JavaMessage Service）——–JMS</p><p>JMS是JavaEE规范中的一种，类比JDBC。很多 MQ产品都实现了JMS规范，例如ActiveMQ。RabbitMQ官方并没 有实现JMS规范，但是开源社区有JMS的实现包。</p><h4 id="工作队列模式"><a href="#工作队列模式" class="headerlink" title="工作队列模式"></a>工作队列模式</h4><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408134220045.png" alt="image-20220408134220045"></p><p>与简单模式相比，工作队列模式(Work Queue)多了一些消费者，该 模式也使用direct交换机，应用于处理消息较多的情况。</p><p>特点如下： </p><p>1 一个队列对应多个消费者。 </p><p>2 一条消息只会被一个消费者消费。 </p><p>3 消息队列默认采用轮询的方式将消息平均发送给消费者。</p><h4 id="发布订阅模式"><a href="#发布订阅模式" class="headerlink" title="发布订阅模式"></a>发布订阅模式</h4><p>前两个模式当中，同一条消息只会被发送到一个队列当中，并且只会被一个消费者消费一次，</p><p>但实际上有些消息是要被多次消费的</p><p>有点不一样的就是，之前两个是直接往队列里面发消息</p><p>但是现在这里会先发消息给交换机，由交换机再分发到队列当中</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406105628569.png" alt="image-20220406105628569"></p><p>在开发过程中，有一些消息需要不同消费者进行不同的处理，如电 商网站的同一条促销信息需要短信发送、邮件发送、站内信发送 等。此时可以使用发布订阅模式(Publish&#x2F;Subscribe) </p><p>特点： </p><p>1 生产者将消息发送给交换机，交换机将消息转发到绑定此交换机的每个队列中。</p><p>2 工作队列模式的交换机只能将消息发送给一个队列，发布订阅模式的交换机能将消息发送给多个队列。发布订阅模式使用fanout交换机。</p><p>然后工作模式和发布订阅是可以一起使用的，也就是可以使用多个消费者去监听同一个队列，他们轮询分配消息。</p><h4 id="路由模式"><a href="#路由模式" class="headerlink" title="路由模式"></a>路由模式</h4><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406105957506.png" alt="image-20220406105957506"></p><p>使用发布订阅模式时，所有消息都会发送到绑定的队列中，但很多 时候，不是所有消息都无差别的发布到所有队列中。比如电商网站 的促销活动，双十一大促可能会发布到所有队列；而一些小的促销 活动为了节约成本，只发布到站内信队列。此时需要使用路由模式 (Routing)完成这一需求。</p><p>特点： </p><p>1 每个队列绑定路由关键字RoutingKey   </p><p>2 生产者将带有RoutingKey的消息发送给交换机，交换机根据RoutingKey转发到指定队列。路由模式使用direct交换机。</p><p>然后交换机还是自己创建，不使用默认的</p><p>然后每个队列是可以添加多个路由关键字的</p><p>就是在交换机绑定队列的时候添加关键字，发送消息的时候也添加关键字。</p><h4 id="通配符模式"><a href="#通配符模式" class="headerlink" title="通配符模式"></a>通配符模式</h4><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220408134734549.png" alt="image-20220408134734549"></p><p>其实就相当于路由模式的进阶版，比路由模式更加的灵活</p><p>生产者和路由模式中的区别就是绑定路由关键字的时候关键字里面带有通配符</p><p>其实通配符模式也叫主题模式topic</p><p>消费者就和也是直接拿路由模式的修改一下监听的队列就行，最终效果和路由模式的效果一样</p><h3 id="Springboot整合RabbtMQ"><a href="#Springboot整合RabbtMQ" class="headerlink" title="Springboot整合RabbtMQ"></a>Springboot整合RabbtMQ</h3><p>之前都是原生Java操作RabbitMQ，真正开发的时候更多都是用框架来简化RabbitMQ的操作；</p><p>配置文件</p><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># 配置RabbitMQ</span><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">rabbitmq</span><span class="token punctuation">:</span>    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.8.14    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">5672</span>    <span class="token key atrule">username</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">password</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">virtual-host</span><span class="token punctuation">:</span> /<span class="token comment" spellcheck="true">#日志格式</span><span class="token key atrule">logging</span><span class="token punctuation">:</span>  <span class="token key atrule">pattern</span><span class="token punctuation">:</span>    <span class="token key atrule">console</span><span class="token punctuation">:</span> '%d&amp;<span class="token comment" spellcheck="true">#123;HH:mm:ss.SSS&amp;#125;%clr(%-5level) ---[%-15thread]%cyan(%-50logger&amp;#123;50&amp;#125;):%msg%n'</span></code></pre><p>SpringBoot整合RabbitMQ时，需要在配置类创建队列和交换机</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.rabbitmqspringboot;import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RabbitConfig &#123;    private final String EXCHANGE_NAME = "boot_topic_exchange";    private final String QUEUE_NAME = "boot_queue";    // 创建交换机    @Bean("bootExchange")    public Exchange getExchange() &#123;        return ExchangeBuilder                .topicExchange(EXCHANGE_NAME) // 交换机类型                .durable(true) // 是否持久化                .build();    &#125;    // 创建队列    @Bean("bootQueue")    public Queue getMessageQueue() &#123;        return new Queue(QUEUE_NAME); // 队列名    &#125;    // 交换机绑定队列    @Bean//参数的交换机和队列都是从spring容器中拿的    public Binding bindMessageQueue(@Qualifier("bootExchange") Exchange exchange, @Qualifier("bootQueue") Queue queue) &#123;        return BindingBuilder                .bind(queue)                .to(exchange)                .with("#.message.#")                .noargs();    &#125;&#125;</code></pre><p>SpringBoot整合RabbitMQ时，提供了工具类RabbitTemplate发送 消息，编写生产者时只需要注入RabbitTemplate即可发送消息。</p><pre class=" language-JAVA"><code class="language-JAVA">@SpringBootTestpublic class TestProducer &#123;    // 注入RabbitTemplate工具类    @Autowired    private RabbitTemplate rabbitTemplate;    @Test    public void testSendMessage()&#123;        /*         * 发送消息         * 参数1：交换机         * 参数2：路由key         * 参数3：要发送的消息         */        rabbitTemplate.convertAndSend("boot_topic_exchange","message","双十一开始了！");    &#125;&#125;</code></pre><p>然后另一个项目编写消费者，为什么？？因为如果是同一个项目的话，直接调用就可以，不需要通过MQ去通信</p><pre class=" language-JAVA"><code class="language-JAVA">//消费者@Componentpublic class Consumer &#123;    //监听队列    @RabbitListener(queues = "boot_queue")    public void listenMessage(String message)&#123;        System.out.println("接收消息："+message);    &#125;&#125;</code></pre><p>然后消费者就不要写测试方法了，直接写普通方法，这样启动之后他就会一直监听队列</p><p>直接拿过来字符串类型的消息就可以用，框架会帮我们去做那个byte的转换</p><p>这个消费者是随着项目的启动而启动的</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406164530529.png" alt="image-20220406164530529"></p><h3 id="消息的可靠性投递"><a href="#消息的可靠性投递" class="headerlink" title="消息的可靠性投递"></a>消息的可靠性投递</h3><p>RabbitMQ消息投递的路径为： 生产者 —&gt; 交换机 —&gt; 队列 —&gt; 消费者</p><ul><li>确认模式（confirm）可以监听消息是否从生产者成功传递到交换机  。 </li><li>退回模式（return）可以监听消息是否从交换机成功传递到队列。 </li><li>消费者消息确认（Consumer Ack）可以监听消费者是否成功处理消息。</li></ul><h4 id="确认模式"><a href="#确认模式" class="headerlink" title="确认模式"></a>确认模式</h4><p>确认模式（confirm）可以监听消息是否从生产者成功传递到交换机。 退回模式（return）可以监听消息是否从交换机成功传递到队列。 消费者消息确认（Consumer Ack）可以监听消费者是否成功处理消息。</p><p>确认模式：在生产者中配置之后才会有作用</p><p>故意写错一个发送消息的交换器名字之后，运行发现交换机和队列都创建出来了，但是，队列里面没有消息，而且控制台也不报错，这就是不加确认模式的一个效果</p><h5 id="1-生产者配置文件开启确认模式"><a href="#1-生产者配置文件开启确认模式" class="headerlink" title="1 生产者配置文件开启确认模式"></a>1 生产者配置文件开启确认模式</h5><p>加了之后</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406174100375.png" alt="image-20220406174100375"></p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">rabbitmq</span><span class="token punctuation">:</span>    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.8.14    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">5672</span>    <span class="token key atrule">username</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">password</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">virtual-host</span><span class="token punctuation">:</span> /    <span class="token comment" spellcheck="true"># 开启确认模式</span>    <span class="token key atrule">publisher-confirm-type</span><span class="token punctuation">:</span> correlated</code></pre><h5 id="2-生产者定义确认模式的回调方法"><a href="#2-生产者定义确认模式的回调方法" class="headerlink" title="2 生产者定义确认模式的回调方法"></a>2 生产者定义确认模式的回调方法</h5><pre class=" language-JAVA"><code class="language-JAVA">@Testpublic void sendMessage()&#123;    //定义确认模式的回调方法，消息交换机发送后会调用confirm方法    rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback()&#123;        /**         * 被调用的回调方法         * @param correlationData 相关配置信息         * @param ack 交换机是否成功收到消息         * @param cause 失败原因         */        @Override        public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123;        if (ack)&#123;            System.out.println("confirm接收成功");        &#125;else &#123;            System.out.println("接收失败，原因为："+cause);            //做一些处理，让消息再次发送            &#125;        &#125;    &#125;);    //故意写一个错的交换机    rabbitTemplate.convertAndSend("my_topic_exchange","my_routing","Send Message...");&#125;</code></pre><h4 id="退回模式"><a href="#退回模式" class="headerlink" title="退回模式"></a>退回模式</h4><p>退回模式：可以监听消息是否从交换机成功传递到队列</p><h5 id="1-生产者配置文件开启退回模式"><a href="#1-生产者配置文件开启退回模式" class="headerlink" title="1 生产者配置文件开启退回模式"></a>1 生产者配置文件开启退回模式</h5><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># 配置RabbitMQ</span><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">rabbitmq</span><span class="token punctuation">:</span>    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.8.14    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">5672</span>    <span class="token key atrule">username</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">password</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">virtual-host</span><span class="token punctuation">:</span> /    <span class="token comment" spellcheck="true"># 开启确认模式</span>    <span class="token key atrule">publisher-confirm-type</span><span class="token punctuation">:</span> correlated      <span class="token comment" spellcheck="true"># 开启回退模式</span>    <span class="token key atrule">publisher-returns</span><span class="token punctuation">:</span> <span class="token boolean important">true</span></code></pre><h5 id="2-生产者定义退回模式的回调方法"><a href="#2-生产者定义退回模式的回调方法" class="headerlink" title="2 生产者定义退回模式的回调方法"></a>2 生产者定义退回模式的回调方法</h5><pre class=" language-JAVA"><code class="language-JAVA">@Testpublic void testReturn()&#123;    //定义退回模式的回调方法。交换机发送到队列失败后才会执行returnedMessage方法    rabbitTemplate.setReturnsCallback(new RabbitTemplate.ReturnsCallback()&#123;        /**         * @param returnedMessage 失败后将失败信息封装到参数中         */        @Override        public void returnedMessage(ReturnedMessage returnedMessage) &#123;            System.out.println("消息对象："+returnedMessage.getMessage());            System.out.println("错误码："+returnedMessage.getReplyCode());            System.out.println("错误信息："+returnedMessage.getReplyText());            System.out.println("交换机："+returnedMessage.getExchange());            System.out.println("路由键："+returnedMessage.getRoutingKey());            //处理消息。。。。        &#125;    &#125;);    rabbitTemplate.convertAndSend("my_topic_exchange","my_routing1","Send Message...");&#125;</code></pre><p>这里故意把routingKey写错，也是发送不到队列还没有报错</p><p>写错之后的发送</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406183631452.png" alt="image-20220406183631452"></p><h4 id="Ack"><a href="#Ack" class="headerlink" title="Ack"></a>Ack</h4><p>在RabbitMQ中，消费者接收到消息后会向队列发送确认签收的消 息，只有确认签收的消息才会被移除队列。这种机制称为消费者消 息确认（Consumer Acknowledge，简称Ack）。类似快递员派送 快递也需要我们签收，否则一直存在于快递公司的系统中。 消息分为自动确认和手动确认。自动确认指消息只要被消费者接收 到，无论是否成功处理消息，则自动签收，并将消息从队列中移 除。但是在实际开发中，收到消息后可能业务处理出现异常，那么 消息就会丢失。此时需要设置手动签收，即在业务处理成功再通知 签收消息，如果出现异常，则拒签消息，让消息依然保留在队列当中。</p><p>自动确认：spring.rabbitmq.listener.simple.acknowledge&#x3D;”none” </p><p>手动确认：spring.rabbitmq.listener.simple.acknowledge&#x3D;”manual”</p><h5 id="-2"><a href="#-2" class="headerlink" title></a></h5><p>然后就是消费者故意人为的制造一个bug&#x2F;0，控制台直接报错，但是队列中的消息还是被消费完了</p><p>然后再发一次，还是没有成功处理掉，就相当于说消息丢失了，所以在开发的时候更多使用的是手动签收消息</p><h5 id="1-消费者配置开启手动签收"><a href="#1-消费者配置开启手动签收" class="headerlink" title="1 消费者配置开启手动签收"></a>1 消费者配置开启手动签收</h5><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># 配置RabbitMQ</span><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">rabbitmq</span><span class="token punctuation">:</span>    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.8.14    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">5672</span>    <span class="token key atrule">username</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">password</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">virtual-host</span><span class="token punctuation">:</span> /    <span class="token comment" spellcheck="true"># 手动签收</span>    <span class="token key atrule">listener</span><span class="token punctuation">:</span>      <span class="token key atrule">simple</span><span class="token punctuation">:</span>        <span class="token key atrule">acknowledge-mode</span><span class="token punctuation">:</span> manual</code></pre><h5 id="2-消费者处理消息时定义手动签收和拒绝签收的情况"><a href="#2-消费者处理消息时定义手动签收和拒绝签收的情况" class="headerlink" title="2 消费者处理消息时定义手动签收和拒绝签收的情况"></a>2 消费者处理消息时定义手动签收和拒绝签收的情况</h5><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myconsumer1;import com.rabbitmq.client.Channel;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;import java.io.IOException;@Componentpublic class AckConsumer &#123;    //监听队列    @RabbitListener(queues = "my_queue")    public void listenMessage(Message message, Channel channel) throws IOException &#123;        //需要使用信道来完成消息的手动签收        //消息投递序号，消息每次投递该值都会+1        long deliveryTag = message.getMessageProperties().getDeliveryTag();        try &#123;            int i = 1 / 0;//模拟处理消息出现bug            System.out.println("成功接收消息：" + message);            //签收消息            /**             * 参数1：消息投递序号             * 参数2：是否一次可以签收多条消息             */            channel.basicAck(deliveryTag, true);        &#125; catch (Exception e) &#123;            //拒签消息            /**             * 参数1：消息投递序号             * 参数2：是否一次可以拒签多条消息             * 参数3：消息是否可以重回队列             */            channel.basicNack(deliveryTag,true,true);        &#125;    &#125;&#125;</code></pre><p>写好之后重启消费方，并再次发送一条消息，就会一直显示消息消费失败，因为回退了又发过来，就会一直报</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406191805803.png" alt="image-20220406191805803"></p><p>消息是一直在队列中的，处于一个未签收的状态，消息并不会丢失掉</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406192133446.png" alt="image-20220406192133446"></p><p><strong>为了避免大量消息把消费者冲击奔溃，就是暂时存在MQ中</strong></p><p>来看看没有开启限流的一个效果，就会一下全部丢给消费者，测试数据少，要是十万条一下丢呢？？</p><p>不就会内存溢出？内存泄漏？</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406194441454.png" alt="image-20220406194441454"></p><h3 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a>高级特性</h3><h4 id="消费端限流"><a href="#消费端限流" class="headerlink" title="消费端限流"></a>消费端限流</h4><p>MQ可以对请求进行“削峰填谷”，即通过消费端限流的 方式限制消息的拉取速度，达到保护消费端的目的。</p><p>1 生产者批量发送消息</p><p>就是搞个for循环</p><pre class=" language-JAVA"><code class="language-JAVA">@Testpublic void testSendBatch()&#123;    for (int i = 0; i < 20; i++) &#123;        rabbitTemplate.convertAndSend("my_topic_exchange","my_routing","Send Message..."+i);    &#125;&#125;</code></pre><p>2 消费端配置限流机制</p><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># 配置RabbitMQ</span><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">rabbitmq</span><span class="token punctuation">:</span>    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.8.14    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">5672</span>    <span class="token key atrule">username</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">password</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">virtual-host</span><span class="token punctuation">:</span> /    <span class="token key atrule">listener</span><span class="token punctuation">:</span>      <span class="token key atrule">simple</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 限流机制必须开启手动签收</span>        <span class="token key atrule">acknowledge-mode</span><span class="token punctuation">:</span> manual        <span class="token comment" spellcheck="true"># 消费端最多拉去5条消息消费，签收后不满5条才会继续拉去消息</span>        <span class="token key atrule">prefetch</span><span class="token punctuation">:</span> <span class="token number">5</span></code></pre><p>3 消费者监听队列</p><p>新写一个消费方，把之前的消费方的注解注释掉不让它监听了</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myconsumer1;import com.rabbitmq.client.Channel;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;import java.io.IOException;@Componentpublic class OosConsumer &#123;//Oos就是限流的意思    //监听队列    @RabbitListener(queues = "my_queue")    public void listenMessage(Message message, Channel channel) throws IOException, InterruptedException &#123;       //获取消息        System.out.println(new String(message.getBody()));        //2.模拟业务处理        Thread.sleep(3000);        //3.签收消息        channel.basicAck(message.getMessageProperties().getDeliveryTag(), true);    &#125;&#125;</code></pre><p>发个20条的</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406195014144.png" alt="image-20220406195014144"></p><p>看看公平分发因为处理时间不同的效果</p><p>但是第一次是全让消费者1消费了，应该是先把消费者1启动起来了，再发消息看看</p><p>然后就会看见，消费者1很快就处理完了，就是等着消费者2处理</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406204258726.png" alt="image-20220406204258726"></p><p>这就是公平分发的一个效果，所以说公平分发就会造成消费者资源的浪费</p><p>接下来是不公平分发，就是谁处理的快让谁处理的多</p><h4 id="利用限流实现不公平分发"><a href="#利用限流实现不公平分发" class="headerlink" title="利用限流实现不公平分发"></a>利用限流实现不公平分发</h4><p>在RabbitMQ中，多个消费者监听同一条队列，则队列默认采用的 轮询分发。但是在某种场景下这种策略并不是很好，例如消费者1处 理任务的速度非常快，而其他消费者处理速度却很慢。此时如果采 用公平分发，则消费者1有很大一部分时间处于空闲状态。此时可以 采用不公平分发，即谁处理的快，谁处理的消息多。</p><p>1 生产者批量发送消息</p><p>2 消费端配置不公平分发</p><p>然后先把消费端的限流最多拉取5注释掉,也就是把限流给他去掉，弄成1</p><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># 配置RabbitMQ</span><span class="token key atrule">spring</span><span class="token punctuation">:</span>  <span class="token key atrule">rabbitmq</span><span class="token punctuation">:</span>    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.8.14    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">5672</span>    <span class="token key atrule">username</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">password</span><span class="token punctuation">:</span> juejue    <span class="token key atrule">virtual-host</span><span class="token punctuation">:</span> /    <span class="token key atrule">listener</span><span class="token punctuation">:</span>      <span class="token key atrule">simple</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 限流机制必须开启手动签收</span>        <span class="token key atrule">acknowledge-mode</span><span class="token punctuation">:</span> manual        <span class="token comment" spellcheck="true"># 消费端最多拉去5条消息消费，签收后不满5条才会继续拉去消息</span><span class="token comment" spellcheck="true">#        prefetch: 5</span>        <span class="token comment" spellcheck="true"># 消费者最多拉去一条消息进行消费，这样谁处理快谁拉取下一条消息</span>        <span class="token key atrule">prefetch</span><span class="token punctuation">:</span> <span class="token number">1</span></code></pre><p>3 编写两个消费者</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myconsumer1;import com.rabbitmq.client.Channel;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;import java.io.IOException;@Componentpublic class UnfairConsumer &#123;    //消费者1    @RabbitListener(queues = "my_queue")    public void listenMessage1(Message message, Channel channel) throws IOException, InterruptedException &#123;       //获取消息        System.out.println("消费者1："+new String(message.getBody()));        //2.模拟业务处理        Thread.sleep(500);        //3.签收消息        channel.basicAck(message.getMessageProperties().getDeliveryTag(), true);    &#125;    //消费者1    @RabbitListener(queues = "my_queue")    public void listenMessage2(Message message, Channel channel) throws IOException, InterruptedException &#123;        //获取消息        System.out.println("消费者2："+new String(message.getBody()));        //2.模拟业务处理        Thread.sleep(3000);        //3.签收消息        channel.basicAck(message.getMessageProperties().getDeliveryTag(), true);    &#125;&#125;</code></pre><p>真的是，只要配置文件的缩进有一个空格的区别，都会直接报错，运行都运行不了</p><p>来看看，这样就造成了性能的节约，这就是利用限流机制实现不公平分发</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220406212028303.png" alt="image-20220406212028303"></p><h4 id="消息存活时间"><a href="#消息存活时间" class="headerlink" title="消息存活时间"></a>消息存活时间</h4><p>RabbitMQ可以设置消息的存活时间（Time To Live，简称TTL）， 当消息到达存活时间后还没有被消费，会被移出队列。RabbitMQ 可以对队列的所有消息设置存活时间，也可以对某条消息设置存活时间。</p><p><strong>对队列消息设置存活时间，要在创建队列的时候设置</strong></p><p><strong>对某条消息设置存活时间，要在发送消息的时候设置</strong></p><p>注释掉原来生产者（myproducer1）的配置类，复制过来一份</p><p>设置队列消息存活时间</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407092358460.png" alt="image-20220407092358460"></p><p>单条消息设置存活时间</p><pre class=" language-JAVA"><code class="language-JAVA">//发送消息，设置消息的存活时间    @Test    public void testSendMessage()&#123;        //1.创建消息属性        MessageProperties messageProperties = new MessageProperties();        //2.设置存活时间        messageProperties.setExpiration("10000");        //3.创建消息对象        Message message = new Message("send Message,...".getBytes(),messageProperties);        //4.发送消息        rabbitTemplate.convertAndSend("my_topic_exchange","my_routing",message);    &#125;</code></pre><p>接下里注意两个事情</p><h5 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h5><p>1 如果设置了单条消息的存活时间，也设置了队列的存活时 间，以时间短的为准。</p><p>2 消息过期后，并不会马上移除消息，只有<strong>消息消费到队列顶端</strong>时，才会移除该消息。</p><h4 id="优先级队列"><a href="#优先级队列" class="headerlink" title="优先级队列"></a>优先级队列</h4><p>假设在电商系统中有一个订单催付的场景，即客户在一段时间内未 付款会给用户推送一条短信提醒，但是系统中分为大型商家和小型商家。比如像苹果，小米这样大商家一年能给我们创造很大的利润，所以在订单量大时，他们的订单必须得到优先处理，此时就需 要为不同的消息设置不同的优先级，此时我们要使用优先级队列。    优先级数值越大，越先被消费</p><p>1 创建队列和交换机</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myproducer1;import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;//@Configurationpublic class RabbitConfig3 &#123;    private final String EXCHANGE_NAME = "priority_exchange";    private final String QUEUE_NAME = "priority_queue";    // 创建交换机    @Bean(EXCHANGE_NAME)    public Exchange getExchange() &#123;        return ExchangeBuilder                .topicExchange(EXCHANGE_NAME) // 交换机类型                .durable(true) // 是否持久化                .build();    &#125;    // 创建队列    @Bean(QUEUE_NAME)    public Queue getMessageQueue() &#123;        return QueueBuilder                .durable(QUEUE_NAME)//队列持久化                .maxPriority(10)//设置队列的最大优先级，最大可以到255，官网推荐不超过10，太高比较浪费资源                .build();    &#125;    // 交换机绑定队列    @Bean//参数的交换机和队列都是从spring容器中拿的    public Binding bindMessageQueue(@Qualifier(EXCHANGE_NAME) Exchange exchange, @Qualifier(QUEUE_NAME) Queue queue) &#123;        return BindingBuilder                .bind(queue)                .to(exchange)                .with("my_routing").noargs();    &#125;&#125;</code></pre><p>2 编写生产者</p><pre class=" language-JAVA"><code class="language-JAVA">@Testpublic void testPriority()&#123;    for (int i = 0; i < 10; i++) &#123;        if (i==5)&#123;//i为5时优先级较高            //1.创建消息属性            MessageProperties messageProperties = new MessageProperties();            //2.设置优先级            messageProperties.setPriority(9);            //3.创建消息对象            Message message = new Message(("send Message,..."+i).getBytes(),messageProperties);            //4.发送消息            rabbitTemplate.convertAndSend("priority_exchange","my_routing",message);        &#125;else &#123;            rabbitTemplate.convertAndSend("priority_exchange","my_routing","send Message");        &#125;    &#125;&#125;</code></pre><p>3 编写消费者</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myconsumer1;import com.rabbitmq.client.Channel;import org.springframework.amqp.core.Message;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.stereotype.Component;import java.io.IOException;@Componentpublic class PriorityConsumer &#123;//    @RabbitListener(queues = "priority_queue")    public void listenMessage(Message message, Channel channel) throws IOException &#123;        //获取消息        System.out.println(new String(message.getBody()));        //签收消息        channel.basicAck(message.getMessageProperties().getDeliveryTag(), true);    &#125;&#125;</code></pre><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407101710237.png" alt="image-20220407101710237"></p><h4 id="死信队列"><a href="#死信队列" class="headerlink" title="死信队列"></a>死信队列</h4><p>在MQ中，当消息成为死信（Dead message）后，消息中间件可以 将其从当前队列发送到另一个队列中，这个队列就是死信队列。而 在RabbitMQ中，由于有交换机的概念，实际是将死信发送给了死信交换机（Dead Letter Exchange，简称DLX）。死信交换机和死信队列和普通的没有区别。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407182948566.png" alt="image-20220407182948566"></p><p>消息成为死信的情况： </p><p>1 队列消息长度到达限制。 </p><p>2 消费者拒签消息，并且不把消息重新放入原队列。 </p><p>3 消息到达存活时间未被消费。</p><h5 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h5><p>创建死信队列</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myproducer1;import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class RabbitConfig4 &#123;    private final String DEAD_EXCHANGE = "dead_exchange";    private final String DEAD_QUEUE = "dead_queue";    private final String NORMAL_EXCHANGE = "normal_exchange";    private final String NORMAL_QUEUE = "normal_queue";    // 死信交换机    @Bean(DEAD_EXCHANGE)    public Exchange deadExchange() &#123;        return ExchangeBuilder                .topicExchange(DEAD_EXCHANGE) // 交换机类型                .durable(true) // 是否持久化                .build();    &#125;    // 死信队列    @Bean(DEAD_QUEUE)    public Queue deadQueue() &#123;        return QueueBuilder                .durable(DEAD_QUEUE)                .build();    &#125;    // 死信交换机绑定死信队列    @Bean    public Binding bindDeadQueue(@Qualifier(DEAD_EXCHANGE) Exchange exchange, @Qualifier(DEAD_QUEUE) Queue queue) &#123;        return BindingBuilder                .bind(queue)                .to(exchange)                .with("dead_routing").noargs();    &#125;    //普通交换机    @Bean(NORMAL_EXCHANGE)    public Exchange normalExchange() &#123;        return ExchangeBuilder                .topicExchange(NORMAL_EXCHANGE) // 交换机类型                .durable(true) // 是否持久化                .build();    &#125;    // 普通队列    @Bean(NORMAL_QUEUE)    public Queue normalQueue() &#123;        return QueueBuilder                .durable(NORMAL_QUEUE)                .deadLetterExchange(DEAD_EXCHANGE)//绑定死信交换机                .deadLetterRoutingKey("dead_routing")//死信队列路由关键字                .ttl(10000)//消息存活10秒                .maxLength(10)//队列最大长度为10                .build();    &#125;    // 普通交换机绑定普通队列    @Bean    public Binding bindMessageQueue(@Qualifier(NORMAL_EXCHANGE) Exchange exchange, @Qualifier(NORMAL_QUEUE) Queue queue) &#123;        return BindingBuilder                .bind(queue)                .to(exchange)                .with("my_routing").noargs();    &#125;&#125;</code></pre><h6 id="注意：-1"><a href="#注意：-1" class="headerlink" title="注意："></a>注意：</h6><p><strong>普通队列绑定死信队列时，需要绑定死信交换机和死信队列的路由关键字</strong></p><h5 id="测试死信队列"><a href="#测试死信队列" class="headerlink" title="测试死信队列"></a>测试死信队列</h5><p>1 生产者发送消息</p><pre class=" language-JAVA"><code class="language-JAVA">  @Test    public void testDlx()&#123;        //存活时间过期后变成死信//        rabbitTemplate.convertAndSend("normal_exchange","my_routing","测试死信！");        //超过队列长度后变成死信//        for (int i = 0; i < 20; i++) &#123;//            rabbitTemplate.convertAndSend("normal_exchange","my_routing","测试死信！");//        &#125;        //消息拒签但不返回原队列后变成死信        rabbitTemplate.convertAndSend("normal_exchange","my_routing","测试死信！");    &#125;</code></pre><p>存活时间过期</p><p>消息超时放到死信队列中</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407135305003.png" alt="image-20220407135305003"></p><p>超出长度后放到死信队列当中</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407135748948.png" alt="image-20220407135748948"></p><p>拒签</p><p>因为忘记开消费者，所以之前发的一条消息超时放进去变24，然后先开启拒签消费者再发送</p><p>然后消费方开不起来，一看，消费方没加@Component</p><p>一发完就直接拒签进死信，完全不放原来队列</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407140653964.png" alt="image-20220407140653964"></p><h4 id="延迟队列"><a href="#延迟队列" class="headerlink" title="延迟队列"></a>延迟队列</h4><p>延迟队列，即消息进入队列后不会立即被消费，只有到达指定时间 后，才会被消费。 例如：用户下单后，30分钟后查询订单状态，未支付则会取消订单。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407184303377.png" alt="image-20220407184303377"></p><p>但RabbitMQ中并未提供延迟队列功能，我们可以使用死信队列实现延迟队列的效果。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407184325497.png" alt="image-20220407184325497"></p><h5 id="死信队列实现"><a href="#死信队列实现" class="headerlink" title="死信队列实现"></a>死信队列实现</h5><h5 id="插件实现"><a href="#插件实现" class="headerlink" title="插件实现"></a>插件实现</h5><p>在使用死信队列实现延迟队列时，会遇到一个问题：RabbitMQ只 会移除队列顶端的过期消息，如果第一个消息的存活时长较长，而 第二个消息的存活时长较短，则第二个消息并不会及时执行。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407194715665.png" alt="image-20220407194715665"></p><p>RabbitMQ虽然本身不能使用延迟队列，但官方提供了延迟队列插 件，安装后可直接使用延迟队列。</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407194730806.png" alt="image-20220407194730806"></p><h6 id="安装延迟队列插件"><a href="#安装延迟队列插件" class="headerlink" title="安装延迟队列插件"></a>安装延迟队列插件</h6><p>1 上传至&#x2F;usr&#x2F;local&#x2F;rabbitmq&#x2F;plugins&#x2F;下</p><p>2 启用插件</p><pre class=" language-bash"><code class="language-bash">rabbitmq-plugins <span class="token function">enable</span> rabbitmq_delayed_message_exchange</code></pre><p>3 重启RabbitMQ服务</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#停止rabbitmq</span>rabbitmqctl stop<span class="token comment" spellcheck="true">#启动rabbitmq</span>rabbitmq-server restart -detached</code></pre><p>这样就把延队列的一个插件安装成功了，此时登录管控台可以看到交换机类型多了延迟消息</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407185450590.png" alt="image-20220407185450590"></p><h6 id="使用延迟队列"><a href="#使用延迟队列" class="headerlink" title="使用延迟队列"></a>使用延迟队列</h6><p>1 创建延迟交换机和延迟队列</p><pre class=" language-JAVA"><code class="language-JAVA">package com.jian.myorder;import org.springframework.amqp.core.*;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.HashMap;import java.util.Map;@Configurationpublic class RabbitConfig2 &#123;    public final String DELAYED_EXCHANGE = "delayed_exchange";    public final String DELAYED_QUEUE = "delayed_queue";    //1.延迟交换机    @Bean(DELAYED_EXCHANGE)    public Exchange delayedExchange() &#123;        // 创建自定义交换机        Map<String, Object> args = new HashMap<>();        //就是延迟交换机也是有实际类型的        args.put("x-delayed-type","topic"); // topic类型的延迟交换机        //参数：交换机名字，类型，是否持久化，是否自动删除        return new CustomExchange(DELAYED_EXCHANGE, "x-delayed-message", true, false, args);    &#125;    //2.延迟队列    @Bean(DELAYED_QUEUE)    public Queue delayedQueue() &#123;        return QueueBuilder                .durable(DELAYED_QUEUE)                .build();    &#125;    // 3.绑定    @Bean    public Binding    bindingDelayedQueue(@Qualifier(DELAYED_QUEUE) Queue queue, @Qualifier(DELAYED_EXCHANGE) Exchange exchange) &#123;        return BindingBuilder                .bind(queue)                .to(exchange)                .with("order_routing").noargs();    &#125;&#125;</code></pre><p>就不能使用ExchangeBuilder去创建交换机了，因为没有</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407185932617.png" alt="image-20220407185932617"></p><p>需要注意的一点就是我们创建延迟队列的时候没有办法去设置消息的延迟时间，只有在发送消息的时候才能去设置一个延迟时间</p><p>2 编写下单的控制器方法</p><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">//插件下单</span><span class="token annotation punctuation">@GetMapping</span><span class="token punctuation">(</span><span class="token string">"/place2/&amp;#123;orderId&amp;#125;"</span><span class="token punctuation">)</span><span class="token keyword">public</span> String <span class="token function">placeOrders</span><span class="token punctuation">(</span><span class="token annotation punctuation">@PathVariable</span> String orderId<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"处理订单数据---插件实现延迟队列？"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//设置延迟时间10s</span>    MessagePostProcessor messagePostProcessor <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">MessagePostProcessor</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> Message <span class="token function">postProcessMessage</span><span class="token punctuation">(</span>Message message<span class="token punctuation">)</span> <span class="token keyword">throws</span> AmqpException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            message<span class="token punctuation">.</span><span class="token function">getMessageProperties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setDelay</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> message<span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//将订单id发送到订单队列</span>    rabbitTemplate<span class="token punctuation">.</span><span class="token function">convertAndSend</span><span class="token punctuation">(</span><span class="token string">"delayed_exchange"</span><span class="token punctuation">,</span><span class="token string">"order_routing"</span><span class="token punctuation">,</span>orderId<span class="token punctuation">,</span>messagePostProcessor<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token string">"下单成功，修改库存--插件"</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p>3 编写延迟队列的消费者</p><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">//监听过期订单的队列，普通订单队列是不需要监听的</span><span class="token annotation punctuation">@RabbitListener</span><span class="token punctuation">(</span>queues <span class="token operator">=</span> <span class="token string">"delayed_queue"</span><span class="token punctuation">)</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">listenMessage2</span><span class="token punctuation">(</span>String orderId<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"查询"</span><span class="token operator">+</span>orderId<span class="token operator">+</span><span class="token string">"号订单的状态，如果已支付无需处理，如果未支付则回退库存"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p>访问测试</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407194248473.png" alt="image-20220407194248473"></p><p>然后发消息之后，队列中也是没有显示的，直接就给消费者了。然后消费者等了10s之后才去消费</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407194429308.png" alt="image-20220407194429308"></p><p>然后就是使用插件比较方便一些，就没有必要去创建那么多的交换机和队列</p><h4 id="搭建集群"><a href="#搭建集群" class="headerlink" title="搭建集群"></a>搭建集群</h4><p>就是单台MQ无法满足消息的吞吐量以及安全性要求的时候，就比如无法满足消息的吞吐量：RabbitMQ每秒能接收1万条消息，但是系统能生产5万</p><p>安全性：单台宕机</p><p>这里就一个机器设置两个RabbitMQ服务了</p><p>1 设置两个RabbitMQ服务</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 关闭RabbitMQ服务</span>rabbitmqctl stop<span class="token comment" spellcheck="true"># 设置服务一</span>RABBITMQ_NODE_PORT<span class="token operator">=</span>5673 RABBITMQ_NODENAME<span class="token operator">=</span>rabbit1 rabbitmq-server start -detached<span class="token comment" spellcheck="true"># 设置服务二</span>RABBITMQ_NODE_PORT<span class="token operator">=</span>5674 RABBITMQ_SERVER_START_ARGS<span class="token operator">=</span><span class="token string">"-rabbitmq_management listener [&amp;#123;port,15674&amp;#125;]"</span> RABBITMQ_NODENAME<span class="token operator">=</span>rabbit2 rabbitmq-server start -detached这里只是启动了两个服务，不是在一个集群里，然后启动后之前创建的数据都会丢失，包括创建的页面</code></pre><p>2 将两个服务设置到同一集群中</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 关闭服务2</span>rabbitmqctl -n rabbit2 stop_app    <span class="token comment" spellcheck="true"># 重新设置服务2</span>rabbitmqctl -n rabbit2 reset<span class="token comment" spellcheck="true"># 将服务2加入服务1中</span>rabbitmqctl -n rabbit2 join_cluster rabbit1@localhost<span class="token comment" spellcheck="true"># 启动服务2</span>rabbitmqctl -n rabbit2 start_app</code></pre><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407203916178.png" alt="image-20220407203916178"></p><p>5672希望留给负载均衡服务器用</p><p>将服务2加入服务1中,网上看的都是装在windows的cookie不一致</p><p>然后我去分别看了一下</p><p>&#x2F;root&#x2F;.erlang.cookie         ~&#x2F;.erlang.cookie </p><p>里面的cookie是一样的</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407211558045.png" alt="image-20220407211558045"></p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407210329849.png" alt="image-20220407210329849"></p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407211610431.png" alt="image-20220407211610431"></p><p>我就是加不进去啊！！就先放着吧，也不知道啥问题</p><h4 id="镜像队列"><a href="#镜像队列" class="headerlink" title="镜像队列"></a>镜像队列</h4><p>搭建了集群后，虽然多个节点可以互相通信，但队列只保存在了一 个节点中，如果该节点故障，则整个集群都将丢失消息。</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 关闭服务1</span>rabbitmqctl -n rabbit1 stop_app</code></pre><p>2就访问不到了废了</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407213037708.png" alt="image-20220407213037708"></p><p>此时我们需要引入镜像队列机制，它可以将队列消息复制到集群中的其他节点上。如果一个节点失效了，另一个节点上的镜像可以保证服务的可用性。</p><p>在管控台点击 Admin —&gt; Policies 设置镜像队列</p><p><img src="/2022/04/08/rabbitmq-bi-ji/image-20220407213059056.png" alt="image-20220407213059056"></p><p>此时某个节点故障则不会影响整个集群。</p><h4 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h4><p>无论是生产者还是消费者，只能连接一个RabbitMQ节点，而在我 们使用RabbitMQ集群时，如果只连接一个RabbitMQ节点，会造成 该节点的压力过大。我们需要平均的向每个RabbitMQ节点发送请 求，此时需要一个负载均衡工具帮助我们分发请求，接下来使用 Haproxy做负载均衡：</p><p>1 安装Haproxy</p><pre class=" language-bash"><code class="language-bash">yum -y <span class="token function">install</span> haproxy</code></pre><p>2 配置Haproxy</p><pre class=" language-bash"><code class="language-bash">vim /etc/haproxy/haproxy.cfg</code></pre><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 以下为修改内容</span>defaults <span class="token comment" spellcheck="true"># 修改为tcp</span> mode tcp<span class="token comment" spellcheck="true"># 以下为添加内容</span>listen rabbitmq_cluster <span class="token comment" spellcheck="true"># 对外暴露端口</span>       bind 0.0.0.0:5672       mode tcp       balance roundrobin       <span class="token comment" spellcheck="true"># 代理RabbitMQ的端口</span>       server node1 127.0.0.1:5673 check inter 5000 rise 2 fall 2       server node2 127.0.0.1:5674 check inter 5000 rise 2 fall 2listen stats <span class="token comment" spellcheck="true"># Haproxy控制台路径</span>       bind 192.168.0.162:8100       mode http       option httplog       stats <span class="token function">enable</span>       stats uri /rabbitmq-stats       stats refresh 5s</code></pre><p>3 启动Haproxy    </p><pre class=" language-bash"><code class="language-bash">haproxy -f /etc/haproxy/haproxy.cfg    </code></pre><p>4 访问Haproxy控制台：<a href="http://192.168.0.162:8100/rabbitmq-stats">http://192.168.0.162:8100/rabbitmq-stats</a></p><p>5 生产者连接Haproxy发送消息</p><pre class=" language-JAVA"><code class="language-JAVA">// 生产者public class Producer &#123;    public static void main(String[] args)throws IOException, TimeoutException &#123;        ConnectionFactory connectionFactory = newConnectionFactory();              connectionFactory.setHost("192.168.0.162");        connectionFactory.setPort(5672);              connectionFactory.setUsername("guest");              connectionFactory.setPassword("guest");              connectionFactory.setVirtualHost("/");        Connection conn = connectionFactory.newConnection();        Channel channel = conn.createChannel();              channel.queueDeclare("simple_queue",false, false, false, null);        channel.basicPublish("","simple_queue", null,"hello!rabbitmq!".getBytes());        channel.close();        conn.close();   &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper笔记2</title>
      <link href="/2022/04/01/zookeeper-bi-ji-2/"/>
      <url>/2022/04/01/zookeeper-bi-ji-2/</url>
      
        <content type="html"><![CDATA[<hr><h3 id="集中式到分布式"><a href="#集中式到分布式" class="headerlink" title="集中式到分布式"></a>集中式到分布式</h3><p>集群：多个人在一起做同样的事</p><p>分布式：多个人在一起做不同的事情</p><h4 id="单机架构"><a href="#单机架构" class="headerlink" title="单机架构"></a>单机架构</h4><p>一个系统业务量很小的时候所有的代码都放在一个项目中就好了， 然后这个项目部署在一台服务器上，整个项目所有的服务都由这台 服务器提供。</p><h5 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h5><ul><li>服务性能存在瓶颈 </li><li>不可伸缩性 </li><li>代码量庞大，系统臃肿，牵一发动全身 </li><li>单点故障问题</li></ul><h4 id="集群架构"><a href="#集群架构" class="headerlink" title="集群架构"></a>集群架构</h4><p>单机处理到达瓶颈的时候，你就把单机复制几份，这样就构成了一个集群。</p><h5 id="集群存在的问题"><a href="#集群存在的问题" class="headerlink" title="集群存在的问题:"></a>集群存在的问题:</h5><p>当你的业务发展到一定程度的时候，你会发现一个问题无论怎 么增加节点，貌似整个集群性能的提升效果并不明显了。这时 候，你就需要使用分布式架构了。</p><h4 id="什么是分布式"><a href="#什么是分布式" class="headerlink" title="什么是分布式"></a>什么是分布式</h4><p>分布式架构就是将一个完整的系统，按照业务功能，拆分成一个个 独立的子系统，在分布式结构中，每个子系统就被称为“服务”。这 些子系统能够独立运行在web容器中，它们之间通过RPC方式通信。</p><h5 id="分布式的优势"><a href="#分布式的优势" class="headerlink" title="分布式的优势:"></a>分布式的优势:</h5><ul><li>系统之间的耦合度大大降低，可以独立开发、独立部署、独立测试，系统与系统之间的边界 非常明确，排错也变得相当容易，开发效率大大提升。</li></ul><ul><li><p>系统之间的耦合度降低，从而系统更易于扩展。我们可以针对性地扩展某些服务。 </p></li><li><p>服务的复用性更高。比如，当我们将用户系统作为单独的服务后，该公司所有的产品都可以 使用该系统作为用户系统，无需重复开发。</p></li></ul><h4 id="三者区别"><a href="#三者区别" class="headerlink" title="三者区别"></a>三者区别</h4><p>我的理解就是，首先我们有一个小饭店，有洗菜、炒菜、切菜、上菜、备料、收银等操作</p><h5 id="单机："><a href="#单机：" class="headerlink" title="单机："></a>单机：</h5><p>一个厨师全干！</p><h5 id="集群："><a href="#集群：" class="headerlink" title="集群："></a>集群：</h5><p>好多个厨师一起做这些活。</p><h5 id="分布式："><a href="#分布式：" class="headerlink" title="分布式："></a>分布式：</h5><p>就有点像大酒店一样，会计，服务员，出事，配菜的人，专门洗菜的人，专门炒菜的厨师。</p><h5 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h5><p>将一套系统拆分成不同子系统部署在不同服务器上（这叫分布 式），然后部署多个相同的子系统在不同的服务器上（这叫集群）。</p><h3 id="CAP定理"><a href="#CAP定理" class="headerlink" title="CAP定理"></a>CAP定理</h3><p>分布式系统的最大难点，就是各个节点的状态如何同步。CAP 定理是这 方面的基本定理，也是理解分布式系统的起点。</p><ul><li>Consistency（一致性） </li><li>Availability （可用性） </li><li>Partition tolerance （分区容错性）</li></ul><p>这三个指标不可能同时做到。这个结论就叫做 CAP 定理。</p><h5 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h5><p>分区容错性是无法避免的，因此可以认为 CAP的 P总是成立。CAP 定 理告诉我们，剩下的 C 和 A 无法同时做到。</p><h5 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h5><p>就是老板和一个服务员A说这个菜价变了，然后别人问另一个服务员B的时候，B只能告诉顾客，菜价还在商定。</p><h5 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h5><p>只要收到用户的请求，服务器就必须给出回应。</p><p>就是不管价格变V0还是V1，只要问了，就必须告诉他</p><h4 id="一致性和可用性如何选择"><a href="#一致性和可用性如何选择" class="headerlink" title="一致性和可用性如何选择"></a>一致性和可用性如何选择</h4><ul><li><h6 id="一致性-1"><a href="#一致性-1" class="headerlink" title="一致性"></a>一致性</h6><p>特别是涉及到重要的数据，就比如钱，商品数量，商品价格。 </p></li><li><h6 id="可用性-1"><a href="#可用性-1" class="headerlink" title="可用性"></a>可用性</h6></li></ul><p>​        网页的更新不是特别强调一致性，短时期内，一些用户拿到老版 本，另一些用户拿到新版本，问题不会特别大。</p><p>外部系统</p><p>分布式服务平台–统一接入管理</p><p>公共服务平台、核心交易平台、信息服务平台、交易后处理平台</p><h5 id="多个节点协同问题"><a href="#多个节点协同问题" class="headerlink" title="多个节点协同问题"></a>多个节点协同问题</h5><p>1.每天的定时任务由哪个节点来执行</p><p>2.RPC调用时的服务发现</p><p>3.如何保证并发请求的幂等</p><p>这些问题可以统一归纳为多节点协调问题，如果靠节点自身进 行协调这是非常不可靠的，性能上也不可取。必须由一个独立 的服务做协调工作，它必须可靠，而且保证性能。</p><p>所以zookeeper就出现发挥作用了</p><h3 id="Zookeeper介绍"><a href="#Zookeeper介绍" class="headerlink" title="Zookeeper介绍"></a>Zookeeper介绍</h3><p>zookeeper是什么，一句话概括，就是文件系统+监听机制     </p><p>ZooKeeper是一个开放源代码的分布式协调服务。ZooKeeper的设 计目标是将那些复杂且容易出错的分布式一致性服务封装起来,构成 一个高效可靠的原语集,并以一系列简单易用的接口提供给用户使用。</p><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>数据发布订阅、负载均衡、命名服务、分布式协调通知</p><h4 id="数据发布-x2F-订阅"><a href="#数据发布-x2F-订阅" class="headerlink" title="数据发布&#x2F;订阅"></a>数据发布&#x2F;订阅</h4><p>数据发布&#x2F;订阅的一个常见的场景是配置中心，发布者把数据发布到 ZooKeeper 的一个或一系列的节点上，供订阅者进行数据订阅，达 到动态获取数据的目的。</p><p>ZooKeeper 采用的是推拉结合的方式。 </p><p>1 推: 服务端会推给注册了监控节点的客户端 Wathcer 事件通知 </p><p>2 拉: 客户端获得通知后，然后主动到服务端拉取最新的数据</p><h4 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h4><p>负载均衡是一种手段，用来把对某种资源的访问分摊给不同的设 备，从而<strong>减轻单点</strong>的压力。</p><h4 id="命名服务"><a href="#命名服务" class="headerlink" title="命名服务"></a>命名服务</h4><p>命名服务就是提供名称的服务。ZooKeeper 的命名服务有两个应用方面。</p><h5 id="功能："><a href="#功能：" class="headerlink" title="功能："></a>功能：</h5><p>1 提供类 JNDI 功能，可以把系统中各种服务的名称、地址以及目录信息存放在 ZooKeeper， 需要的时候去 ZooKeeper 中读取  </p><p>2 制作分布式的序列号生成器 </p><h4 id="分布式协调-x2F-通知"><a href="#分布式协调-x2F-通知" class="headerlink" title="分布式协调&#x2F;通知"></a>分布式协调&#x2F;通知</h4><p>分布式协调&#x2F;通知服务是分布式系统中不可缺少的一个环节,是将不同 的分布式组件有机结合起来的关键所在。对于一个在多台机器上部 署运行的应用而言，通常需要一个协调者(Coordinator）来控制整 个系统的运行流程。</p><h3 id="为什么选择Zookeeper"><a href="#为什么选择Zookeeper" class="headerlink" title="为什么选择Zookeeper"></a>为什么选择Zookeeper</h3><p>分布式架构的出现，越来越多的分布式应用会面临数据一致性 问题。很遗憾的是，在解决分布式数据一致性上，除了ZooKeeper 之外，目前还没有一个成熟稳定且被大规模应用的解决方案。</p><p>ZooKeeper无论从易用性还是稳定性上来说，都已经达到了一 个工业级产品的标准。</p><p>还是免费的。</p><h5 id="广泛应用"><a href="#广泛应用" class="headerlink" title="广泛应用"></a>广泛应用</h5><p>最后，ZooKeeper已经得到了广泛的应用。诸如Hadoop、 HBase、Storm、kafka等越来越多的大型分布式项目都将 Zookeeper作为核心组件。</p><h4 id="集群角色"><a href="#集群角色" class="headerlink" title="集群角色"></a>集群角色</h4><p>通常在分布式系统中，构成一个集群的每一台机器都有自己的角 色，最典型的集群模式就是Master&#x2F;Slave模式（主备模式)。在这种 模式中，我们把能够处理所有写操作的机器称为Master机器，把所 有通过异步复制方式获取最新数据，并提供读服务的机器称为Slave 机器。</p><h5 id="概念颠覆："><a href="#概念颠覆：" class="headerlink" title="概念颠覆："></a>概念颠覆：</h5><p>而在ZooKeeper中，这些概念被颠覆了。它没有沿用传统的 MasterlSlave概念，而是引入了Leader、Follower和 Observer 三种角色。</p><h5 id="数据节点Znode"><a href="#数据节点Znode" class="headerlink" title="数据节点Znode"></a>数据节点Znode</h5><p>ZooKeeper将所有数据存储在内存中，数据模型是一棵树。</p><h4 id="Watcher监听机制"><a href="#Watcher监听机制" class="headerlink" title="Watcher监听机制"></a>Watcher监听机制</h4><p> Watcher(事件监听器)，是ZooKeeper 中的一个很重要的特性。</p><p>ZooKeeper 允许用户在指定节点上注册一些Watcher，并且在 一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到 感兴趣的客户端上去，该机制是ZooKeeper实现分布式协调服务的重要特性。</p><p>比较普通的为数据修改和节点修改（包括删除）</p><h4 id="ACL权限控制"><a href="#ACL权限控制" class="headerlink" title="ACL权限控制"></a>ACL权限控制</h4><p>ZooKeeper 采用ACL (Access Control Lists）策略来进行权限控 制，类似于UNIX文件系统的权限控制。ZooKeeper定义了如下5种 权限。</p><p>CREATE:创建子节点的权限 </p><p>READ:获取节点数据和子节点列表的权限 </p><p>WRITE:更新节点数据的权限 </p><p>DELETE:删除子节点的权限 </p><p>ADMIN:设置节点ACL的权限</p><p>注：create和delete这两种权限都是针对子节点的权限控制。</p><h3 id="集群安装"><a href="#集群安装" class="headerlink" title="集群安装"></a>集群安装</h3><p>创建三台机器，因为配置好了电脑和Vmware的网络，还是dhcp，所以他们的ip就分别为192.168.8.14    192.168.8.15   192.168.8.16</p><p>设置开机激活网卡</p><p>设置关闭防火墙</p><p>这样才能使用Xshell远程连接上</p><p>搭建好第一台机器的zookeeper之后，别的集群机器就不用再重复一样的操作了</p><p>直接传jdk过去</p><p>新版本的搭建zookeeper伪集群</p><p>$PATH相当于是获取计算机之前的环境变量，然后通过冒号再拼接一个刚刚编写的环境变量</p><p>但是再windows里面是%获取</p><pre class=" language-none"><code class="language-none">#  $# 启动脚本携带的参数个数#  -ne 不等于</code></pre><h4 id><a href="#" class="headerlink" title></a></h4><p>服务器与服务器之间可以通过scp这个命令去传</p><pre class=" language-none"><code class="language-none">scp -r jdk/ 198.168.xx.xx:$PWD递归传        就是这台机器什么目录就传给那台机器什么目录 也可以写死:/usr/local/xx</code></pre><p>回车之后就要输入yes和密码</p><p>传zookeeper也是同样的传法</p><p>然后就是和第一台机器一样配置一下环境变量 和让他重新生效一下</p><p>然后三台机器都再配置文件上加上，几台就配几个</p><pre class=" language-none"><code class="language-none">server.1=192.168.8.14:2888:3888server.2=192.168.8.15:2888:3888server.3=192.168.8.16:2888:3888</code></pre><p>然后配置好之后把这个配置文件直接发送给别的机器就行</p><p>然后三台机器的配置文件都是一摸一样的，就得有一个机器的标识</p><p>然后用重定向echo写一下</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191549565.png" alt="image-20220403191549565"></p><p>我就直接配置好一台然后虚拟机拷贝s修改了。。。</p><p>创建数据持久化目录</p><pre class=" language-none"><code class="language-none">mkdir /usr/local/zookeeper/zkdatamkdir /usr/local/zookeeper/zklogs</code></pre><p>配置JDK环境</p><p>vim &#x2F;etc&#x2F;profile  最后这两个</p><pre class=" language-none"><code class="language-none">export JAVA_HOME=/usr/local/jdkexport PATH=$PATH:$JAVA_HOME/bin</code></pre><p>生效环境变量</p><pre class=" language-none"><code class="language-none">source /etc/profile</code></pre><p>然后可以java -version 看一下</p><h5 id="设置一键启动-x2F-一键停止脚本"><a href="#设置一键启动-x2F-一键停止脚本" class="headerlink" title="设置一键启动&#x2F;一键停止脚本"></a><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403190515065.png" alt="image-20220403190515065">设置一键启动&#x2F;一键停止脚本</h5><pre class=" language-sh"><code class="language-sh">if [ $# -ne 1 ];then   echo "无效参数，用法为: $1 &#123;start|stop|restart|status&#125;"   exitfi#遍历所有节点for host in 192.168.8.14 192.168.8.15 192.168.8.16do   echo "========== $host 正在 $1 ========="   #发送命令给目标机器   ssh $host "source /etc/profile; /usr/local/zookeeper/bin/zkServer.sh $1"done</code></pre><p>然后就是给权限</p><p>chmod  777 文件名</p><p>然后启动一下</p><pre class=" language-none"><code class="language-none">./zkStart-all.sh start</code></pre><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191349175.png" alt="image-20220403191349175"></p><p>查看状态</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191355180.png" alt="image-20220330161453551"></p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191359971.png" alt="image-20220403191359971">一个leader (zk-02)两个follower</p><p>节点类型也就还是那四种，持久化，临时；有序无序；看需求2选一组合</p><h3 id="节点特性"><a href="#节点特性" class="headerlink" title="节点特性"></a>节点特性</h3><h4 id="持久节点"><a href="#持久节点" class="headerlink" title="持久节点"></a>持久节点</h4><p>持久节点是zookeeper中最常见的一种节点类型。所谓持久节点， 是指改数据节点被创建后，就会一直存在与zookeeper服务器上， 直到有删除操作来主动清除这个节点。</p><h4 id="持久顺序节点"><a href="#持久顺序节点" class="headerlink" title="持久顺序节点"></a>持久顺序节点</h4><p>这类节点的基本特性和上面的节点类型是一致的。额外的特性是， 在ZK中，每个父节点会为他的第一级子节点维护一份时序，会记录 每个子节点创建的先后顺序。</p><h4 id="临时节点"><a href="#临时节点" class="headerlink" title="临时节点"></a>临时节点</h4><p>区别： 和持久节点不同的是，临时节点的生命周期和客户端会话绑定。也就是说，如果客户端会话失效，那么这个节点就会自动被清除掉。注意，这里提到的是会话失效，而非连接断开。另 外，在临时节点下面不能创建子节点。</p><h4 id="临时顺序节点"><a href="#临时顺序节点" class="headerlink" title="临时顺序节点"></a>临时顺序节点</h4><p>临时顺序节点的基本特性和临时节点是一致的，同样是在临时节点 的基础上，添加了顺序的特性。</p><h3 id="客户端命令行"><a href="#客户端命令行" class="headerlink" title="客户端命令行"></a>客户端命令行</h3><p>create [-s] [-e] path data acl</p><p>参数：</p><p>-s：顺序节点 </p><p>-e：临时节点 </p><p>默认情况下，不添加-s或者-e参数的，创建的是持久节点。</p><p>ls &#x2F;路径   </p><p>读取节点信息</p><p>set &#x2F;路径 data</p><p>更新节点数据</p><p>get &#x2F;路径 </p><p>获取zookeeper指定节点的数据内容和属性信息。</p><p>delete path [version]</p><p>删除指定节点，有子节点就报错</p><h4 id="节点信息"><a href="#节点信息" class="headerlink" title="节点信息"></a>节点信息</h4><p>上一篇笔记有，不过这里有图</p><h3 id="Watcher监听机制-1"><a href="#Watcher监听机制-1" class="headerlink" title="Watcher监听机制"></a><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191407815.png" alt="image-20220403191407815">Watcher监听机制</h3><p>监听节点变化</p><pre class=" language-none"><code class="language-none">ls -w path</code></pre><p>监听节点的值的变化</p><pre class=" language-none"><code class="language-none">get -w path</code></pre><h5 id="Watcher-特性总结"><a href="#Watcher-特性总结" class="headerlink" title="Watcher 特性总结"></a>Watcher 特性总结</h5><h6 id="一次性"><a href="#一次性" class="headerlink" title="一次性"></a>一次性</h6><p>无论是服务端还是客户端，一旦一个 Watcher 被触发，ZooKeeper 都会将其从相应的存储中移除。因此，在 Watcher 的使用上，需要 反复注册。这样的设计有效地减轻了服务端的压力。</p><h5 id="客户端串行执行"><a href="#客户端串行执行" class="headerlink" title="客户端串行执行"></a>客户端串行执行</h5><p>客户端 Watcher 回调的过程是一个<strong>串行同步</strong>的过程，这为我们保证了顺序，同时，需要注意的一点是，一定不能因为一个 Watcher 的处理逻辑影响了整个客户端的 Watcher 回调。</p><p>轻量 WatcherEvent 是 ZooKeeper 整个 Watcher 通知机制的最小通知 单元，这个数据结构中只包含三部分内容：通知状态、事件类型和 节点路径。</p><h3 id="权限控制-ACL"><a href="#权限控制-ACL" class="headerlink" title="权限控制 ACL"></a>权限控制 ACL</h3><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191416175.png" alt="image-20220403191416175">)</p><p>在ZooKeeper的实际使用中，我们的做法往往是搭建一个共用的 ZooKeeper集群，统一为若干个应用提供服务。在这种情况下，不 同的应用之间往往是不会存在共享数据的使用场景的，因此需要解 决不同应用之间的权限问题。</p><p>参数： </p><p>1 ZooKeeper的权限控制是基于每个znode节点的，需要对每个节点设置权限 </p><p>2 每个znode支持设置多种权限控制方案和多个权限 </p><p>3 子节点不会继承父节点的权限，客户端无权访问某节点，但可能可以访问它的子节点</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/Users/jianjian/blog/source/_posts/Zookeeper%E7%AC%94%E8%AE%B02/image-20220403182150011.png" alt="image-20220403182150011"></p><h5 id="schema"><a href="#schema" class="headerlink" title="schema"></a>schema</h5><p>ZooKeeper内置了一些权限控制方案，可以用以下方案为每个节点设置权限：</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191422575.png" alt="image-20220403191422575"></p><p><img src="/2022/04/01/zookeeper-bi-ji-2/Users/jianjian/blog/source/_posts/Zookeeper%E7%AC%94%E8%AE%B02/image-20220403182623463.png" alt="image-20220403182623463"></p><h5 id="id"><a href="#id" class="headerlink" title="id"></a>id</h5><p>授权对象ID是指，权限赋予的用户或者一个实体，例如：IP 地址或 者机器。授权模式 schema 与 授权对象 ID 之间关系：</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191427673.png" alt="image-20220403191427673">)</p><h5 id="权限permission"><a href="#权限permission" class="headerlink" title="权限permission"></a>权限permission</h5><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191431927.png" alt="image-20220403191431927"></p><h5 id="权限相关命令"><a href="#权限相关命令" class="headerlink" title="权限相关命令"></a>权限相关命令</h5><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191436188.png" alt="image-20220403191436188"></p><h6 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h6><p>默认创建一个节点就是world方案，就是任何人都拥有所有权限</p><h6 id="ip"><a href="#ip" class="headerlink" title="ip"></a>ip</h6><pre class=" language-none"><code class="language-none">setAcl /node2 ip:192.168.100.1:cdrwa </code></pre><h6 id="Auth方案"><a href="#Auth方案" class="headerlink" title="Auth方案"></a>Auth方案</h6><p>语法格式：</p><pre class=" language-none"><code class="language-none">setAcl <path> auth:<user>:<acl></code></pre><p>添加认证用户</p><pre class=" language-none"><code class="language-none">addauth digest <user>:<password></code></pre><p>注：断开会话重连需要重 新addauth添加认证用户</p><h4 id="原生API操作Zookeeper"><a href="#原生API操作Zookeeper" class="headerlink" title="原生API操作Zookeeper"></a>原生API操作Zookeeper</h4><pre class=" language-Java"><code class="language-Java">/** * zookeeper原生API操作 */public class ZKMain &#123;    public static void main(String[] args) throws IOException, InterruptedException, KeeperException &#123;        //1.创建会话        /**         * 参数解释：         *  param 1 - Zookeeper 的实例 ip ，此处是一个集群，所以配置了多个 ip，用逗号隔开         *  param 2 - session 过期时间，单位秒(1000),会话超时时间         *  param 3 - 监视者，用于获取监听事件，监听机制         */        ZooKeeper zk = new ZooKeeper("192.168.8.14,192.168.8.15," +                "192.168.8.16",4000,null);        //查看链接状态        System.out.println(zk.getState());        /**         * 创建节点         * 第一个参数：节点名字         * 节点数据         * ACL策略  OpenAcl:完全开放，任何属性都能操作，还有就是创建者，可读...         * 节点类型         *///        zk.create("/node1","123".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);//        System.out.println("========创建成功============");        //判断节点是否存在//        Stat node1 = zk.exists("/node1", null);//        System.out.println(node1.toString());        //删除节点   -1全匹配全部版本号        zk.delete("/node1",-1);        //修改节点        zk.setData("/node1","fuckkkk".getBytes(),-1);        //获取节点数据        byte[] data = zk.getData("/node1", null, null);        System.out.println(new String(data));        //获取节点        List<String> children = zk.getChildren("/node1", null);        for (String child: children             ) &#123;            System.out.println(child);        &#125;    &#125;&#125;</code></pre><p>下来就是看如何实现监听的机制</p><p>针对于节点的监听</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191451855.png" alt="image-20220403191451855"></p><p>监听节点数据</p><p><img src="/2022/04/01/zookeeper-bi-ji-2/image-20220403191456045.png" alt="image-20220403191456045"></p><p>监听节点，监听数据</p><p>使用原生AP操作的话，他的监听就是只有一次的，要想多次监听，就还得重新注册，这就是一个坏处</p><p>具体怎么一个监听一次呢，就是你一直运行着这个项目，然后直接去改节点数据，一改完就可以看见监听成功的回调，然后你清空控制台，再去修改一次节点数据，然后回去看控制台什么反应都没有的</p><h4 id="ZkClient操作Zookeeper"><a href="#ZkClient操作Zookeeper" class="headerlink" title="ZkClient操作Zookeeper"></a>ZkClient操作Zookeeper</h4><pre class=" language-Java"><code class="language-Java">package com.jian.zookeepernewdemo;import org.I0Itec.zkclient.IZkChildListener;import org.I0Itec.zkclient.IZkDataListener;import org.I0Itec.zkclient.ZkClient;import org.apache.zookeeper.CreateMode;import java.util.List;public class ZKClientMain &#123;    public static void main(String[] args) throws InterruptedException &#123;        //1.创建会话        ZkClient zk = new ZkClient("192.168.8.14,192.168.8.15,192.168.8.16");        //2.获取子节点//        List<String> children = zk.getChildren("/node");//        children.forEach(f ->&#123;//            System.out.println(f);//        &#125;);                //3.创建节点//        zk.create("/node3","666", CreateMode.PERSISTENT);//        System.out.println("创建节点成功");        //4.修改节点数据//        zk.writeData("/node3","fuckkk");        //5.获取数据//        String o = zk.readData("/node3");//        System.out.println(o);        //6.删除数据//        zk.delete("/node3");        //7.注册节点监听事件//        zk.subscribeChildChanges("/node", new IZkChildListener() &#123;//            @Override//            public void handleChildChange(String s, List<String> list) throws Exception &#123;////                System.out.println("数据发生改变");//                list.forEach(f ->&#123;//                    System.out.println(f);//                &#125;);//            &#125;//        &#125;);        //8.注册节点数据监听事件            zk.subscribeDataChanges("/node2", new IZkDataListener() &#123;                @Override                public void handleDataChange(String s, Object o) throws Exception &#123;                &#125;                @Override                public void handleDataDeleted(String s) throws Exception &#123;                    System.out.println("数据被删除了");                &#125;            &#125;);            Thread.sleep(Long.MAX_VALUE);    &#125;&#125;</code></pre><h4 id="Curator"><a href="#Curator" class="headerlink" title="Curator"></a>Curator</h4><p>然后Curator也是一个zookeeper的客户端框架，和ZkClient一样，但是他是全世界范围内使用最广泛的Zookeeper客户端之一，目前已经成为了Apache的顶级项目</p><p>然后有三个版本，直接引入最高级的版本，他是肯定包含低级版本的</p><pre class=" language-Java"><code class="language-Java">package com.jian.zookeepernewdemo;import org.apache.curator.framework.CuratorFramework;import org.apache.curator.framework.CuratorFrameworkFactory;import org.apache.curator.framework.recipes.cache.NodeCache;import org.apache.curator.retry.ExponentialBackoffRetry;import org.apache.zookeeper.CreateMode;import java.util.List;/** * curator的方式操作zookeeper */public class CuratorMain &#123;    public static void main(String[] args) throws Exception &#123;        //1.创建会话        String connStr = "192.168.8.14,192.168.8.15,192.168.8.16";        //工厂模式创建会话        CuratorFramework cur = CuratorFrameworkFactory.builder()                .connectString(connStr)                .sessionTimeoutMs(5000)//超时时间                .retryPolicy(new ExponentialBackoffRetry(1000, 3))//断开重试机制                .build();        //连接        cur.start();        //2.创建节点//        cur.create()//里面不能写东西，也是通过.调用//        .withMode(CreateMode.PERSISTENT).forPath("/node4","666".getBytes());        //3.获取数据//        byte[] bytes = cur.getData()//                .forPath("/node4");//        System.out.println(new String(bytes));        //4.删除一个节点，这种方式不能删除有子节点的//        cur.delete().forPath("/node4");        //5.删除节点但是这个节点里面有子节点  递归删除//        cur.delete().deletingChildrenIfNeeded().forPath("/node3");        //6.修改节点//        cur.setData().forPath("/node","666".getBytes());        //7.获取某个节点的所有子节点//        List<String> list = cur.getChildren().forPath("/node");//        for (String s:list//             ) &#123;//            System.out.println(s);//        &#125;        //8.监听机制 --永久的        NodeCache nodeCache = new NodeCache(cur,"/node");        nodeCache.getListenable().addListener(() ->&#123;            System.out.println("被修改了.........");        &#125;);        nodeCache.start();//运行跑起来        Thread.sleep(Long.MAX_VALUE);    &#125;&#125;</code></pre><h4 id="四字命令"><a href="#四字命令" class="headerlink" title="四字命令"></a>四字命令</h4><p>这里不多解释</p><p>ruok有点问题，就是他说没问题，他有可能是服务出现问题，所以在工作中不要用ruok来判断zookeeper运行没运行</p><p>用的比较多的就是conf、cons、stat</p><h4 id="选举机制"><a href="#选举机制" class="headerlink" title="选举机制"></a>选举机制</h4><p>采用半数选举的方式</p><h5 id="核心选举原则"><a href="#核心选举原则" class="headerlink" title="核心选举原则"></a>核心选举原则</h5><ul><li><p>Zookeeper集群中只有超过半数以上的服务器启动，集群才能正常工作； </p></li><li><p>在集群正常工作之前，myid小的服务器给myid大的服务器投票，直到集群正常工作，选出 Leader； </p></li><li><p>半数机制；</p><h4 id="选举机制流程"><a href="#选举机制流程" class="headerlink" title="选举机制流程"></a>选举机制流程</h4></li><li><p>服务器1启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息， 服务器1的状态一直属于Looking(选举状态)。 </p></li><li><p>服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的编号大所以服务 器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。 </p></li><li><p>服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的编号最大所以 服务器3胜出，此时投票数正好大于半数，所以服务器3成为领导者，服务器1,2成为小弟。 </p></li><li><p>服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的编号大，但 之前服务器3已经胜出，所以服务器4只能成为小弟。 </p></li><li><p>服务器5启动，后面的逻辑同服务器4成为小弟。</p></li></ul><h5 id="选择机制中的概念"><a href="#选择机制中的概念" class="headerlink" title="选择机制中的概念"></a>选择机制中的概念</h5><h6 id="Serverid：服务器ID"><a href="#Serverid：服务器ID" class="headerlink" title="Serverid：服务器ID"></a>Serverid：服务器ID</h6><p>比如有三台服务器，编号分别是1,2,3。</p><p><strong>编号越大在选择算法中的权重越大。</strong></p><h6 id="Zxid：数据ID"><a href="#Zxid：数据ID" class="headerlink" title="Zxid：数据ID"></a>Zxid：数据ID</h6><p>服务器中存放的最大数据ID.</p><p><strong>值越大说明数据越新，在选举算法中数据越新权重越大。</strong></p><h6 id="Epoch：逻辑时钟"><a href="#Epoch：逻辑时钟" class="headerlink" title="Epoch：逻辑时钟"></a>Epoch：逻辑时钟</h6><p>或者叫投票的次数，同一轮投票过程中的逻辑时钟值是相同的。每 投完一次票这个数据就会增加，然后与接收到的其它服务器返回的 投票信息中的数值相比，根据不同的值做出不同的判断。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper笔记1</title>
      <link href="/2022/03/29/zookeeper-bi-ji-1/"/>
      <url>/2022/03/29/zookeeper-bi-ji-1/</url>
      
        <content type="html"><![CDATA[<hr><hr><h5 id="注："><a href="#注：" class="headerlink" title="注："></a>注：</h5><p>笔记为技术入门学习，到时候再写一篇书籍《Zookeeper分布式过程协同技术详解的笔记》</p><h3 id="一、-Zookeeper-简介"><a href="#一、-Zookeeper-简介" class="headerlink" title="一、 Zookeeper 简介"></a>一、 Zookeeper 简介</h3><h4 id="1-什么是-Zookeeper"><a href="#1-什么是-Zookeeper" class="headerlink" title="1 什么是 Zookeeper"></a>1 什么是 Zookeeper</h4><p>Zookeeper 是 Apache 的一个分布式服务框架，是 Apache Hadoop 的一个子项目。官方 文档上这么解释 Zookeeper，它主要是用来解决分布式应用中经常遇到的一些数据管理问题， 如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。 </p><p><strong>简单来说 zookeeper&#x3D;文件系统+监听通知机制</strong></p><h3 id="二、-Zookeeper-存储结构"><a href="#二、-Zookeeper-存储结构" class="headerlink" title="二、 Zookeeper 存储结构"></a>二、 Zookeeper 存储结构</h3><h4 id="1-Znode"><a href="#1-Znode" class="headerlink" title="1 Znode"></a><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329120753191.png" alt="image-20220329120753191">1 Znode</h4><p>在 Zookeeper 中，znode 是一个跟 Unix 文件系统路径相似的节点，可以向节点存储数据或者获取数据。 </p><p>Zookeeper 底层是一套数据结构。这个存储结构是一个树形结构，其上的每一个节点， 我们称之为“znode” </p><p>Zookeeper 中的数据是按照“树”结构进行存储的。而且 znode 节点还分为 4 中不同的类型。 </p><p>每一个 znode 默认能够存储 1MB 的数据（对于记录状态性质的数据来说，够了） </p><p>可以使用 zkCli 命令，登录到 Zookeeper 上，并通过 ls、create、delete、get、set 等命令操作这些 znode 节点</p><h4 id="2-Znode-节点类型"><a href="#2-Znode-节点类型" class="headerlink" title="2 Znode 节点类型"></a>2 Znode 节点类型</h4><h5 id="2-1-PERSISTENT-持久化目录节点"><a href="#2-1-PERSISTENT-持久化目录节点" class="headerlink" title="2.1 PERSISTENT-持久化目录节点"></a>2.1 PERSISTENT-持久化目录节点</h5><p>客户端与 zookeeper 断开连接后，该节点依旧存在。 </p><h5 id="2-2-PERSISTENT-SEQUENTIAL-持久化顺序编号目录节点"><a href="#2-2-PERSISTENT-SEQUENTIAL-持久化顺序编号目录节点" class="headerlink" title="2.2 PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点"></a>2.2 PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点</h5><p>客户端与 zookeeper 断开连接后，该节点依旧存在，只是 Zookeeper 给该节点名称进行顺序编号。 </p><h5 id="2-3-EPHEMERAL-临时目录节点"><a href="#2-3-EPHEMERAL-临时目录节点" class="headerlink" title="2.3 EPHEMERAL-临时目录节点"></a>2.3 EPHEMERAL-临时目录节点</h5><p>客户端与 zookeeper 断开连接后，该节点被删除。 </p><h5 id="2-4-EPHEMERAL-SEQUENTIAL-临时顺序编号目录节点"><a href="#2-4-EPHEMERAL-SEQUENTIAL-临时顺序编号目录节点" class="headerlink" title="2.4 EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点"></a>2.4 EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点</h5><p>客户端与 zookeeper 断开连接后，该节点被删除，只是 Zookeeper 给该节点名称进行顺序编号。</p><h3 id="三、-监听通知机制"><a href="#三、-监听通知机制" class="headerlink" title="三、 监听通知机制"></a>三、 监听通知机制</h3><p>Zookeeper 是使用观察者设计模式来设计的。当客户端注册监听它关心的目录节点时， 当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，Zookeeper 会通知客户端。</p><h3 id="四、-安装-zookeeper"><a href="#四、-安装-zookeeper" class="headerlink" title="四、 安装 zookeeper"></a>四、 安装 zookeeper</h3><h4 id="1-安装单机版"><a href="#1-安装单机版" class="headerlink" title="1.安装单机版"></a>1.安装单机版</h4><p>首先先去创建一台虚拟机，然后安装一下JDK以及配置一个环境变量</p><p>接着就是上传和解压zookeeper的压缩包</p><h4 id="2-Zookeeper-目录结构"><a href="#2-Zookeeper-目录结构" class="headerlink" title="2.Zookeeper 目录结构"></a>2.Zookeeper 目录结构</h4><pre class=" language-none"><code class="language-none">1. bin：放置运行脚本和工具脚本，2. conf：zookeeper 默认读取配置的目录，里面会有默认的配置文件3. docs：zookeeper 相关的文档4. lib：zookeeper 核心的 jar5. logs：zookeeper 日志</code></pre><h4 id="3-配置zookeeper"><a href="#3-配置zookeeper" class="headerlink" title="3.配置zookeeper"></a>3.配置zookeeper</h4><p>Zookeeper 在启动时默认的去 conf 目录下查找一个名称为 zoo.cfg 的配置文件。 在 zookeeper 应用目录中有子目录 conf。其中有配置文件模板：zoo_sample.cfg cp zoo_sample.cfg zoo.cfg。zookeeper 应用中的配置文件为 conf&#x2F;zoo.cfg。</p><p>修改配置文件 zoo.cfg - 设置数据缓存路径</p><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329124124371.png" alt="image-20220329124124371"></p><h4 id="4-启动-Zookeeper"><a href="#4-启动-Zookeeper" class="headerlink" title="4.启动 Zookeeper"></a>4.启动 Zookeeper</h4><p>默认加载配置文件：.&#x2F;zkServer.sh start：默认的会去 conf 目录下加载 zoo.cfg 配置文件。 </p><p>指定加载配置文件：.&#x2F;zkServer.sh start <strong>配置文件的路径。</strong></p><h4 id="5-停止zookeeper"><a href="#5-停止zookeeper" class="headerlink" title="5.停止zookeeper"></a>5.停止zookeeper</h4><pre class=" language-none"><code class="language-none">./zkServer.sh stop</code></pre><h4 id="6-查看-Zookeeper-状态"><a href="#6-查看-Zookeeper-状态" class="headerlink" title="6.查看 Zookeeper 状态"></a>6.查看 Zookeeper 状态</h4><pre class=" language-none"><code class="language-none">./zkServer.sh status</code></pre><h4 id="7-使用客户端连接单机版-Zookeepe"><a href="#7-使用客户端连接单机版-Zookeepe" class="headerlink" title="7.使用客户端连接单机版 Zookeepe"></a>7.使用客户端连接单机版 Zookeepe</h4><h5 id="7-1连接方式一"><a href="#7-1连接方式一" class="headerlink" title="7.1连接方式一"></a>7.1连接方式一</h5><p>bin&#x2F;zkCli.sh 默认连接地址为本机地址，默认连接端口为 2181</p><h5 id="7-2连接方式二"><a href="#7-2连接方式二" class="headerlink" title="7.2连接方式二"></a>7.2连接方式二</h5><p>bin&#x2F;zkCli.sh -server ip:port 连接指定 IP 地址与端口</p><h4 id="8-安装集群版"><a href="#8-安装集群版" class="headerlink" title="8.安装集群版"></a>8.安装集群版</h4><h5 id="8-1-Zookeeper-集群中的角色"><a href="#8-1-Zookeeper-集群中的角色" class="headerlink" title="8.1 Zookeeper 集群中的角色"></a>8.1 Zookeeper 集群中的角色</h5><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329124655830.png" alt="image-20220329124655830"></p><p>学习阶段在这里就搭建伪集群了</p><p>应用部署位置是：192.168.233.130。客户端 监听端口分别为：2181、2182、2183。投票选举端口分别为 2881&#x2F;3881、2882&#x2F;3882、2883&#x2F;3883。 tar -zxf zookeeper-3.6.0.tar.gz </p><p>将解压后的 Zookeeper 应用目录重命名，便于管理 mv zookeeper-3.6.0 zookeeper01</p><h5 id="8-2提供数据缓存目录"><a href="#8-2提供数据缓存目录" class="headerlink" title="8.2提供数据缓存目录"></a>8.2提供数据缓存目录</h5><p>在 zookeeper01 应用目录中，创建 data 目录，用于缓存应用运行数据 cd zookeeper01 mkdir data</p><h5 id="8-3复制应用"><a href="#8-3复制应用" class="headerlink" title="8.3复制应用"></a>8.3复制应用</h5><p>复制两份 Zookeeper 应用。用于模拟集群中的 3 个节点。 </p><p>cp -r zookeeper01 zookeeper02 </p><p>cp -r zookeeper01 zookeeper03</p><h5 id="8-4-提供配置文件、设置数据缓存路径"><a href="#8-4-提供配置文件、设置数据缓存路径" class="headerlink" title="8.4 提供配置文件、设置数据缓存路径"></a>8.4 提供配置文件、设置数据缓存路径</h5><p>这个上面有，做相关修改就行</p><h5 id="8-5提供应用唯一标识"><a href="#8-5提供应用唯一标识" class="headerlink" title="8.5提供应用唯一标识"></a>8.5提供应用唯一标识</h5><p>在 Zookeeper 集群中，每个节点需要一个唯一标识。这个唯一标识要求是自然数。且唯 一标识保存位置是：数据缓存目录(dataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;data)的 myid 文件中。其中“数据缓存目录”为配置文件 zoo.cfg 中的配置参数 </p><p>在 data 目录中创建文件 myid ： touch myid </p><p>为应用提供唯一标识。本环境中使用 1、2、3 作为每个节点的唯一标识。 </p><p>vi myid </p><p>简化方式为： echo [唯一标识] &gt;&gt; myid。 echo 命令为回声命令，系统会将命令发送的 数据返回。 ‘&gt;&gt;’为定位，代表系统回声数据指定发送到什么位置。 此命令代表系统回声数 据发送到 myid 文件中。 如果没有文件创建文件</p><h5 id="8-6修改配置文件"><a href="#8-6修改配置文件" class="headerlink" title="8.6修改配置文件"></a>8.6修改配置文件</h5><p>vim zoo.cfg</p><p>就是根据应用做对应的端口修改</p><p>都设置好之后，查看状态，02leader，其他都是follower</p><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220122204938380.png" alt="image-20220122204938380"></p><h5 id="8-7编写一个启动，关闭集群脚本"><a href="#8-7编写一个启动，关闭集群脚本" class="headerlink" title="8.7编写一个启动，关闭集群脚本"></a>8.7编写一个启动，关闭集群脚本</h5><p>chmod 777 文件名  </p><p>分配可读可写可执行权限</p><p>启动</p><pre class=" language-none"><code class="language-none">zookeeper01/bin/zkServer.sh startzookeeper02/bin/zkServer.sh startzookeeper03/bin/zkServer.sh start</code></pre><p>关闭</p><pre class=" language-none"><code class="language-none">zookeeper01/bin/zkServer.sh stopzookeeper02/bin/zkServer.sh stopzookeeper03/bin/zkServer.sh stop</code></pre><h5 id="8-8连接集群"><a href="#8-8连接集群" class="headerlink" title="8.8连接集群"></a>8.8连接集群</h5><p>可以使用任何节点中的客户端工具连接集群中的任何节点。 .&#x2F;zkCli.sh -server 192.168.233.130:2183</p><h3 id="五、-Zookeeper-常用命令"><a href="#五、-Zookeeper-常用命令" class="headerlink" title="五、 Zookeeper 常用命令"></a>五、 Zookeeper 常用命令</h3><h4 id="1-ls"><a href="#1-ls" class="headerlink" title="1 ls"></a>1 ls</h4><p>ls &#x2F;path 使用 ls 命令查看 zookeeper 中的内容。在 ZooKeeper 控制台客户端中，没有默认列表功 能，必须指定要列表资源的位置。 如： ls &#x2F; 或者 ls  &#x2F;path</p><h4 id="2-create"><a href="#2-create" class="headerlink" title="2 create"></a>2 create</h4><p>create [-e] [-s] &#x2F;path [data]</p><p>使用 create 命令创建一个新的 Znode。</p><p>如： create &#x2F;test 123 创建一个&#x2F;test 节点，节点携带数据信息 123。 create -e &#x2F;test 123 创建一个临时节 点&#x2F;test，携带数据为 123，临时节点只在当前会话生命周期中有效，会话结束节点自动删除。</p><p>create -s &#x2F;test 123 创建一个顺序节点&#x2F;test，携带数据 123，创建的顺序节点由 ZooKeeper 自 动为节点增加后缀信息，如-&#x2F;test00000001 等。-e 和-s 参数可以联合使用</p><h4 id="3-get"><a href="#3-get" class="headerlink" title="3 get"></a>3 get</h4><p>get [-s] &#x2F;path</p><p>get 命令获取 Znode 中的数据。</p><p><strong>-s 查看 Znode 详细信息</strong></p><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329133741788.png" alt="image-20220329133741788"></p><p>oldlu:存放的数据 </p><p>cZxid:创建时 zxid(znode 每次改变时递增的事务 id) </p><p>ctime:创建时间戳 </p><p>mZxid:最近一次更近的 zxid </p><p>mtime:最近一次更新的时间戳 </p><p>pZxid:子节点的 zxid </p><p>cversion:子节点更新次数 </p><p>dataversion:节点数据更新次数 </p><p>aclVersion:节点 ACL(授权信息)的更新次数 </p><p>ephemeralOwner:如果该节点为 ephemeral 节点(临时，生命周期与 session 一样), ephemeralOwner 值表示与该节点绑定的 session id. 如果该节点不是 ephemeral 节点, ephemeralOwner 值为 0.</p><p>dataLength:节点数据字节数 </p><p>numChildren:子节点数量</p><h4 id="4-set"><a href="#4-set" class="headerlink" title="4 set"></a>4 set</h4><p>set &#x2F;path [data] </p><p>添加或修改 Znode 中的值</p><h4 id="5-delete"><a href="#5-delete" class="headerlink" title="5 delete"></a>5 delete</h4><p>delete &#x2F;path </p><p>删除 Znode。</p><h3 id="六、-使用-Java-API-操作-Zooke"><a href="#六、-使用-Java-API-操作-Zooke" class="headerlink" title="六、 使用 Java API 操作 Zooke"></a>六、 使用 Java API 操作 Zooke</h3><p>创建项目，添加zookeeper依赖</p><h4 id="1-创建Znode并添加数据"><a href="#1-创建Znode并添加数据" class="headerlink" title="1.创建Znode并添加数据"></a>1.创建Znode并添加数据</h4><pre class=" language-Java"><code class="language-Java">/** * 操作Zookeeper的Znode */public class ZnodeDemo implements Watcher &#123;    public static void main(String[] args) throws InterruptedException, KeeperException, IOException &#123;        //创建连接Zookeeper对象,这里用的三个参数构造方法        //第一个，连接的结点和端口，多个之间逗号隔开，        // sessionTimeOut：连接超时时间，   Watcher：事件通知处理器（回调）        ZooKeeper zooKeeper = new ZooKeeper(                "192.168.8.103:2181," +                "192.168.8.103:2182," +                "192.168.8.103:2183",15000,new ZnodeDemo() );       String path = zooKeeper.create("/bjsxt/test", "jianjian".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT_SEQUENTIAL);//相当于create命令，四个参,路径，存放的值（字节数组），操作的权限，CreateMode（四种类型之一）//OpenACL,开放所有权限，create：创建权限，read：读取，还有一个anyoneID：对当前客户端开放所有权限        System.out.println(path);    /**     * 事件通知回调方法     * @param event     */    @Override    public void process(WatchedEvent event) &#123;        //获取连接事件  返回值相等表示连接成功        if (event.getState() == Event.KeeperState.SaslAuthenticated)&#123;//.SyncConnected？？            System.out.println("连接成功！");        &#125;    &#125;&#125;</code></pre><h4 id="2-获取Znode中的数据"><a href="#2-获取Znode中的数据" class="headerlink" title="2. 获取Znode中的数据"></a>2. 获取Znode中的数据</h4><h5 id="2-1获取指定节点中的数据"><a href="#2-1获取指定节点中的数据" class="headerlink" title="2.1获取指定节点中的数据"></a>2.1获取指定节点中的数据</h5><pre class=" language-java"><code class="language-java">  <span class="token comment" spellcheck="true">//获取指定结点的数据   路径  处理器  统计对象</span>        <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> data <span class="token operator">=</span> zooKeeper<span class="token punctuation">.</span><span class="token function">getData</span><span class="token punctuation">(</span><span class="token string">"/bjsxt/test0000000000"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">ZnodeDemo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Stat</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token comment" spellcheck="true">//output:jianjian</span></code></pre><h5 id="2-2获取所有子节点中的数据"><a href="#2-2获取所有子节点中的数据" class="headerlink" title="2.2获取所有子节点中的数据"></a>2.2获取所有子节点中的数据</h5><pre class=" language-Java"><code class="language-Java">//获取指定节点中的所有子节点中的数据        List<String> list = zooKeeper.getChildren("/bjsxt", new ZnodeDemo());//子节点路径，Watcher        //list存放的是返回的所有子节点的路径        for (String path:list             ) &#123;            byte[] data = zooKeeper.getData("/bjsxt/" + path, new ZnodeDemo(), new Stat());            System.out.println(new String(data));        &#125;        //output:jianjian</code></pre><h4 id="3-设置-Znode-中的值"><a href="#3-设置-Znode-中的值" class="headerlink" title="3 设置 Znode 中的值"></a>3 设置 Znode 中的值</h4><pre class=" language-java"><code class="language-java">        <span class="token comment" spellcheck="true">//设置Znode中的值   三个参   路径  设置的值  version：详细信息中的子节点更新次数</span>        <span class="token comment" spellcheck="true">//就是给定的版本号和当前的version不匹配，就不会修改   -1：任何版本都可以(匹配任何版本)</span>        Stat stat <span class="token operator">=</span> zooKeeper<span class="token punctuation">.</span><span class="token function">setData</span><span class="token punctuation">(</span><span class="token string">"/bjsxt/test0000000000"</span><span class="token punctuation">,</span> <span class="token string">"juejue"</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>stat<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h4 id="4-删除Znode"><a href="#4-删除Znode" class="headerlink" title="4.删除Znode"></a>4.删除Znode</h4><pre class=" language-java"><code class="language-java"><span class="token comment" spellcheck="true">//删除   路径，版本</span>        zooKeeper<span class="token punctuation">.</span><span class="token function">delete</span><span class="token punctuation">(</span><span class="token string">"/bjsxt/test0000000000"</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><h3 id="七、-Zookeeper-实战"><a href="#七、-Zookeeper-实战" class="headerlink" title="七、 Zookeeper 实战"></a>七、 Zookeeper 实战</h3><p>实战案例介绍：使用 Zookeeper 与 RMI 技术实现一个 RPC 框架。</p><p>RPC：（Remote Procedure Call）远程过程调用</p><h4 id="1-基于-RMI-实现远程方法调用"><a href="#1-基于-RMI-实现远程方法调用" class="headerlink" title="1 基于 RMI 实现远程方法调用"></a>1 基于 RMI 实现远程方法调用</h4><h5 id="1-1RMI-简-介"><a href="#1-1RMI-简-介" class="headerlink" title="1.1RMI 简 介"></a>1.1RMI 简 介</h5><p>RMI(Remote Method Invocation) 远程方法调用。 RMI 是从 JDK1.2 推出的功能，它可以实现在一个 Java 应用中可以像调用本地方法一样 调用另一个服务器中 Java 应用（JVM）中的内容。 RMI 是 Java 语言的远程调用，无法实现跨语言</p><h5 id="1-2执行流程"><a href="#1-2执行流程" class="headerlink" title="1.2执行流程"></a>1.2执行流程</h5><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329140808122.png" alt="image-20220329140808122"></p><p>Registry(注册表)是放置所有服务器对象的命名空间。 每次服务端创建一个对象时，它都会使用 bind()或 rebind()方法注册该对象。 这些是使用称为绑定名称的唯一名称注册的。 </p><p>要调用远程对象，客户端需要该对象的引用。即通过服务端绑定的名称从注册表中获取 对象(lookup()方法)。</p><h5 id="1-3RMI-的-API-介绍"><a href="#1-3RMI-的-API-介绍" class="headerlink" title="1.3RMI 的 API 介绍"></a>1.3RMI 的 API 介绍</h5><h6 id="1-3-1-Remote-接口"><a href="#1-3-1-Remote-接口" class="headerlink" title="1.3.1 Remote 接口"></a>1.3.1 Remote 接口</h6><p>java.rmi.Remote 定义了此接口为远程调用接口。如果接口被外部调用，需要继承此接口。</p><h6 id="1-3-2-RemoteException-类"><a href="#1-3-2-RemoteException-类" class="headerlink" title="1.3.2 RemoteException 类"></a>1.3.2 RemoteException 类</h6><p>java.rmi.RemoteException </p><p>继承了 Remote 接口的接口，如果方法是允许被远程调用的，需要抛出此异常。</p><h6 id="1-3-3-UnicastRemoteObject-类"><a href="#1-3-3-UnicastRemoteObject-类" class="headerlink" title="1.3.3 UnicastRemoteObject 类"></a>1.3.3 UnicastRemoteObject 类</h6><p>java.rmi.server.UnicastRemoteObject </p><p>此类实现了 Remote 接口和 Serializable 接口</p><p><strong>自定义接口实现类除了实现自定义接口还需要继承此类。</strong></p><h6 id="1-3-4-LocateRegistry-类"><a href="#1-3-4-LocateRegistry-类" class="headerlink" title="1.3.4 LocateRegistry 类"></a>1.3.4 LocateRegistry 类</h6><p>java.rmi.registry.LocateRegistry </p><p>可以通过 LocateRegistry 在本机上创建 Registry，通过特定的端口就可以访问这个 Registry。</p><h6 id="1-3-5-Naming-类"><a href="#1-3-5-Naming-类" class="headerlink" title="1.3.5 Naming 类"></a>1.3.5 Naming 类</h6><p>java.rmi.Naming </p><p>Naming 定义了发布内容可访问 RMI 名称。也是通过 Naming 获取到指定的远程方法</p><h5 id="1-4创建-Server"><a href="#1-4创建-Server" class="headerlink" title="1.4创建 Server"></a>1.4创建 Server</h5><h6 id="1-4-1创建项目"><a href="#1-4-1创建项目" class="headerlink" title="1.4.1创建项目"></a>1.4.1创建项目</h6><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329150012005.png" alt="image-20220329150012005"></p><h6 id="1-4-2创建接口"><a href="#1-4-2创建接口" class="headerlink" title="1.4.2创建接口"></a>1.4.2创建接口</h6><pre class=" language-Java"><code class="language-Java">/** *  定义允许远程调用接口，该接口必须要继承Remote接口 *  允许被远程调用的方法必须要抛出RemoteException */public interface DemoService extends Remote &#123;    String demo(String str) throws RemoteException;&#125;</code></pre><h6 id="1-4-3创建接口实现类"><a href="#1-4-3创建接口实现类" class="headerlink" title="1.4.3创建接口实现类"></a>1.4.3创建接口实现类</h6><pre class=" language-Java"><code class="language-Java">/** * 接口实现类必须要继承UnicastRemoteObject * 会自动添加构造方法，需要修改为public */public class DemoServiceImpl extends UnicastRemoteObject implements DemoService &#123;    public DemoServiceImpl() throws RemoteException &#123;    &#125;    @Override    public String demo(String str) throws RemoteException &#123;        return "Hello RMI"+str;    &#125;&#125;</code></pre><h6 id="1-4-4-编写主方法"><a href="#1-4-4-编写主方法" class="headerlink" title="1.4.4 编写主方法"></a>1.4.4 编写主方法</h6><pre class=" language-Java"><code class="language-Java">public class DemoServer &#123;    public static void main(String[] args) throws RemoteException, MalformedURLException, AlreadyBoundException &#123;        //将对象实例化        DemoService demoService = new DemoServiceImpl();        //创建本地注册表--给定别人访问注册表的端口        LocateRegistry.createRegistry(8888);        //将对象绑定到注册表当中   第一个参：查找对象使用rmi协议,最后必须要给绑定对象的唯一标识（注册表中不能有重复）        //第二个是绑定的对象    如果是别的机器，换localhost就可以了        Naming.bind("rmi://localhost:8888/demoService",demoService);    &#125;&#125;</code></pre><h5 id="1-5创建Client端"><a href="#1-5创建Client端" class="headerlink" title="1.5创建Client端"></a>1.5创建Client端</h5><h6 id="1-5-1创建项目"><a href="#1-5-1创建项目" class="headerlink" title="1.5.1创建项目"></a>1.5.1创建项目</h6><p><img src="/2022/03/29/zookeeper-bi-ji-1/image-20220329150249119.png" alt="image-20220329150249119"></p><h6 id="1-5-2复制服务端接口"><a href="#1-5-2复制服务端接口" class="headerlink" title="1.5.2复制服务端接口"></a>1.5.2复制服务端接口</h6><h6 id="1-5-3-创建主方法"><a href="#1-5-3-创建主方法" class="headerlink" title="1.5.3 创建主方法"></a>1.5.3 创建主方法</h6><pre class=" language-Java"><code class="language-Java">public class ClientDemo &#123;    public static void main(String[] args) throws MalformedURLException, NotBoundException, RemoteException &#123;        //把server中绑定的uri给过来，这样就能去注册表里找这个对象        DemoService demoService = (DemoService) Naming.lookup("rmi://localhost:8888/demoService");        String result = demoService.demo("JianJian");        System.out.println(result);    &#125;&#125;</code></pre><p>这就完事了</p><h4 id="2-使用-Zookeeper-作为注册中心"><a href="#2-使用-Zookeeper-作为注册中心" class="headerlink" title="2. 使用 Zookeeper 作为注册中心"></a>2. 使用 Zookeeper 作为注册中心</h4><h5 id="2-1-创建服务端"><a href="#2-1-创建服务端" class="headerlink" title="2.1 创建服务端"></a>2.1 创建服务端</h5><p>创建项目</p><h6 id="2-1-1-修改POM文件依赖"><a href="#2-1-1-修改POM文件依赖" class="headerlink" title="2.1.1 修改POM文件依赖"></a>2.1.1 修改POM文件依赖</h6><pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.zookeeper<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>zookeeper<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.6.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></code></pre><h6 id="2-1-2创建接口"><a href="#2-1-2创建接口" class="headerlink" title="2.1.2创建接口"></a>2.1.2创建接口</h6><pre class=" language-Java"><code class="language-Java">public interface UsersService extends Remote &#123;    String findUsers(String str) throws RemoteException;&#125;</code></pre><h6 id="2-1-3-创建接口实现类"><a href="#2-1-3-创建接口实现类" class="headerlink" title="2.1. 3 创建接口实现类"></a>2.1. 3 创建接口实现类</h6><pre class=" language-Java"><code class="language-Java">public class UsersServiceImpl extends UnicastRemoteObject implements UsersService &#123;    public UsersServiceImpl() throws RemoteException &#123;    &#125;    @Override    public String findUsers(String str) throws RemoteException &#123;        return "Hello Zookeeper"+str;    &#125;&#125;</code></pre><h6 id="2-1-4-编写主方法"><a href="#2-1-4-编写主方法" class="headerlink" title="2.1.4  编写主方法"></a>2.1.4  编写主方法</h6><pre class=" language-Java"><code class="language-Java">public class ServerDemo implements Watcher &#123;    public static void main(String[] args) throws IOException, AlreadyBoundException, InterruptedException, KeeperException &#123;        UsersService usersService = new UsersServiceImpl();        LocateRegistry.createRegistry(8888);        String str = "rmi://localhost:8888/user";        Naming.bind(str,usersService);        //将url信息放到zookeeper节点        ZooKeeper zooKeeper = new ZooKeeper(                "192.168.8.103:2181," +                        "192.168.8.103:2182," +                        "192.168.8.103:2183",15000,new ServerDemo() );        //创建Znode        zooKeeper.create("/bjsxt/service",str.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);        System.out.println("服务发布成功");    &#125;    @Override    public void process(WatchedEvent event) &#123;        //获取连接事件  返回值相等表示连接成功        if (event.getState() == Event.KeeperState.SyncConnected)&#123;            System.out.println("连接成功！");        &#125;    &#125;&#125;</code></pre><h5 id="2-2-创建客户端"><a href="#2-2-创建客户端" class="headerlink" title="2.2 创建客户端"></a>2.2 创建客户端</h5><p>依赖</p><h6 id="2-2-1-创建接口"><a href="#2-2-1-创建接口" class="headerlink" title="2.2.1 创建接口"></a>2.2.1 创建接口</h6><pre class=" language-Java"><code class="language-Java">public interface UsersService&#123;    String findUsers(String str);&#125;</code></pre><h6 id="2-2-2-编写主方法"><a href="#2-2-2-编写主方法" class="headerlink" title="2.2.2 编写主方法"></a>2.2.2 编写主方法</h6><pre class=" language-Java"><code class="language-Java">public class ClientDemo implements Watcher &#123;    public static void main(String[] args) throws IOException, InterruptedException, KeeperException, NotBoundException &#123;        ZooKeeper zooKeeper = new ZooKeeper(                "192.168.8.103:2181," +                        "192.168.8.103:2182," +                        "192.168.8.103:2183",15000,new ClientDemo() );        byte[] data = zooKeeper.getData("/bjsxt/service", new ClientDemo(),null);        String url = new String(data);        //通过lookup      UsersService usersService = (UsersService) Naming.lookup(url);      String result = usersService.findUsers("JianJian");      System.out.println(result);    &#125;    @Override    public void process(WatchedEvent event) &#123;        if (event.getState() == Event.KeeperState.SyncConnected)&#123;            System.out.println("连接成功！");        &#125;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Maven不能导入依赖</title>
      <link href="/2022/03/28/maven-bu-neng-dao-ru-yi-lai/"/>
      <url>/2022/03/28/maven-bu-neng-dao-ru-yi-lai/</url>
      
        <content type="html"><![CDATA[<hr><hr><hr><h4 id="做Dubbo的Demo"><a href="#做Dubbo的Demo" class="headerlink" title="做Dubbo的Demo"></a>做Dubbo的Demo</h4><p>maven在一个项目里面，任何依赖都导不出来，重新导入和刷新以及网上的方法都已经试了超多，也找了一些学友求助。</p><p>但是把这些依赖放在另一个没有问题的项目中，就可以正常的导出依赖。</p><p>接着仔细一看dependencyManagement，这个标签把dependencies标签包住了，直接删除掉。简单来说就是，先删除dependencyManagement标签等自动引入完依赖之后再原封不动还回去</p><p>然后后面创建consumer之后，就差运行tomcat了，发现插件没有tomcat，再仔细一看，又有一个插件管理，删掉之后等自动引入完成就可以看到tomcat的插件了。</p><p>重点！！！子项目就别搞依赖管理和插件管理，那是父项目使用的，插件管理就是不会自动引入，所以就会没有用    </p><h4 id="一、作用"><a href="#一、作用" class="headerlink" title="一、作用"></a>一、作用</h4><p>使用dependencyManagement可以统一管理项目中依赖包的版本号，当需要变更版本号时只需在父pom中修改即可；如果某个子项目需要指定一个特殊的版本号时，只需要在自己项目的pom.xml中显示声明一个版本号即可，此时子项目会使用自己声明的版本号，而不继承父项目的版本号</p><h4 id="二、dependencyManagement与dependencies的区别"><a href="#二、dependencyManagement与dependencies的区别" class="headerlink" title="二、dependencyManagement与dependencies的区别"></a>二、dependencyManagement与dependencies的区别</h4><ul><li><p>dependencies相对于dependencyManagement，所有声明在dependencies里的依赖都会<strong>自动引入</strong>，并默认被所有的子项目继承</p></li><li><p>dependencyManagement里只是声明依赖，<strong>并不会自动引入</strong>，因此子项目需要显示声明依赖。在子项目中声明了依赖项，且没有指定具体版本，才会从父项目中继承该项，并且version和scope都读取自父pom；另外如果子项目中指定了版本号，则会使用子项目中指定的版本</p></li><li><p>⚠️注意：一个无子工程的独立工程中如果使用dependencyManagement，那么它自己的pom.xml文件引入的依赖也可以不指定版本</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Maven </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Vue3-axios报错解决</title>
      <link href="/2022/03/28/vue3-axios-bao-cuo-jie-jue/"/>
      <url>/2022/03/28/vue3-axios-bao-cuo-jie-jue/</url>
      
        <content type="html"><![CDATA[<hr><p>在做springboot整合vue的前后端分离项目时遇到此问题。</p><p>搜了一下，别人是这样说的：根本原因是 引入的axios库是使用vue2.0开发的一套组件库，而我们当前的项目为vue3，所有存在兼容性的问题。</p><p>网上的解决方案也都试了一遍，问了前端的小伙伴他也不知道，但是它建议我用vue2再来，我不服，没人踩这坑，我拼了半条命也要给他填了。</p><p>首先，如果你是简单的项目，<a href="https://so.csdn.net/so/search?q=axios&spm=1001.2101.3001.7020">axios</a>调用也只有一个弹窗测试，那么你可以这样做。</p><p><img src="/2022/03/28/vue3-axios-bao-cuo-jie-jue/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeuWwvA==,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="img"></p><p>注释掉就可以了，你就会发现可以用。</p><p>但是当你真想调用访问后端接口时，比如调用get</p><pre class=" language-vue"><code class="language-vue">   created() &#123;    // alert(123)    axios.get("http://localhost:xxxx/xxxx").then(function (resp)&#123;      console.log(resp)    &#125;)  &#125;</code></pre><p>你就会发现马上就报错了。不卖关子了，整体怎么解决呢。</p><h4 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h4><p>1.注释掉axios中的倒数第二行代码（如果你刚刚做了可以直接下一步）</p><p>2.去main.js中添加以下代码</p><pre class=" language-vue"><code class="language-vue">import axios from 'axios'import VueAxios from 'vue-axios'createApp(App).use(VueAxios,axios)</code></pre><p> 3.这个时候，确实不报刚刚的ues问题了，但是会报vue-axios没安装</p><p>4.没安装就去安装呗，但是你会发现，安装不上。（安装上的就已经解决完了）。</p><p>5.没安装上你仔细一看，报错是这样的</p><p><img src="/2022/03/28/vue3-axios-bao-cuo-jie-jue/image-20220328210140344.png" alt="image-20220328210140344"> 很简单，我就理解为是vue3和axios冲突完了，别的又发生冲突了，报错提示的非常明显了，那我们继续下一步，直接去package.json里改版本</p><p><img src="/2022/03/28/vue3-axios-bao-cuo-jie-jue/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAeuWwvA==,size_20,color_FFFFFF,t_70,g_se,x_16-16484725345782.png" alt="img"></p><p>既然你说axios版本不太行，行，直接上最新的0.26.1。</p><p>然后就是控制台npm install一下，然后运行项目，到此这些问题就解决完了。</p><p>注：要是你运行还错，而且有关axios什么not found，请去你的vue文件里导入axios，</p><p>import axios from “axios”;<br>如果解决了，剩下的就是跨域问题了</p><p>跨域问题请看我的另一博客：<a href="https://blog.csdn.net/weixin_53156322/article/details/123416375">https://blog.csdn.net/weixin_53156322/article/details/123416375</a></p><p>感谢观看。</p>]]></content>
      
      
      <categories>
          
          <category> Vue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Active持久化到本地DB</title>
      <link href="/2022/03/28/active-chi-jiu-hua-dao-ben-di-db/"/>
      <url>/2022/03/28/active-chi-jiu-hua-dao-ben-di-db/</url>
      
        <content type="html"><![CDATA[<hr><p>ActiveMQ持久化到本地数据库报错，改好配置文件启动后，访问不到ActiveMQ的管理界面，就去<strong>查看日志文件</strong>。</p><pre><code>message from server: “Host ‘XXXXXX-XXXXXXXX‘ is not allowed to connect to this MySQL server“</code></pre><p>​    这个异常是数据库只允许<strong>localhost或127.0.0.1</strong>访问，也就是你虚拟机自己访问，不允许远程访问。由于本地项目无法设置SSH通道，所以需要修改数据库的访问权限。</p><p>首先我是直接想去改数据库的访问权限的，但是navicat又不能直接修改数据库访问权限，只能对表进行修改，但是我们就是<strong>没有表</strong>呀！！！</p><p><strong>这个表就是得让ActiveMQ来创建的</strong></p><p>然后是想着创建一个新用户，再去配置文件里把root用户改为这个用户。结果失败了</p><h4 id="正解："><a href="#正解：" class="headerlink" title="正解："></a>正解：</h4><p>cmd</p><p>mysql -u root -p 回车，输密码</p><p><img src="/2022/03/28/active-chi-jiu-hua-dao-ben-di-db/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57ud57ud44GX,size_20,color_FFFFFF,t_70,g_se,x_16.png" alt="img"></p><p>然后这就完事了，管理界面可以访问，也会帮你创建表</p><p><img src="/2022/03/28/active-chi-jiu-hua-dao-ben-di-db/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA57ud57ud44GX,size_16,color_FFFFFF,t_70,g_se,x_16.png" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> DB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Chrome恢复标签页</title>
      <link href="/2022/03/28/chrome-hui-fu-biao-qian-ye/"/>
      <url>/2022/03/28/chrome-hui-fu-biao-qian-ye/</url>
      
        <content type="html"><![CDATA[<h2 id="一不小心关闭了Chrome的标签页"><a href="#一不小心关闭了Chrome的标签页" class="headerlink" title="一不小心关闭了Chrome的标签页"></a>一不小心关闭了Chrome的标签页</h2><p>​          学习过程中总会有很多意外情况，比如另外一个屏幕新建了一个浏览器标签页，学习完了关电脑了，但是先关闭的是很多标签页的窗口，当然了，这些标签页再历史记录里都会有。</p><p><img src="/2022/03/28/chrome-hui-fu-biao-qian-ye/1562799979449.jpeg"></p><p>​          也算是有被自己的下饭操作秀到，第二天一打开浏览器发现上面一排标签页都没了，我确实慌了。</p><p>​                                                                                          <img src="/2022/03/28/chrome-hui-fu-biao-qian-ye/1564050376268.jpeg">                          </p><p>​        但是往往我们都是10~20+的标签页面，有各种各样的错误或者学习资源站点等等。还不是每一个都加入了收藏夹</p><p>无需记住被关闭的标签页的标题，一键恢复前一个被关闭的标签页，快捷键： <code> Ctrl + Shirt + T</code></p><p>​                                                                                      <img src="/2022/03/28/chrome-hui-fu-biao-qian-ye/1562799879092.jpeg"> </p>]]></content>
      
      
      <categories>
          
          <category> Other </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小失误 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java</title>
      <link href="/2022/03/28/wo-de-di-yi-ge-bo-ke/"/>
      <url>/2022/03/28/wo-de-di-yi-ge-bo-ke/</url>
      
        <content type="html"><![CDATA[<h5 id><a href="#" class="headerlink" title></a></h5><p>最全的实例</p><pre class=" language-markdown"><code class="language-markdown">title: typora-vue-theme主题介绍date: 2018-09-07 09:25:00author: 赵奇img: /source/images/xxx.jpgtop: truecover: true    这个玩意是轮播图coverImg: /images/1.jpgpassword: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92toc: falsemathjax: falsesummary: 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要categories: Markdowntags:  这里就是标签  <span class="token list punctuation">-</span> Typora  <span class="token list punctuation">-</span> Markdown</code></pre><hr><h3 id="内容一"><a href="#内容一" class="headerlink" title="内容一"></a>内容一</h3><hr><h3 id="内容二"><a href="#内容二" class="headerlink" title="内容二"></a>内容二</h3><table><thead><tr><th>外币巴伯？？</th><th>乌西滴西</th></tr></thead></table><p>写好之后清理，生成，推送一下就好了</p><p>但是这样的话，一行代码太长不会自动换行</p><pre class=" language-markdown"><code class="language-markdown">太长的一条跳TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT阿萨大阿萨大 撒达哈哈哈哈和和和和和呵呵和啊倒萨大苏打看哈就肯定不止吧但是这样的话，一行代码太长就不会自动换行，而且下面的进度跳也是没有用的</code></pre><p>安静的拉萨空间</p><p>噢噢噢噢噢噢噢噢噢噢噢噢噢噢噢噢哦哦哦</p><p>什么叫做代码高亮，md文件里怎么写才能让显示后代码高亮呢 <code>hexo new page &#39;My-second-blog&#39;</code></p><p><code>asdasad as gao liang??</code>   好像就是两个英文的1旁边的<code> 这个东西</code>括起来的内容就是高亮</p><p>加粗：<strong>阿大撒了解的空间里</strong></p><p>斜体：<em>撒角度来看啊空间达拉斯空间</em></p><p>下划线：<u>爱睡觉的拉开点距离看</u></p><p>删除线：<del>删除删除删除删除DELETE</del></p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 案例 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
